{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import sqlparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from src.database import SqliteDatabase\n",
    "from src.eval import result_eq, check_if_exists_orderby\n",
    "from src.eval_complexity import eval_all\n",
    "from src.process_sql import get_schema, Schema\n",
    "from src.parsing_sql import (\n",
    "    extract_selection, \n",
    "    extract_condition, \n",
    "    extract_aggregation, \n",
    "    extract_nested_setoperation, \n",
    "    extract_others,\n",
    "    extract_aliases,\n",
    ")\n",
    "\n",
    "proj_path = Path('.').resolve()\n",
    "all_tasks = []\n",
    "\n",
    "for typ in ['_c', '_t']:\n",
    "    iterator = ['low', 'mid', 'high'] if typ == '_c' else ['1', '2', '3+']\n",
    "    for typ2 in ['desc', 'descvt']:        \n",
    "        for n_retrieval in [1, 3]:\n",
    "            for level in iterator:\n",
    "                all_tasks.append(f'sql_gen_hint_top{n_retrieval}_{level}_{typ2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_infos = {\n",
    "    'pred_exec': [],\n",
    "    'result': [],\n",
    "    'parsing_sql': [],\n",
    "    'error_samples': set()\n",
    "}\n",
    "\n",
    "# filter parsing errors\n",
    "for task in all_tasks:\n",
    "    with open(proj_path / 'experiments' / f'{task}.jsonl', 'r') as f:\n",
    "        for line in tqdm(f, desc=task):\n",
    "            x = json.loads(line)\n",
    "            has_error = False\n",
    "            schema = get_schema(str(proj_path / 'data' / 'spider' / 'database' / x['db_id'] / f'{x[\"db_id\"]}.sqlite'))\n",
    "            schema = Schema(schema)\n",
    "            \n",
    "            parsed_result = {}\n",
    "            for s in ['gold', 'pred']:\n",
    "                try:\n",
    "                    sql = x[f'{s}_sql']\n",
    "                    statement = sqlparse.parse(sql.strip())[0]\n",
    "                    aliases = extract_aliases(statement)\n",
    "                    selection = extract_selection(statement, aliases, schema)\n",
    "                    condition = extract_condition(statement)\n",
    "                    aggregation = extract_aggregation(statement, aliases, schema)\n",
    "                    nested = extract_nested_setoperation(statement)\n",
    "                    others = extract_others(statement, aliases, schema)\n",
    "                    \n",
    "                    parsed_result[s + '_selection'] = selection\n",
    "                    parsed_result[s + '_condition'] = condition\n",
    "                    parsed_result[s + '_aggregation'] = aggregation\n",
    "                    parsed_result[s + '_nested'] = nested\n",
    "                    parsed_result[s + '_others'] = {\n",
    "                        'distinct': others['distinct'], \n",
    "                        'order by': others['order by'], \n",
    "                        'limit': others['limit']\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    has_error = True\n",
    "                    error_infos['parsing_sql'].append((x['sample_id'], s, str(e)))\n",
    "                    error_infos['error_samples'].add(x['sample_id'])\n",
    "                    break\n",
    "            \n",
    "            if has_error:\n",
    "                continue\n",
    "\n",
    "print(f'Parsing SQL errors: {len(error_infos[\"parsing_sql\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dev.225',\n",
       " 'dev.229',\n",
       " 'dev.311',\n",
       " 'dev.312',\n",
       " 'dev.742',\n",
       " 'dev.743',\n",
       " 'train.1602',\n",
       " 'train.167',\n",
       " 'train.168',\n",
       " 'train.205',\n",
       " 'train.2328',\n",
       " 'train.2500',\n",
       " 'train.3672',\n",
       " 'train.4363',\n",
       " 'train.6014',\n",
       " 'train.6330',\n",
       " 'train.897',\n",
       " 'train.898'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(error_infos['error_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'sql_gen_hint_top1_low_desc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pred_exec: 29 | result: 588: : 710it [00:10, 65.52it/s] \n"
     ]
    }
   ],
   "source": [
    "# process single task\n",
    "\n",
    "def process_task(task, error_infos):\n",
    "    task_results = {\n",
    "        'sample_id': [],\n",
    "        'score': [],\n",
    "        's_sel': [], 's_cond': [], 's_agg': [], 's_nest': [], 's_oth': [],\n",
    "    }\n",
    "    with open(proj_path / 'experiments' / f'{task}.jsonl', 'r') as f:\n",
    "        iterator = tqdm(f)\n",
    "        for line in iterator:\n",
    "            x = json.loads(line)\n",
    "            if x['sample_id'] in error_infos['error_samples']:\n",
    "                continue\n",
    "\n",
    "            task_results['sample_id'].append(x['sample_id'])\n",
    "            # parsing sql\n",
    "            schema = get_schema(str(proj_path / 'data' / 'spider' / 'database' / x['db_id'] / f'{x[\"db_id\"]}.sqlite'))\n",
    "            schema = Schema(schema)\n",
    "            \n",
    "            parsed_result = {}\n",
    "            for s in ['gold', 'pred']:\n",
    "                sql = x[f'{s}_sql']\n",
    "                statement = sqlparse.parse(sql.strip())[0]\n",
    "                aliases = extract_aliases(statement)\n",
    "                selection = extract_selection(statement, aliases, schema)\n",
    "                condition = extract_condition(statement)\n",
    "                aggregation = extract_aggregation(statement, aliases, schema)\n",
    "                nested = extract_nested_setoperation(statement)\n",
    "                others = extract_others(statement, aliases, schema)\n",
    "                \n",
    "                parsed_result[s + '_selection'] = selection\n",
    "                parsed_result[s + '_condition'] = condition\n",
    "                parsed_result[s + '_aggregation'] = aggregation\n",
    "                parsed_result[s + '_nested'] = nested\n",
    "                parsed_result[s + '_others'] = {\n",
    "                    'distinct': others['distinct'], \n",
    "                    'order by': others['order by'], \n",
    "                    'limit': others['limit']\n",
    "                }\n",
    "\n",
    "            # partial & complexity eval\n",
    "            eval_res = eval_all(parsed_result, k=6)\n",
    "            task_results['s_sel'].append(eval_res['score']['selection'])\n",
    "            task_results['s_cond'].append(eval_res['score']['condition'])\n",
    "            task_results['s_agg'].append(eval_res['score']['aggregation'])\n",
    "            task_results['s_nest'].append(eval_res['score']['nested'])\n",
    "            task_results['s_oth'].append(eval_res['score']['others'])\n",
    "            # Execution\n",
    "            database = SqliteDatabase(\n",
    "                str(proj_path / 'data' / 'spider' / 'database' / x['db_id'] / f'{x[\"db_id\"]}.sqlite')\n",
    "            )\n",
    "            error_info = ''\n",
    "            try:\n",
    "                pred_result = database.execute(x['pred_sql'], rt_pandas=False)\n",
    "            except Exception as e:\n",
    "                pred_result = []\n",
    "                error_info = 'Predction Execution Error:' + str(e)\n",
    "                score = 0\n",
    "\n",
    "            try:\n",
    "                gold_result = database.execute(x['gold_sql'], rt_pandas=False)\n",
    "            except Exception as e:\n",
    "                error_info = 'Gold Execution Error:' + str(e)\n",
    "\n",
    "            if 'Gold Execution Error' in error_info:\n",
    "                continue\n",
    "            elif 'Predction Execution Error' in error_info:\n",
    "                task_results['score'].append(score)\n",
    "                continue\n",
    "            else:\n",
    "                exists_orderby = check_if_exists_orderby(x['gold_sql'])\n",
    "                score = int(result_eq(pred_result, gold_result, order_matters=exists_orderby))\n",
    "                task_results['score'].append(score)\n",
    "\n",
    "    return task_results, error_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>db_id</th>\n",
       "      <th>score</th>\n",
       "      <th>s_sel</th>\n",
       "      <th>s_cond</th>\n",
       "      <th>s_agg</th>\n",
       "      <th>s_nest</th>\n",
       "      <th>s_oth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train.56</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train.64</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train.65</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train.76</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train.77</td>\n",
       "      <td>student_assessment</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>dev.954</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>dev.958</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>dev.960</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>dev.997</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>dev.999</td>\n",
       "      <td>dog_kennels</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sample_id               db_id  score     s_sel  s_cond  s_agg  s_nest  \\\n",
       "0    train.56  student_assessment      0  0.000000     1.0    0.0     1.0   \n",
       "1    train.64  student_assessment      0  0.000000     1.0    1.0     1.0   \n",
       "2    train.65  student_assessment      0  1.000000     0.0    1.0     1.0   \n",
       "3    train.76  student_assessment      0  0.000000     1.0    1.0     1.0   \n",
       "4    train.77  student_assessment      0  0.666667     1.0    1.0     1.0   \n",
       "..        ...                 ...    ...       ...     ...    ...     ...   \n",
       "687   dev.954         dog_kennels      0  1.000000     0.5    1.0     1.0   \n",
       "688   dev.958         dog_kennels      0  1.000000     1.0    1.0     1.0   \n",
       "689   dev.960         dog_kennels      0  1.000000     0.0    1.0     0.0   \n",
       "690   dev.997         dog_kennels      0  0.000000     1.0    1.0     1.0   \n",
       "691   dev.999         dog_kennels      1  1.000000     1.0    1.0     1.0   \n",
       "\n",
       "     s_oth  \n",
       "0      0.5  \n",
       "1      1.0  \n",
       "2      1.0  \n",
       "3      0.5  \n",
       "4      0.5  \n",
       "..     ...  \n",
       "687    1.0  \n",
       "688    0.5  \n",
       "689    0.0  \n",
       "690    0.5  \n",
       "691    0.5  \n",
       "\n",
       "[692 rows x 8 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(task_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_id': 'train.56',\n",
       " 'db_id': 'student_assessment',\n",
       " 'question': 'which course has most number of registered students?',\n",
       " 'rationale': ['We need to find out which course has the most number of registered students.',\n",
       "  \"To do this, we will use the 'Student_Course_Registrations' table, which contains the relationship between students and courses.\",\n",
       "  'We will count the number of students registered for each course using COUNT(student_id).',\n",
       "  'We will group the results by course_id to get the count for each course.',\n",
       "  'To find the course with the most students, we will order the results in descending order based on the student count.',\n",
       "  'Finally, we will limit the results to 1 to get only the course with the highest number of registered students.'],\n",
       " 'gold_sql': 'SELECT T1.course_name FROM courses AS T1 JOIN student_course_registrations AS T2 ON T1.course_id = T2.course_Id GROUP BY T1.course_id ORDER BY count(*) DESC LIMIT 1',\n",
       " 'source_tables': ['courses', 'student_course_registrations'],\n",
       " 'pred_sql': 'SELECT course_id, COUNT(student_id) AS student_count \\nFROM Student_Course_Registrations \\nGROUP BY course_id \\nORDER BY student_count DESC \\nLIMIT 1;',\n",
       " 'hint': 'Descriptions:\\n{\\n    \"0\": \"This virtual table provides a list of student details from the \\'Students\\' table for students who have registered for courses. The data is retrieved by joining the \\'Student_Course_Registrations\\' table with the \\'Students\\' table based on the student ID. The results are ordered by the registration date in descending order, and a placeholder is included to limit the number of results returned.\"\\n}\\n'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {\n",
    "    'task': [],\n",
    "    'bo_topk': [], 'bo_level': [], 'bo_desc_vt': [], \n",
    "    'ex_acc': [], 'pm_sel': [], 'pm_cond': [], 'pm_agg': [], 'pm_nest': [], 'pm_oth': [],\n",
    "    'ex_acc_low': [], 'ex_acc_mid': [], 'ex_acc_high': [], 'ex_acc_1': [], 'ex_acc_2': [], 'ex_acc_3+': [],\n",
    "    'pm_sel_low': [], 'pm_sel_mid': [], 'pm_sel_high': [], 'pm_sel_1': [], 'pm_sel_2': [], 'pm_sel_3+': [],\n",
    "    'pm_cond_low': [], 'pm_cond_mid': [], 'pm_cond_high': [], 'pm_cond_1': [], 'pm_cond_2': [], 'pm_cond_3+': [],\n",
    "    'pm_agg_low': [], 'pm_agg_mid': [], 'pm_agg_high': [], 'pm_agg_1': [], 'pm_agg_2': [], 'pm_agg_3+': [],\n",
    "    'pm_nest_low': [], 'pm_nest_mid': [], 'pm_nest_high': [], 'pm_nest_1': [], 'pm_nest_2': [], 'pm_nest_3+': [],\n",
    "    'pm_oth_low': [], 'pm_oth_mid': [], 'pm_oth_high': [], 'pm_oth_1': [], 'pm_oth_2': [], 'pm_oth_3+': [],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# real eval\n",
    "for task in all_tasks:\n",
    "    print(task)\n",
    "    results['task'].append(task)\n",
    "    results['bo_topk'].append(int(task.lstrip('sql_gen_hint_top').split('_')[0]))\n",
    "    results['bo_level'].append(task.lstrip('sql_gen_hint_top').split('_')[1])\n",
    "    results['bo_desc_vt'].append(task.lstrip('sql_gen_hint_top').split('_')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': {'selection': 0.0,\n",
       "  'condition': 1.0,\n",
       "  'aggregation': 0.0,\n",
       "  'nested': 1.0,\n",
       "  'others': 0.5},\n",
       " 'complexity': {'selection': [0.2799999999999999, 0.4705882352941176],\n",
       "  'condition': [0.0, 0.0],\n",
       "  'aggregation': [0.2799999999999999, 0.2799999999999999],\n",
       "  'nested': [0.0, 0.0],\n",
       "  'others': [0.2799999999999999, 0.2799999999999999]}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
