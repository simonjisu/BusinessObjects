{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "proj_path = Path('.').resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cols = ['c_low', 'c_mid', 'c_high', 't_1',  't_2',  't_3+']\n",
    "eval_cols = ['score', 's_sel', 's_cond', 's_agg', 's_nest', 's_oth']\n",
    "\n",
    "df_train = pd.read_csv(proj_path / 'data' / 'split_in_domain' / 'train_origin.csv')\n",
    "df = pd.read_csv(proj_path / 'experiments' / 'bo_evals' / 'all.csv')\n",
    "\n",
    "# check hint\n",
    "no_hint_str = 'Descriptions and Virtual Tables:\\n{}\\n'\n",
    "hint_cols = [f'{test_col}_hint' for test_col in test_cols]\n",
    "df_hint = df.loc[:, hint_cols].apply(lambda x: x != no_hint_str)\n",
    "df_hint.rename(columns={col: f'{col}_exist' for col in hint_cols}, inplace=True)\n",
    "df = pd.concat([df, df_hint], axis=1)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cate_len_tbls\n",
       "1     3412\n",
       "2     1783\n",
       "3+     572\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(['cate_len_tbls']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cate_gold_c\n",
       "high    1434\n",
       "low     2650\n",
       "mid     1683\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby(['cate_gold_c']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cate_len_tbls\n",
       "1     857\n",
       "2     903\n",
       "3+    225\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['cate_len_tbls']).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of db\n",
    "len(set(df['db_id'].drop_duplicates().values.tolist() + df_train['db_id'].drop_duplicates().values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sum      5767.00\n",
       "count    7752.00\n",
       "mean       74.39\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline = (df['score'].agg(['sum', 'count']) + df_train['score'].agg(['sum', 'count']))\n",
    "df_baseline['mean'] = (df_baseline['sum'] / df_baseline['count'] * 100).round(2)\n",
    "df_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>ex_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cate_gold_c</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>low</th>\n",
       "      <td>2650</td>\n",
       "      <td>3167</td>\n",
       "      <td>83.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mid</th>\n",
       "      <td>1683</td>\n",
       "      <td>2357</td>\n",
       "      <td>71.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high</th>\n",
       "      <td>1434</td>\n",
       "      <td>2228</td>\n",
       "      <td>64.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              sum  count  ex_acc\n",
       "cate_gold_c                     \n",
       "low          2650   3167   83.68\n",
       "mid          1683   2357   71.40\n",
       "high         1434   2228   64.36"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_c = (df.groupby(['cate_gold_c'])['score'].agg(['sum', 'count']) + df_train.groupby(['cate_gold_c'])['score'].agg(['sum', 'count']))\n",
    "df_baseline_c['ex_acc'] = (df_baseline_c['sum'] / df_baseline_c['count']*100).round(2)\n",
    "df_baseline_c.reindex(['low', 'mid', 'high'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>ex_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cate_len_tbls</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3412</td>\n",
       "      <td>4269</td>\n",
       "      <td>79.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1783</td>\n",
       "      <td>2686</td>\n",
       "      <td>66.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3+</th>\n",
       "      <td>572</td>\n",
       "      <td>797</td>\n",
       "      <td>71.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                sum  count  ex_acc\n",
       "cate_len_tbls                     \n",
       "1              3412   4269   79.93\n",
       "2              1783   2686   66.38\n",
       "3+              572    797   71.77"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_baseline_t = (df.groupby(['cate_len_tbls'])['score'].agg(['sum', 'count']) + df_train.groupby(['cate_len_tbls'])['score'].agg(['sum', 'count']))\n",
    "df_baseline_t['ex_acc'] = (df_baseline_t['sum'] / df_baseline_t['count']*100).round(2)\n",
    "df_baseline_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>ex_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_low_score</th>\n",
       "      <td>6101</td>\n",
       "      <td>7752</td>\n",
       "      <td>78.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_mid_score</th>\n",
       "      <td>6144</td>\n",
       "      <td>7752</td>\n",
       "      <td>79.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_high_score</th>\n",
       "      <td>6165</td>\n",
       "      <td>7752</td>\n",
       "      <td>79.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_1_score</th>\n",
       "      <td>6107</td>\n",
       "      <td>7752</td>\n",
       "      <td>78.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_2_score</th>\n",
       "      <td>6156</td>\n",
       "      <td>7752</td>\n",
       "      <td>79.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3+_score</th>\n",
       "      <td>6000</td>\n",
       "      <td>7752</td>\n",
       "      <td>77.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               sum  count  ex_acc\n",
       "c_low_score   6101   7752   78.70\n",
       "c_mid_score   6144   7752   79.26\n",
       "c_high_score  6165   7752   79.53\n",
       "t_1_score     6107   7752   78.78\n",
       "t_2_score     6156   7752   79.41\n",
       "t_3+_score    6000   7752   77.40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_overall = df.loc[:, [f'{test_col}_score' for test_col in test_cols]].agg(['sum', 'count']).T\n",
    "df_overall += np.repeat(np.array([len(df_train)]), 2)[None, :]\n",
    "df_overall['ex_acc'] = (df_overall['sum'] * 100 / df_overall['count']).round(2)\n",
    "df_overall['sum'] = df_overall['sum'].astype(int)\n",
    "df_overall['count'] = df_overall['count'].astype(int)\n",
    "df_overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>low</th>\n",
       "      <th>mid</th>\n",
       "      <th>high</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_low_score</th>\n",
       "      <td>87.97</td>\n",
       "      <td>74.97</td>\n",
       "      <td>69.48</td>\n",
       "      <td>78.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_mid_score</th>\n",
       "      <td>86.20</td>\n",
       "      <td>79.17</td>\n",
       "      <td>69.48</td>\n",
       "      <td>79.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_high_score</th>\n",
       "      <td>86.11</td>\n",
       "      <td>76.41</td>\n",
       "      <td>73.47</td>\n",
       "      <td>79.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                low    mid   high  overall\n",
       "c_low_score   87.97  74.97  69.48    78.70\n",
       "c_mid_score   86.20  79.17  69.48    79.26\n",
       "c_high_score  86.11  76.41  73.47    79.53"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_acc(df: pd.DataFrame, df_train: pd.DataFrame, key_column: list[str], key_test_cols: list[str], key_sort_indexs: list[str]):\n",
    "    cols = [f'{test_col}_score' for test_col in key_test_cols]\n",
    "    df_c = df.groupby([key_column])[cols].agg(['count', 'sum']).astype(np.int64)\n",
    "    for c in cols:\n",
    "        df_c[c] = df_c[c] + df_train.groupby([key_column]).size().values[:, None]\n",
    "    df_acc = (df_c.xs('sum', axis=1, level=1) / df_c.xs('count', axis=1, level=1) * 100).round(2)\n",
    "    df_acc = df_acc.reindex(key_sort_indexs)\n",
    "    return df_acc.T\n",
    "\n",
    "key_column = 'cate_gold_c'\n",
    "key_test_cols = ['c_low', 'c_mid', 'c_high']\n",
    "key_sort_indexs = ['low', 'mid', 'high']\n",
    "df_acc_c = get_acc(df, df_train, key_column, key_test_cols, key_sort_indexs)\n",
    "df_acc_c = pd.concat([df_acc_c, df_overall.iloc[:3][['ex_acc']].rename(columns={'ex_acc': 'overall'})], axis=1)\n",
    "df_acc_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3+</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>t_1_score</th>\n",
       "      <td>85.06</td>\n",
       "      <td>69.92</td>\n",
       "      <td>75.03</td>\n",
       "      <td>78.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_2_score</th>\n",
       "      <td>81.96</td>\n",
       "      <td>76.17</td>\n",
       "      <td>76.66</td>\n",
       "      <td>79.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t_3+_score</th>\n",
       "      <td>81.26</td>\n",
       "      <td>70.18</td>\n",
       "      <td>81.05</td>\n",
       "      <td>77.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                1      2     3+  overall\n",
       "t_1_score   85.06  69.92  75.03    78.78\n",
       "t_2_score   81.96  76.17  76.66    79.41\n",
       "t_3+_score  81.26  70.18  81.05    77.40"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_column = 'cate_len_tbls'\n",
    "key_test_cols = ['t_1', 't_2',  't_3+']\n",
    "key_sort_indexs = ['1', '2', '3+']\n",
    "df_acc_t = get_acc(df, df_train, key_column, key_test_cols, key_sort_indexs)\n",
    "df_acc_t = pd.concat([df_acc_t, df_overall.iloc[3:][['ex_acc']].rename(columns={'ex_acc': 'overall'})], axis=1)\n",
    "df_acc_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df_acc_c.reset_index(), df_acc_t.reset_index()], axis=1).to_csv(proj_path / 'experiments' / 'bo_evals' / 'acc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby hints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sample_id', 'db_id', 'question', 'score', 'gold_sql', 'cate_len_tbls',\n",
       "       'cate_gold_c', 'need_high|wrong', 'need_high|correct', 'need_mid|wrong',\n",
       "       'need_mid|correct', 'need_low|wrong', 'need_low|correct',\n",
       "       'need_1|wrong', 'need_1|correct', 'need_2|wrong', 'need_2|correct',\n",
       "       'need_3+|wrong', 'need_3+|correct', 'c_low', 'c_low_hint', 'c_mid',\n",
       "       'c_mid_hint', 'c_high', 'c_high_hint', 't_1', 't_1_hint', 't_2',\n",
       "       't_2_hint', 't_3+', 't_3+_hint', 'c_low_score', 'c_low_s_sel',\n",
       "       'c_low_s_cond', 'c_low_s_agg', 'c_low_s_nest', 'c_low_s_oth',\n",
       "       'c_mid_score', 'c_mid_s_sel', 'c_mid_s_cond', 'c_mid_s_agg',\n",
       "       'c_mid_s_nest', 'c_mid_s_oth', 'c_high_score', 'c_high_s_sel',\n",
       "       'c_high_s_cond', 'c_high_s_agg', 'c_high_s_nest', 'c_high_s_oth',\n",
       "       't_1_score', 't_1_s_sel', 't_1_s_cond', 't_1_s_agg', 't_1_s_nest',\n",
       "       't_1_s_oth', 't_2_score', 't_2_s_sel', 't_2_s_cond', 't_2_s_agg',\n",
       "       't_2_s_nest', 't_2_s_oth', 't_3+_score', 't_3+_s_sel', 't_3+_s_cond',\n",
       "       't_3+_s_agg', 't_3+_s_nest', 't_3+_s_oth', 'c_low_hint_exist',\n",
       "       'c_mid_hint_exist', 'c_high_hint_exist', 't_1_hint_exist',\n",
       "       't_2_hint_exist', 't_3+_hint_exist'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "from src.database import SqliteDatabase\n",
    "from src.eval import result_eq, check_if_exists_orderby\n",
    "from src.eval_complexity import eval_all\n",
    "from src.process_sql import get_schema, Schema\n",
    "from src.parsing_sql import (\n",
    "    extract_selection, \n",
    "    extract_condition, \n",
    "    extract_aggregation, \n",
    "    extract_nested_setoperation, \n",
    "    extract_others,\n",
    "    extract_aliases,\n",
    ")\n",
    "\n",
    "def error_check(proj_path, all_tasks):\n",
    "    error_infos = {\n",
    "        'pred_exec': [],\n",
    "        'result': [],\n",
    "        'parsing_sql': [],\n",
    "        'error_samples': set(),\n",
    "        'empty_hint': set()\n",
    "    }\n",
    "\n",
    "    # filter parsing errors\n",
    "    for task in all_tasks:\n",
    "        with open(proj_path / 'experiments' / f'{task}.jsonl', 'r') as f:\n",
    "            iterator = tqdm(f, desc=task)\n",
    "            for line in iterator:\n",
    "                x = json.loads(line)\n",
    "                if x['hint'] == '':\n",
    "                    error_infos['empty_hint'].add(x['sample_id'])\n",
    "                has_error = False\n",
    "                schema = get_schema(str(proj_path / 'data' / 'spider' / 'database' / x['db_id'] / f'{x[\"db_id\"]}.sqlite'))\n",
    "                schema = Schema(schema)\n",
    "                \n",
    "                parsed_result = {}\n",
    "                for s in ['gold', 'pred']:\n",
    "                    try:\n",
    "                        sql = x[f'{s}_sql']\n",
    "                        statement = sqlparse.parse(sql.strip())[0]\n",
    "                        aliases = extract_aliases(statement)\n",
    "                        selection = extract_selection(statement, aliases, schema)\n",
    "                        condition = extract_condition(statement)\n",
    "                        aggregation = extract_aggregation(statement, aliases, schema)\n",
    "                        nested = extract_nested_setoperation(statement)\n",
    "                        others = extract_others(statement, aliases, schema)\n",
    "                        \n",
    "                        parsed_result[s + '_selection'] = selection\n",
    "                        parsed_result[s + '_condition'] = condition\n",
    "                        parsed_result[s + '_aggregation'] = aggregation\n",
    "                        parsed_result[s + '_nested'] = nested\n",
    "                        parsed_result[s + '_others'] = {\n",
    "                            'distinct': others['distinct'], \n",
    "                            'order by': others['order by'], \n",
    "                            'limit': others['limit']\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        has_error = True\n",
    "                        error_infos['parsing_sql'].append((x['sample_id'], s, str(e)))\n",
    "                        error_infos['error_samples'].add(x['sample_id'])\n",
    "                        break\n",
    "                \n",
    "                if has_error:\n",
    "                    continue\n",
    "\n",
    "                iterator.update()\n",
    "                iterator.set_description_str(f'{task} | error samples {len(error_infos[\"error_samples\"])} | empty hints {len(error_infos[\"empty_hint\"])}')\n",
    "\n",
    "    print(f'Parsing SQL errors: {len(error_infos[\"parsing_sql\"])}')\n",
    "\n",
    "    return error_infos\n",
    "\n",
    "# process single task\n",
    "def process_task(task, error_infos):\n",
    "    task_results = {\n",
    "        'sample_id': [],\n",
    "        'score': [],\n",
    "        's_sel': [], 's_cond': [], 's_agg': [], 's_nest': [], 's_oth': [],\n",
    "    }\n",
    "    with open(proj_path / 'experiments' / f'{task}.jsonl', 'r') as f:\n",
    "        iterator = tqdm(f, desc=task.lstrip('sql_gen_hint_top'))\n",
    "        for line in iterator:\n",
    "            x = json.loads(line)\n",
    "            if x['sample_id'] in error_infos['error_samples']:\n",
    "                continue\n",
    "\n",
    "            task_results['sample_id'].append(x['sample_id'])\n",
    "            # parsing sql\n",
    "            schema = get_schema(str(proj_path / 'data' / 'spider' / 'database' / x['db_id'] / f'{x[\"db_id\"]}.sqlite'))\n",
    "            schema = Schema(schema)\n",
    "            \n",
    "            parsed_result = {}\n",
    "            for s in ['gold', 'pred']:\n",
    "                sql = x[f'{s}_sql']\n",
    "                statement = sqlparse.parse(sql.strip())[0]\n",
    "                aliases = extract_aliases(statement)\n",
    "                selection = extract_selection(statement, aliases, schema)\n",
    "                condition = extract_condition(statement)\n",
    "                aggregation = extract_aggregation(statement, aliases, schema)\n",
    "                nested = extract_nested_setoperation(statement)\n",
    "                others = extract_others(statement, aliases, schema)\n",
    "                \n",
    "                parsed_result[s + '_selection'] = selection\n",
    "                parsed_result[s + '_condition'] = condition\n",
    "                parsed_result[s + '_aggregation'] = aggregation\n",
    "                parsed_result[s + '_nested'] = nested\n",
    "                parsed_result[s + '_others'] = {\n",
    "                    'distinct': others['distinct'], \n",
    "                    'order by': others['order by'], \n",
    "                    'limit': others['limit']\n",
    "                }\n",
    "\n",
    "            # partial & complexity eval\n",
    "            eval_res = eval_all(parsed_result, k=6)\n",
    "            task_results['s_sel'].append(eval_res['score']['selection'])\n",
    "            task_results['s_cond'].append(eval_res['score']['condition'])\n",
    "            task_results['s_agg'].append(eval_res['score']['aggregation'])\n",
    "            task_results['s_nest'].append(eval_res['score']['nested'])\n",
    "            task_results['s_oth'].append(eval_res['score']['others'])\n",
    "            # Execution\n",
    "            database = SqliteDatabase(\n",
    "                str(proj_path / 'data' / 'spider' / 'database' / x['db_id'] / f'{x[\"db_id\"]}.sqlite')\n",
    "            )\n",
    "            error_info = ''\n",
    "            try:\n",
    "                pred_result = database.execute(x['pred_sql'], rt_pandas=False)\n",
    "            except Exception as e:\n",
    "                pred_result = []\n",
    "                error_info = 'Predction Execution Error:' + str(e)\n",
    "                score = 0\n",
    "\n",
    "            try:\n",
    "                gold_result = database.execute(x['gold_sql'], rt_pandas=False)\n",
    "            except Exception as e:\n",
    "                error_info = 'Gold Execution Error:' + str(e)\n",
    "\n",
    "            if 'Gold Execution Error' in error_info:\n",
    "                continue\n",
    "            elif 'Predction Execution Error' in error_info:\n",
    "                task_results['score'].append(score)\n",
    "                continue\n",
    "            else:\n",
    "                exists_orderby = check_if_exists_orderby(x['gold_sql'])\n",
    "                score = int(result_eq(pred_result, gold_result, order_matters=exists_orderby))\n",
    "                task_results['score'].append(score)\n",
    "\n",
    "    return task_results\n",
    "\n",
    "def process_all_exps(proj_path, all_tasks):\n",
    "    error_infos = error_check(proj_path, all_tasks)\n",
    "    for task in all_tasks:\n",
    "        task_results = process_task(task, error_infos)\n",
    "        pd.DataFrame(task_results).to_csv(proj_path / 'experiments' / 'bo_evals' / f'{task}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove trainset error samples when parsing\n",
    "train_error_infos = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tasks = []\n",
    "typ = '_c'  # '_c'\n",
    "iterator = ['low', 'mid', 'high'] if typ == '_c' else ['1', '2', '3+']\n",
    "for typ2 in ['desc', 'descvt']:        \n",
    "    for n_retrieval in [1, 3]:\n",
    "        for level in iterator:\n",
    "            all_tasks.append(f'sql_gen_hint_top{n_retrieval}_{level}_{typ2}')\n",
    "\n",
    "# process_all_exps(proj_path, all_tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlparse\n",
    "def additional_tables(proj_path, task, df: pd.DataFrame):\n",
    "    df1 = pd.read_csv(proj_path / 'experiments' / 'evals' / 'spider_train_eval_plus.csv')\n",
    "    df1['sample_id'] = 'train.' + df1['sample_id'].astype(str)\n",
    "    df2 = pd.read_csv(proj_path / 'experiments' / 'evals' / 'spider_dev_eval_plus.csv')\n",
    "    df2['sample_id'] = 'dev.' + df2['sample_id'].astype(str)\n",
    "    df3 = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "    df3['previous_pred_sql'] = df3['pred_sql'].apply(lambda x: sqlparse.format(x, reindent=True))\n",
    "    \n",
    "    data = []\n",
    "    with open(proj_path / 'experiments' / f'{task}.jsonl') as f:\n",
    "        for line in f:\n",
    "            data.append(json.loads(line))\n",
    "    df4 = pd.DataFrame(data)\n",
    "    df4['gold_sql'] = df4['gold_sql'].apply(lambda x: sqlparse.format(x, reindent=True))\n",
    "    df4['pred_sql'] = df4['pred_sql'].apply(lambda x: sqlparse.format(x, reindent=True))\n",
    "\n",
    "    df5 = pd.merge(\n",
    "        left=df.loc[:, ['sample_id', 'score', 'cate_len_tbls', 'cate_gold_c', 's_sel', 's_cond', 's_agg', 's_nest', 's_oth']], \n",
    "        right=df4.loc[:, ['sample_id', 'db_id', 'hint', 'gold_sql', 'pred_sql']], \n",
    "        on='sample_id', how='left')\n",
    "    df6 = pd.merge(\n",
    "        left=df5, \n",
    "        right=df3.loc[:, ['sample_id', 'previous_pred_sql']],\n",
    "        on='sample_id', how='left')\n",
    "    with pd.ExcelWriter(proj_path / 'experiments' / 'bo_evals' / 'additional' / f'{task}.xlsx') as writer:\n",
    "        df6.to_excel(writer, sheet_name='task', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sql_gen_hint_top1_1_desc\n",
      "sql_gen_hint_top1_2_desc\n",
      "sql_gen_hint_top1_3+_desc\n",
      "sql_gen_hint_top3_1_desc\n",
      "sql_gen_hint_top3_2_desc\n",
      "sql_gen_hint_top3_3+_desc\n",
      "sql_gen_hint_top1_1_descvt\n",
      "sql_gen_hint_top1_2_descvt\n",
      "sql_gen_hint_top1_3+_descvt\n",
      "sql_gen_hint_top3_1_descvt\n",
      "sql_gen_hint_top3_2_descvt\n",
      "sql_gen_hint_top3_3+_descvt\n"
     ]
    }
   ],
   "source": [
    "# real eval\n",
    "typ = '_t' # '_t', '_c'\n",
    "iterator = ['low', 'mid', 'high'] if typ == '_c' else ['1', '2', '3+']\n",
    "all_tasks = []\n",
    "for typ2 in ['desc', 'descvt']:        \n",
    "    for n_retrieval in [1, 3]:\n",
    "        for level in iterator:\n",
    "            all_tasks.append(f'sql_gen_hint_top{n_retrieval}_{level}_{typ2}')\n",
    "\n",
    "col = 'cate_gold_c' if typ == '_c' else 'cate_len_tbls'\n",
    "results = {\n",
    "    'bo_topk': [], 'bo_level': [], 'bo_desc_vt': [], \n",
    "    'count': [], 'ex_acc': [], 'pm_sel': [], 'pm_cond': [], 'pm_agg': [], 'pm_nest': [], 'pm_oth': [],\n",
    "}\n",
    "for l in iterator:\n",
    "    results[f'ex_acc_{l}'] = []\n",
    "    results[f'count_{l}'] = []\n",
    "    for c in ['sel', 'cond', 'agg', 'nest', 'oth']:\n",
    "        results[f'pm_{c}_{l}'] = []\n",
    "\n",
    "df_test = pd.read_csv(proj_path / 'data' / 'split_in_domain' / f'bo{typ}_eval.csv')\n",
    "baseline = df_test.groupby(col)[['score', 's_sel', 's_cond', 's_agg', 's_nest', 's_oth']].mean() * 100\n",
    "\n",
    "for task in all_tasks:\n",
    "    print(task)\n",
    "    # results['task'].append(task)\n",
    "    results['bo_topk'].append(int(task.lstrip('sql_gen_hint_top').split('_')[0]))\n",
    "    results['bo_level'].append(task.lstrip('sql_gen_hint_top').split('_')[1])\n",
    "    results['bo_desc_vt'].append(task.lstrip('sql_gen_hint_top').split('_')[2])\n",
    "\n",
    "    df = pd.read_csv(proj_path / 'experiments' / 'bo_evals' / f'{task}.csv')\n",
    "    df = pd.merge(df, df_test.loc[:, ['sample_id', 'cate_len_tbls', 'cate_gold_c']], on='sample_id', how='left')\n",
    "\n",
    "    results['count'].append(df.shape[0])\n",
    "    results['ex_acc'].append(df['score'].mean()*100)\n",
    "    results['pm_sel'].append((df['s_sel'].mean() - df_test['s_sel'].mean())*100)\n",
    "    results['pm_cond'].append((df['s_cond'].mean() - df_test['s_cond'].mean())*100)\n",
    "    results['pm_agg'].append((df['s_agg'].mean() - df_test['s_agg'].mean())*100)\n",
    "    results['pm_nest'].append((df['s_nest'].mean() - df_test['s_nest'].mean())*100)\n",
    "    results['pm_oth'].append((df['s_oth'].mean() - df_test['s_oth'].mean())*100)\n",
    "\n",
    "    g_score = df.groupby(col)[['score', 's_sel', 's_cond', 's_agg', 's_nest', 's_oth']].mean() * 100 - baseline\n",
    "    for l in iterator:\n",
    "        results[f'ex_acc_{l}'].append(g_score.loc[l, 'score'])\n",
    "        results[f'count_{l}'].append(df[df[col] == l].shape[0])\n",
    "        for c in ['s_sel', 's_cond', 's_agg', 's_nest', 's_oth']:\n",
    "            results[f'pm_{c[2:]}_{l}'].append(g_score.loc[l, c])\n",
    "\n",
    "    if task.lstrip('sql_gen_hint_top').split('_')[2] == 'descvt' and int(task.lstrip('sql_gen_hint_top').split('_')[0]) == 3:\n",
    "        additional_tables(proj_path, task, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "# df.set_index(['bo_topk','bo_desc_vt', 'bo_level'], inplace=True)\n",
    "desc_vt = {'desc': 'BA', 'descvt': 'BA + VT'}\n",
    "df['bo_desc_vt'] = df['bo_desc_vt'].map(desc_vt)\n",
    "df['bo_level'] = df['bo_level'].str.capitalize()\n",
    "\n",
    "idx_cols = ['bo_topk','bo_desc_vt', 'bo_level']\n",
    "count_cols = ['count', 'count_low', 'count_mid', 'count_high'] if typ == '_c' else ['count', 'count_1', 'count_2', 'count_3+']\n",
    "r1 = ['ex_acc_low', 'ex_acc_mid', 'ex_acc_high', 'ex_acc'] if typ == '_c' else ['ex_acc_1', 'ex_acc_2', 'ex_acc_3+', 'ex_acc']\n",
    "r2 = ['pm_sel', 'pm_cond', 'pm_agg', 'pm_nest', 'pm_oth'] if typ == '_c' else ['pm_sel', 'pm_cond', 'pm_agg', 'pm_nest', 'pm_oth']\n",
    "r3 = ['pm_sel_low', 'pm_sel_mid', 'pm_sel_high'] if typ == '_c' else ['pm_sel_1', 'pm_sel_2', 'pm_sel_3+']\n",
    "r4 = ['pm_cond_low', 'pm_cond_mid', 'pm_cond_high'] if typ == '_c' else ['pm_cond_1', 'pm_cond_2', 'pm_cond_3+']\n",
    "r5 = ['pm_agg_low', 'pm_agg_mid', 'pm_agg_high'] if typ == '_c' else ['pm_agg_1', 'pm_agg_2', 'pm_agg_3+']\n",
    "r6 = ['pm_nest_low', 'pm_nest_mid', 'pm_nest_high'] if typ == '_c' else ['pm_nest_1', 'pm_nest_2', 'pm_nest_3+']\n",
    "r7 = ['pm_oth_low', 'pm_oth_mid', 'pm_oth_high'] if typ == '_c' else ['pm_oth_1', 'pm_oth_2', 'pm_oth_3+']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter(proj_path / 'experiments' / 'reports' / f'bo_eval{typ}.xlsx') as writer:\n",
    "    df.loc[:, idx_cols+count_cols].to_excel(writer, sheet_name='count')\n",
    "\n",
    "    df1 = df.loc[:, idx_cols+r1].round(2)\n",
    "    rename_cols = {\n",
    "        'bo_topk': 'Top-K', 'bo_desc_vt': 'Prompt Type',\n",
    "        'bo_level': 'Complexity Lv.' if typ == '_c' else 'Table Num.',\n",
    "        'ex_acc': 'Overall',\n",
    "    }\n",
    "    for l in iterator:\n",
    "        rename_cols[f'ex_acc_{l}'] = f'{l.capitalize()}'\n",
    "    df1.rename(columns=rename_cols, inplace=True)\n",
    "    df1.to_excel(writer, sheet_name='ex_acc', index=False)\n",
    "\n",
    "    df2 = df.loc[:, idx_cols+r2].round(2)\n",
    "    \n",
    "    df2.rename(columns={\n",
    "        'bo_topk': 'Top-K', 'bo_desc_vt': 'Prompt Type',\n",
    "        'bo_level': 'Complexity Lv.' if typ == '_c' else 'Table Num.',\n",
    "        'pm_sel': 'Selection',\n",
    "        'pm_cond': 'Condition',\n",
    "        'pm_agg': 'Aggregation',\n",
    "        'pm_nest': 'Nested',\n",
    "        'pm_oth': 'Others',\n",
    "    }, inplace=True)\n",
    "    df2.to_excel(writer, sheet_name='pm', index=False)\n",
    "\n",
    "    df3 = df.loc[:, idx_cols+r3+r4+r5+r6+r7].round(2)\n",
    "    rename_cols = {\n",
    "        'bo_topk': 'Top-K', 'bo_desc_vt': 'Prompt Type',\n",
    "        'bo_level': 'Complexity Lv.' if typ == '_c' else 'Table Num.',\n",
    "    }\n",
    "    for l in iterator:\n",
    "        for c in ['sel', 'cond', 'agg', 'nest', 'oth']:\n",
    "            rename_cols[f'pm_{c}_{l}'] = f'{c.capitalize()} {l.capitalize()}'\n",
    "    df3.rename(columns=rename_cols, inplace=True)\n",
    "    df3.to_excel(writer, sheet_name='pm_detail', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(proj_path / 'experiments' / 'evals' / 'spider_train_eval_plus.csv')\n",
    "df1['sample_id'] = 'train.' + df1['sample_id'].astype(str)\n",
    "df2 = pd.read_csv(proj_path / 'experiments' / 'evals' / 'spider_dev_eval_plus.csv')\n",
    "df2['sample_id'] = 'dev.' + df2['sample_id'].astype(str)\n",
    "df = pd.concat([df1, df2]).reset_index(drop=True)\n",
    "\n",
    "df.to_csv(proj_path / 'experiments' / 'bo_evals' / 'additional' / f'all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.387\n",
      "Show origins of all flights with destination Honolulu.\n",
      "SELECT origin\n",
      "FROM Flight\n",
      "WHERE destination = 'Honolulu'\n",
      "\n",
      "train.388\n",
      "What are the origins of all flights that are headed to Honolulu?\n",
      "SELECT origin\n",
      "FROM Flight\n",
      "WHERE destination = 'Honolulu'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, x in df.loc[df['sample_id'].isin(['train.388', 'train.387'])].iterrows():\n",
    "    print(x['sample_id'])\n",
    "    print(x['question'])\n",
    "    print(sqlparse.format(x['gold_sql'], reindent=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>question</th>\n",
       "      <th>gold_sql</th>\n",
       "      <th>pred_sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>train.380</td>\n",
       "      <td>What is the id and salary of the employee name...</td>\n",
       "      <td>SELECT eid ,  salary FROM Employee WHERE name ...</td>\n",
       "      <td>SELECT eid, salary FROM employee WHERE name = ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>train.381</td>\n",
       "      <td>How many flights do we have?</td>\n",
       "      <td>SELECT count(*) FROM Flight</td>\n",
       "      <td>SELECT COUNT(*) AS total_flights FROM flight;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>train.382</td>\n",
       "      <td>What is the number of flights?</td>\n",
       "      <td>SELECT count(*) FROM Flight</td>\n",
       "      <td>SELECT COUNT(*) AS number_of_flights FROM flight;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>train.383</td>\n",
       "      <td>Show flight number, origin, destination of all...</td>\n",
       "      <td>SELECT flno ,  origin ,  destination FROM Flig...</td>\n",
       "      <td>SELECT flno, origin, destination FROM flight O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>train.384</td>\n",
       "      <td>What is the flight number, origin, and destina...</td>\n",
       "      <td>SELECT flno ,  origin ,  destination FROM Flig...</td>\n",
       "      <td>SELECT flno, origin, destination FROM flight O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>train.385</td>\n",
       "      <td>Show all flight number from Los Angeles.</td>\n",
       "      <td>SELECT flno FROM Flight WHERE origin  =  'Los ...</td>\n",
       "      <td>SELECT flno FROM flight WHERE origin = 'Los An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>train.386</td>\n",
       "      <td>What are the numbers of all flights coming fro...</td>\n",
       "      <td>SELECT flno FROM Flight WHERE origin  =  'Los ...</td>\n",
       "      <td>SELECT flno FROM flight WHERE origin = 'Los An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>train.387</td>\n",
       "      <td>Show origins of all flights with destination H...</td>\n",
       "      <td>SELECT origin FROM Flight WHERE destination  =...</td>\n",
       "      <td>SELECT DISTINCT origin FROM flight WHERE desti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>train.388</td>\n",
       "      <td>What are the origins of all flights that are h...</td>\n",
       "      <td>SELECT origin FROM Flight WHERE destination  =...</td>\n",
       "      <td>SELECT DISTINCT origin FROM flight WHERE desti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>train.389</td>\n",
       "      <td>Show me the departure date and arrival date fo...</td>\n",
       "      <td>SELECT departure_date ,  arrival_date FROM Fli...</td>\n",
       "      <td>SELECT departure_date, arrival_date FROM fligh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>train.390</td>\n",
       "      <td>What are the departure and arrival dates of al...</td>\n",
       "      <td>SELECT departure_date ,  arrival_date FROM Fli...</td>\n",
       "      <td>SELECT departure_date, arrival_date FROM fligh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample_id                                           question  \\\n",
       "370  train.380  What is the id and salary of the employee name...   \n",
       "371  train.381                       How many flights do we have?   \n",
       "372  train.382                     What is the number of flights?   \n",
       "373  train.383  Show flight number, origin, destination of all...   \n",
       "374  train.384  What is the flight number, origin, and destina...   \n",
       "375  train.385           Show all flight number from Los Angeles.   \n",
       "376  train.386  What are the numbers of all flights coming fro...   \n",
       "377  train.387  Show origins of all flights with destination H...   \n",
       "378  train.388  What are the origins of all flights that are h...   \n",
       "379  train.389  Show me the departure date and arrival date fo...   \n",
       "380  train.390  What are the departure and arrival dates of al...   \n",
       "\n",
       "                                              gold_sql  \\\n",
       "370  SELECT eid ,  salary FROM Employee WHERE name ...   \n",
       "371                        SELECT count(*) FROM Flight   \n",
       "372                        SELECT count(*) FROM Flight   \n",
       "373  SELECT flno ,  origin ,  destination FROM Flig...   \n",
       "374  SELECT flno ,  origin ,  destination FROM Flig...   \n",
       "375  SELECT flno FROM Flight WHERE origin  =  'Los ...   \n",
       "376  SELECT flno FROM Flight WHERE origin  =  'Los ...   \n",
       "377  SELECT origin FROM Flight WHERE destination  =...   \n",
       "378  SELECT origin FROM Flight WHERE destination  =...   \n",
       "379  SELECT departure_date ,  arrival_date FROM Fli...   \n",
       "380  SELECT departure_date ,  arrival_date FROM Fli...   \n",
       "\n",
       "                                              pred_sql  \n",
       "370  SELECT eid, salary FROM employee WHERE name = ...  \n",
       "371      SELECT COUNT(*) AS total_flights FROM flight;  \n",
       "372  SELECT COUNT(*) AS number_of_flights FROM flight;  \n",
       "373  SELECT flno, origin, destination FROM flight O...  \n",
       "374  SELECT flno, origin, destination FROM flight O...  \n",
       "375  SELECT flno FROM flight WHERE origin = 'Los An...  \n",
       "376  SELECT flno FROM flight WHERE origin = 'Los An...  \n",
       "377  SELECT DISTINCT origin FROM flight WHERE desti...  \n",
       "378  SELECT DISTINCT origin FROM flight WHERE desti...  \n",
       "379  SELECT departure_date, arrival_date FROM fligh...  \n",
       "380  SELECT departure_date, arrival_date FROM fligh...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[370:380, ['sample_id', 'question', 'gold_sql', 'pred_sql']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
