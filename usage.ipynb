{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "proj_path = Path('.').resolve()\n",
    "sys.path.append(str(proj_path))\n",
    "\n",
    "import sqlglot\n",
    "import numpy as np\n",
    "from sqlglot import expressions as exp\n",
    "from src.parsing_sql import Schema, extract_all\n",
    "from src.eval_utils import (\n",
    "    partial_match, \n",
    "    compute_tsed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {'lists': {'user_id': 'text',\n",
    "  'list_id': 'text',\n",
    "  'list_title': 'text',\n",
    "  'list_movie_number': 'text',\n",
    "  'list_update_timestamp_utc': 'text',\n",
    "  'list_creation_timestamp_utc': 'text',\n",
    "  'list_followers': 'text',\n",
    "  'list_url': 'text',\n",
    "  'list_comments': 'text',\n",
    "  'list_description': 'text',\n",
    "  'list_cover_image_url': 'text',\n",
    "  'list_first_image_url': 'text',\n",
    "  'list_second_image_url': 'text',\n",
    "  'list_third_image_url': 'text'},\n",
    " 'movies': {'movie_id': 'integer',\n",
    "  'movie_title': 'integer',\n",
    "  'movie_release_year': 'integer',\n",
    "  'movie_url': 'integer',\n",
    "  'movie_title_language': 'integer',\n",
    "  'movie_popularity': 'integer',\n",
    "  'movie_image_url': 'integer',\n",
    "  'director_id': 'integer',\n",
    "  'director_name': 'integer',\n",
    "  'director_url': 'integer'},\n",
    " 'ratings_users': {'user_id': 'integer',\n",
    "  'rating_date_utc': 'integer',\n",
    "  'user_trialist': 'integer',\n",
    "  'user_subscriber': 'integer',\n",
    "  'user_avatar_image_url': 'integer',\n",
    "  'user_cover_image_url': 'integer',\n",
    "  'user_eligible_for_trial': 'integer',\n",
    "  'user_has_payment_method': 'integer'},\n",
    " 'lists_users': {'user_id': 'text',\n",
    "  'list_id': 'text',\n",
    "  'list_update_date_utc': 'text',\n",
    "  'list_creation_date_utc': 'text',\n",
    "  'user_trialist': 'text',\n",
    "  'user_subscriber': 'text',\n",
    "  'user_avatar_image_url': 'text',\n",
    "  'user_cover_image_url': 'text',\n",
    "  'user_eligible_for_trial': 'text',\n",
    "  'user_has_payment_method': 'text'},\n",
    " 'ratings': {'movie_id': 'integer',\n",
    "  'rating_id': 'integer',\n",
    "  'rating_url': 'integer',\n",
    "  'rating_score': 'integer',\n",
    "  'rating_timestamp_utc': 'integer',\n",
    "  'critic': 'integer',\n",
    "  'critic_likes': 'integer',\n",
    "  'critic_comments': 'integer',\n",
    "  'user_id': 'integer',\n",
    "  'user_trialist': 'integer',\n",
    "  'user_subscriber': 'integer',\n",
    "  'user_eligible_for_trial': 'integer',\n",
    "  'user_has_payment_method': 'integer'}}\n",
    "\n",
    "sqls = \"\"\"\n",
    "SELECT movie_release_year FROM movies WHERE movie_title = 'Cops'\n",
    "SELECT T1.user_id FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE rating_score = 4 AND rating_timestamp_utc LIKE '2013-05-04 06:33:32' AND T2.movie_title LIKE 'Freaks'\n",
    "SELECT T1.user_trialist FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'A Way of Life' AND T1.user_id = 39115684\n",
    "SELECT T2.movie_title FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T1.rating_timestamp_utc LIKE '2020%' GROUP BY T2.movie_title ORDER BY COUNT(T2.movie_title) DESC LIMIT 1\n",
    "SELECT AVG(T1.rating_score), T2.director_name FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'When Will I Be Loved'\n",
    "\"\"\"\n",
    "schema = Schema(schema_dict)\n",
    "sqls = [s.strip() for s in sqls.strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parsing_sql import (\n",
    "    extract_aliases,\n",
    "    extract_condition,\n",
    "    get_subqueries,\n",
    "    _extract_conditions,\n",
    "    _extract_columns_from_expression,\n",
    "    _determine_tag,\n",
    "    _format_expression,\n",
    "    _get_full_column_name,\n",
    "    extract_aliases,\n",
    "    extract_selection,\n",
    "    extract_aggregation,\n",
    "    extract_orderby,\n",
    "    extract_others,\n",
    "    \n",
    "    _extract_aliases_from_select,\n",
    "    _handle_table_or_subquery\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sql in sqls:\n",
    "    parsed_sql = sqlglot.parse_one(sql)\n",
    "    output = extract_all(parsed_sql, schema)\n",
    "    # print\n",
    "    print('SQL:', sql)\n",
    "    print('# Selection')\n",
    "    print(f'  unique columns: {output[\"sel\"]}')\n",
    "    for i, ast in enumerate(output['sel_asts']):\n",
    "        print(f' [{i}] type: {ast[2]}')\n",
    "        print(f' [{i}] ast:')\n",
    "        print('  ' + repr(ast[1]))\n",
    "    if output['cond_asts']:\n",
    "        print('\\n# condition')\n",
    "        print(f'  operations: {output[\"op_types\"]}')\n",
    "        for i, ast in enumerate(output['cond_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    if output['agg_asts']:\n",
    "        print('\\n# aggregation')\n",
    "        print(f'  unique columns: {output[\"agg\"]}')\n",
    "        for i, ast in enumerate(output['agg_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    if output['orderby_asts']:\n",
    "        print('\\n# orderby')\n",
    "        print(f'  unique columns: {output[\"orderby\"]}')\n",
    "        for i, ast in enumerate(output['group_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    \n",
    "    if output['nested']:\n",
    "        print('\\n# nested')\n",
    "        print(f'  number of nested: {output[\"nested\"]}')\n",
    "        # check the `output['subqueries']` if you waht to see the nested queries\n",
    "        # first one is the original query\n",
    "    if output['distinct']:\n",
    "        print(f'\\n# distinct: {output[\"distinct\"]}')\n",
    "    if output['limit']:\n",
    "        print(f'\\n# limit: {output[\"limit\"]}')\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SQL1]\n",
      " SELECT\n",
      "  ratings.user_id\n",
      "FROM ratings AS T1\n",
      "INNER JOIN movies AS T2\n",
      "  ON T1.movie_id = T2.movie_id\n",
      "WHERE\n",
      "  ratings.rating_score = [placeholder-type:numeric]\n",
      "  AND ratings.rating_timestamp_utc LIKE '[placeholder-type:string]'\n",
      "  AND movies.movie_title LIKE '[placeholder-type:string]'\n",
      "\n",
      "[SQL2]\n",
      " SELECT\n",
      "  ratings.user_id,\n",
      "  COUNT(movies.movie_title)\n",
      "FROM ratings AS T1\n",
      "INNER JOIN movies AS T2\n",
      "  ON T1.movie_id = T2.movie_id\n",
      "GROUP BY\n",
      "  ratings.user_id\n",
      "HAVING\n",
      "  COUNT(movies.movie_title) > [placeholder-type:numeric]\n",
      "ORDER BY\n",
      "  COUNT(movies.movie_title)\n",
      "\n",
      "TSED: 0.4634\n",
      "Tree Edit Distance: 22\n",
      "Partial Match Score\n",
      "  Selection: 0.5000\n",
      "  Condition: 0.2222\n",
      "  Aggregation: 0.0\n",
      "  Orderby: 0.0\n",
      "  Nested: 1.0\n",
      "  Distinct: 1.0\n",
      "  Limit: 1.0\n"
     ]
    }
   ],
   "source": [
    "import sqlglot\n",
    "\n",
    "sql1 = \"\"\"SELECT T1.USER_ID \n",
    "FROM ratings AS T1 \n",
    "INNER JOIN movies AS T2 \n",
    "ON T1.movie_id = T2.movie_id \n",
    "WHERE \n",
    "    rating_score = 4 \n",
    "    AND rating_timestamp_utc LIKE '2013-05-04 06:33:32' \n",
    "    AND T2.movie_title LIKE 'Freaks'\n",
    "\"\"\"\n",
    "\n",
    "sql2 = \"\"\"SELECT T1.user_id, COUNT(T2.movie_title)\n",
    "FROM ratings AS T1 \n",
    "INNER JOIN movies AS T2 \n",
    "ON T1.movie_id = T2.movie_id \n",
    "GROUP BY T1.user_id\n",
    "HAVING COUNT(T2.movie_title) > 1\n",
    "ORDER BY COUNT(T2.movie_title) DESC\n",
    "\"\"\"\n",
    "\n",
    "# sql1 = \"\"\"SELECT\n",
    "#   COUNT(*) AS late_line_items_count, (SUM(lineitem.L_EXTENDEDPRICE * lineitem.L_DISCOUNT) / 100) AS revenue\n",
    "# FROM LINEITEM\n",
    "# WHERE\n",
    "#   lineitem.L_RECEIPTDATE > lineitem.L_COMMITDATE\n",
    "#   AND STRFTIME('%Y', lineitem.L_RECEIPTDATE) = 'abcd'\"\"\"\n",
    "\n",
    "# sql2 = \"\"\"SELECT\n",
    "#   COUNT(*) AS count\n",
    "# FROM lineitem\n",
    "# WHERE\n",
    "#   lineitem.l_commitdate < lineitem.l_receiptdate\n",
    "#   AND lineitem.l_receiptdate >= '1993-01-01'\n",
    "#   AND lineitem.l_receiptdate < '1994-01-01'\"\"\"\n",
    "\n",
    "sql1 = sqlglot.parse_one(sql1)  # prediction\n",
    "sql2 = sqlglot.parse_one(sql2)  # target\n",
    "output1 = extract_all(sql1, schema)\n",
    "output2 = extract_all(sql2, schema)\n",
    "\n",
    "print('[SQL1]\\n', sql1.sql(pretty=True))\n",
    "print()\n",
    "print('[SQL2]\\n', sql2.sql(pretty=True))\n",
    "print()\n",
    "tsed, distance = compute_tsed(sql1, sql2, build_type='apted')  # apted or zss\n",
    "print(f'TSED: {tsed:.4f}')\n",
    "print(f'Tree Edit Distance: {distance}')\n",
    "\n",
    "\n",
    "# partial match\n",
    "print('Partial Match Score')\n",
    "sel_score = []\n",
    "for sel_ast1 in output1['sel_asts']:\n",
    "    for sel_ast2 in output2['sel_asts']:\n",
    "        tsed, distance = compute_tsed(sel_ast1[1], sel_ast2[1], build_type='apted')\n",
    "        sel_score.append(tsed)\n",
    "print(f'  Selection: {np.mean(sel_score):.4f}')\n",
    "\n",
    "if output1['cond_asts'] and output2['cond_asts']:\n",
    "    # both have conditions\n",
    "    cond_score = []\n",
    "    for cond_ast1 in output1['cond_asts']:\n",
    "        for cond_ast2 in output2['cond_asts']:\n",
    "            tsed, distance = compute_tsed(cond_ast1[1], cond_ast2[1], build_type='apted')\n",
    "            cond_score.append(tsed)\n",
    "    print(f'  Condition: {np.mean(cond_score):.4f}')\n",
    "elif output2['cond_asts']:\n",
    "    # target has condition\n",
    "    if not output1['cond_asts']:\n",
    "        # prediction has no condition\n",
    "        print(f'  Condition: {0.0}')\n",
    "else:\n",
    "    # both have no conditions\n",
    "    print(f'  Condition: {1.0}')\n",
    "\n",
    "if output1['agg_asts'] and output2['agg_asts']:\n",
    "    # both have aggregation\n",
    "    agg_score = []\n",
    "    for agg_ast1 in output1['agg_asts']:\n",
    "        for agg_ast2 in output2['agg_asts']:\n",
    "            tsed, distance = compute_tsed(agg_ast1[1], agg_ast2[1], build_type='apted')\n",
    "            agg_score.append(tsed)\n",
    "    print(f'  Aggregation: {np.mean(agg_score):.4f}')\n",
    "elif output2['agg_asts']:\n",
    "    # target has aggregation\n",
    "    if not output1['agg_asts']:\n",
    "        # prediction has no aggregation\n",
    "        print(f'  Aggregation: {0.0}')\n",
    "else:\n",
    "    # both have no aggregation\n",
    "    print(f'  Aggregation: {1.0}')\n",
    "\n",
    "if output1['orderby_asts'] and output2['orderby_asts']:\n",
    "    # both have orderby\n",
    "    orderby_score = []\n",
    "    for orderby_ast1 in output1['orderby_asts']:\n",
    "        for orderby_ast2 in output2['orderby_asts']:\n",
    "            tsed, distance = compute_tsed(orderby_ast1[1], orderby_ast2[1], build_type='apted')\n",
    "            orderby_score.append(tsed)\n",
    "    print(f'  Orderby: {np.mean(orderby_score):.4f}')\n",
    "elif output2['orderby_asts']:\n",
    "    # target has orderby\n",
    "    if not output1['orderby_asts']:\n",
    "        # prediction has no orderby\n",
    "        print(f'  Orderby: {0.0}')\n",
    "else:\n",
    "    # both have no orderby\n",
    "    print('  Orderby: 1.0 (no orderby)')\n",
    "\n",
    "if output1['subqueries'][1:] and output2['subqueries'][1:]:\n",
    "    # both have nested queries\n",
    "    nested_score = []\n",
    "    for nested_ast1 in output1['subqueries'][1:]:\n",
    "        for nested_ast2 in output2['subqueries'][1:]:\n",
    "            tsed, distance = compute_tsed(nested_ast1, nested_ast2, build_type='apted')\n",
    "            nested_score.append(tsed)\n",
    "    print(f'  Nested: {np.mean(nested_score):.4f}')\n",
    "elif output2['subqueries'][1:]:\n",
    "    # target has nested queries\n",
    "    if not output1['subqueries'][1:]:\n",
    "        # prediction has no nested queries\n",
    "        print(f'  Nested: {0.0}')\n",
    "else:\n",
    "    # both have no nested queries\n",
    "    print(f'  Nested: {1.0}')\n",
    "\n",
    "if output1['distinct'] and output2['distinct']:\n",
    "    # both have distinct\n",
    "    print(f'  Distinct: 1.0')\n",
    "elif output2['distinct']:\n",
    "    # target has distinct\n",
    "    if not output1['distinct']:\n",
    "        # prediction has no distinct\n",
    "        print(f'  Distinct: 0.0')\n",
    "else:\n",
    "    # both have no distinct\n",
    "    print(f'  Distinct: {1.0}')\n",
    "\n",
    "if output1['limit'] and output2['limit']:\n",
    "    # both have limit\n",
    "    print(f'  Limit: 1.0')\n",
    "elif output2['limit']:\n",
    "    # target has limit\n",
    "    if not output1['limit']:\n",
    "        # prediction has no limit\n",
    "        print(f'  Limit: 0.0')\n",
    "else:\n",
    "    # both have no limit\n",
    "    print(f'  Limit: {1.0}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
