{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "proj_path = Path('.').resolve()\n",
    "sys.path.append(str(proj_path))\n",
    "\n",
    "import sqlglot\n",
    "import numpy as np\n",
    "from sqlglot import expressions as exp\n",
    "from src.parsing_sql import Schema, extract_all\n",
    "from src.eval_utils import (\n",
    "    partial_match, \n",
    "    compute_tsed\n",
    ")\n",
    "\n",
    "from src.parsing_sql import (\n",
    "    extract_aliases,\n",
    "    extract_condition,\n",
    "    get_subqueries,\n",
    "    _extract_conditions,\n",
    "    _extract_columns_from_expression,\n",
    "    _determine_tag,\n",
    "    _format_expression,\n",
    "    _get_full_column_name,\n",
    "    extract_aliases,\n",
    "    extract_selection,\n",
    "    extract_aggregation,\n",
    "    extract_orderby,\n",
    "    extract_others,\n",
    "    \n",
    "    _extract_aliases_from_select,\n",
    "    _handle_table_or_subquery\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {'lists': {'user_id': 'text',\n",
    "  'list_id': 'text',\n",
    "  'list_title': 'text',\n",
    "  'list_movie_number': 'text',\n",
    "  'list_update_timestamp_utc': 'text',\n",
    "  'list_creation_timestamp_utc': 'text',\n",
    "  'list_followers': 'text',\n",
    "  'list_url': 'text',\n",
    "  'list_comments': 'text',\n",
    "  'list_description': 'text',\n",
    "  'list_cover_image_url': 'text',\n",
    "  'list_first_image_url': 'text',\n",
    "  'list_second_image_url': 'text',\n",
    "  'list_third_image_url': 'text'},\n",
    " 'movies': {'movie_id': 'integer',\n",
    "  'movie_title': 'integer',\n",
    "  'movie_release_year': 'integer',\n",
    "  'movie_url': 'integer',\n",
    "  'movie_title_language': 'integer',\n",
    "  'movie_popularity': 'integer',\n",
    "  'movie_image_url': 'integer',\n",
    "  'director_id': 'integer',\n",
    "  'director_name': 'integer',\n",
    "  'director_url': 'integer'},\n",
    " 'ratings_users': {'user_id': 'integer',\n",
    "  'rating_date_utc': 'integer',\n",
    "  'user_trialist': 'integer',\n",
    "  'user_subscriber': 'integer',\n",
    "  'user_avatar_image_url': 'integer',\n",
    "  'user_cover_image_url': 'integer',\n",
    "  'user_eligible_for_trial': 'integer',\n",
    "  'user_has_payment_method': 'integer'},\n",
    " 'lists_users': {'user_id': 'text',\n",
    "  'list_id': 'text',\n",
    "  'list_update_date_utc': 'text',\n",
    "  'list_creation_date_utc': 'text',\n",
    "  'user_trialist': 'text',\n",
    "  'user_subscriber': 'text',\n",
    "  'user_avatar_image_url': 'text',\n",
    "  'user_cover_image_url': 'text',\n",
    "  'user_eligible_for_trial': 'text',\n",
    "  'user_has_payment_method': 'text'},\n",
    " 'ratings': {'movie_id': 'integer',\n",
    "  'rating_id': 'integer',\n",
    "  'rating_url': 'integer',\n",
    "  'rating_score': 'integer',\n",
    "  'rating_timestamp_utc': 'integer',\n",
    "  'critic': 'integer',\n",
    "  'critic_likes': 'integer',\n",
    "  'critic_comments': 'integer',\n",
    "  'user_id': 'integer',\n",
    "  'user_trialist': 'integer',\n",
    "  'user_subscriber': 'integer',\n",
    "  'user_eligible_for_trial': 'integer',\n",
    "  'user_has_payment_method': 'integer'}}\n",
    "\n",
    "sqls = \"\"\"\n",
    "SELECT movie_release_year FROM movies WHERE movie_title = 'Cops'\n",
    "SELECT T1.user_id FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE rating_score = 4 AND rating_timestamp_utc LIKE '2013-05-04 06:33:32' AND T2.movie_title LIKE 'Freaks'\n",
    "SELECT T1.user_trialist FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'A Way of Life' AND T1.user_id = 39115684\n",
    "SELECT T2.movie_title FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T1.rating_timestamp_utc LIKE '2020%' GROUP BY T2.movie_title ORDER BY COUNT(T2.movie_title) DESC LIMIT 1\n",
    "SELECT AVG(T1.rating_score), T2.director_name FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'When Will I Be Loved'\n",
    "\"\"\"\n",
    "schema = Schema(schema_dict)\n",
    "sqls = [s.strip() for s in sqls.strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sql in sqls:\n",
    "    parsed_sql = sqlglot.parse_one(sql)\n",
    "    output = extract_all(parsed_sql, schema)\n",
    "    # print\n",
    "    print('SQL:', sql)\n",
    "    print('# Selection')\n",
    "    print(f'  unique columns: {output[\"sel\"]}')\n",
    "    for i, ast in enumerate(output['sel_asts']):\n",
    "        print(f' [{i}] type: {ast[2]}')\n",
    "        print(f' [{i}] ast:')\n",
    "        print('  ' + repr(ast[1]))\n",
    "    if output['cond_asts']:\n",
    "        print('\\n# condition')\n",
    "        print(f'  operations: {output[\"op_types\"]}')\n",
    "        for i, ast in enumerate(output['cond_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    if output['agg_asts']:\n",
    "        print('\\n# aggregation')\n",
    "        print(f'  unique columns: {output[\"agg\"]}')\n",
    "        for i, ast in enumerate(output['agg_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    if output['orderby_asts']:\n",
    "        print('\\n# orderby')\n",
    "        print(f'  unique columns: {output[\"orderby\"]}')\n",
    "        for i, ast in enumerate(output['group_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    \n",
    "    if output['nested']:\n",
    "        print('\\n# nested')\n",
    "        print(f'  number of nested: {output[\"nested\"]}')\n",
    "        # check the `output['subqueries']` if you waht to see the nested queries\n",
    "        # first one is the original query\n",
    "    if output['distinct']:\n",
    "        print(f'\\n# distinct: {output[\"distinct\"]}')\n",
    "    if output['limit']:\n",
    "        print(f'\\n# limit: {output[\"limit\"]}')\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement of Complexity\n",
    "\n",
    "1. Tree Similarity Edit Distance\n",
    "2. Set of unique columns, tables, types of functions ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SQL1]\n",
      " SELECT\n",
      "  COUNT(*)\n",
      "FROM lineitem\n",
      "WHERE\n",
      "  lineitem.l_receiptdate > lineitem.l_commitdate\n",
      "  AND STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
      "\n",
      "[SQL2]\n",
      " SELECT\n",
      "  COUNT(*)\n",
      "FROM lineitem\n",
      "WHERE\n",
      "  lineitem.l_commitdate < lineitem.l_receiptdate\n",
      "  AND lineitem.l_receiptdate >= '[placeholder-type:string]'\n",
      "  AND lineitem.l_receiptdate < '[placeholder-type:string]'\n",
      "\n",
      "TSED: 0.4231\n",
      "Tree Edit Distance: 15\n",
      "Partial Match Score\n"
     ]
    }
   ],
   "source": [
    "import sqlglot\n",
    "\n",
    "# sql1 = \"\"\"SELECT T1.USER_ID \n",
    "# FROM ratings AS T1 \n",
    "# INNER JOIN movies AS T2 \n",
    "# ON T1.movie_id = T2.movie_id \n",
    "# WHERE \n",
    "#     rating_score = 4 \n",
    "#     AND rating_timestamp_utc LIKE '2013-05-04 06:33:32' \n",
    "#     AND T2.movie_title LIKE 'Freaks'\n",
    "# \"\"\"\n",
    "\n",
    "# sql2 = \"\"\"SELECT T1.user_id, COUNT(T2.movie_title)\n",
    "# FROM ratings AS T1 \n",
    "# INNER JOIN movies AS T2 \n",
    "# ON T1.movie_id = T2.movie_id \n",
    "# GROUP BY T1.user_id\n",
    "# HAVING COUNT(T2.movie_title) > 1\n",
    "# ORDER BY COUNT(T2.movie_title) DESC\n",
    "# \"\"\"\n",
    "\n",
    "sql1 = \"\"\"SELECT\n",
    "  COUNT(*) AS late_line_items_count\n",
    "FROM LINEITEM L\n",
    "WHERE\n",
    "  lineitem.L_RECEIPTDATE > lineitem.L_COMMITDATE\n",
    "  AND STRFTIME('%Y', lineitem.L_RECEIPTDATE) = 'abcd'\"\"\"\n",
    "\n",
    "sql2 = \"\"\"SELECT\n",
    "  COUNT(*) AS count\n",
    "FROM lineitem\n",
    "WHERE\n",
    "  lineitem.l_commitdate < lineitem.l_receiptdate\n",
    "  AND lineitem.l_receiptdate >= '1993-01-01'\n",
    "  AND lineitem.l_receiptdate < '1994-01-01'\n",
    "\"\"\"\n",
    "\n",
    "schema = Schema({\n",
    "    'lineitem': {'l_receiptdate': 'date', 'l_commitdate': 'date'}\n",
    "})\n",
    "\n",
    "output1 = extract_all(sql1, schema)\n",
    "output2 = extract_all(sql2, schema)\n",
    "\n",
    "\n",
    "formatted_sql1 = output1['subqueries'][0]\n",
    "formatted_sql2 = output2['subqueries'][0]\n",
    "tsed, distance = compute_tsed(formatted_sql1, formatted_sql2, build_type='apted')  # apted or zss\n",
    "print('[SQL1]\\n', formatted_sql1.sql(pretty=True))\n",
    "print()\n",
    "print('[SQL2]\\n', formatted_sql2.sql(pretty=True))\n",
    "print()\n",
    "print(f'TSED: {tsed:.4f}')\n",
    "print(f'Tree Edit Distance: {distance}')\n",
    "\n",
    "\n",
    "# partial match\n",
    "print('Partial Match Score')\n",
    "\n",
    "def get_partial_score(output1, output2, arg):\n",
    "    \"\"\"\n",
    "    table:\n",
    "\n",
    "    target |  prediction  |  score\n",
    "    True   |  True        |  depends on arg\n",
    "    True   |  False       |  0.0, np.infty\n",
    "    False  |  True        |  0.0, np.infty\n",
    "    False  |  False       |  1.0, 0.0\n",
    "    \n",
    "    arg: \n",
    "     - use all: 'sel_asts', 'cond_asts', 'agg_asts', 'orderby_asts'\n",
    "     - only use items from 2nd item in the list: 'subqueries'\n",
    "     - boolean: 'distinct', 'limit'\n",
    "    \"\"\"\n",
    "    if output2[arg] and output1[arg]:\n",
    "        if arg in ['sel_asts', 'cond_asts', 'agg_asts', 'orderby_asts']:\n",
    "            source = [ast for _, ast, _ in output1[arg]]\n",
    "            target = [ast for _, ast, _ in output2[arg]]\n",
    "            score, dis = get_tsed_score(source, target, build_type='apted')\n",
    "        elif arg == 'subqueries':\n",
    "            source = output1[arg][1:]\n",
    "            target = output2[arg][1:]\n",
    "            score, dis = get_tsed_score(source, target, build_type='apted')\n",
    "        elif arg in ['distinct', 'limit']:\n",
    "            score, dis = 1.0, 0.0\n",
    "    elif (not output2[arg]) and (not output1[arg]):\n",
    "        score, dis = 1.0, 0.0    \n",
    "    else:\n",
    "        score, dis = 0.0, np.infty\n",
    "\n",
    "    return score, dis\n",
    "\n",
    "def get_tsed_score(\n",
    "        source: list[exp.Expression], \n",
    "        target: list[exp.Expression], \n",
    "        build_type='apted',\n",
    "        criteria='tsed'  # tsed or distance\n",
    "    ):\n",
    "    \"\"\"\n",
    "    1. calculate pairwise tsed\n",
    "    2. check possible matchings\n",
    "    3. choose the matching with the highest score\n",
    "    4. return the overall score\n",
    "\n",
    "    criteria: tsed (max) or distance (min)\n",
    "    \"\"\"\n",
    "    scores = np.zeros((len(source), len(target)))\n",
    "    distances = np.ones((len(source), len(target))) * np.infty\n",
    "\n",
    "    for i, ast1 in enumerate(source):\n",
    "        for j, ast2 in enumerate(target):\n",
    "            score, distance = compute_tsed(ast1, ast2, build_type)\n",
    "            scores[i, j] = score\n",
    "            distances[i, j] = distance\n",
    "\n",
    "    return scores, distances\n",
    "\n",
    "# sel_score, sel_dis = get_partial_score(output1, output2, arg='sel_asts')\n",
    "# print(f'  Selection: tsed={sel_score:.4f} | distance={sel_dis:.2f}')\n",
    "# cond_score, cond_dis = get_partial_score(output1, output2, arg='cond_asts')\n",
    "# print(f'  Condition: tsed={cond_score:.4f} | distance={cond_dis:.2f}')\n",
    "# agg_score, agg_dis = get_partial_score(output1, output2, arg='agg_asts')\n",
    "# print(f'  Aggregation: tsed={agg_score:.4f} | distance={agg_dis:.2f}')\n",
    "# orderby_score, orderby_dis = get_partial_score(output1, output2, arg='orderby_asts')\n",
    "# print(f'  Orderby: tsed={orderby_score:.4f} | distance={orderby_dis:.2f}')\n",
    "# nested_score, nested_dis = get_partial_score(output1, output2, arg='subqueries')\n",
    "# print(f'  Nested: tsed={nested_score:.4f} | distance={nested_dis:.2f}')\n",
    "# distinct_score, distinct_dis = get_partial_score(output1, output2, arg='distinct')\n",
    "# print(f'  Distinct: tsed={distinct_score:.4f} | distance={distinct_dis:.2f}')\n",
    "# limit_score, limit_dis = get_partial_score(output1, output2, arg='limit')\n",
    "# print(f'  Limit: tsed={limit_score:.4f} | distance={limit_dis:.2f}')\n",
    "\n",
    "source = [ast for _, ast, _ in output1['cond_asts']]\n",
    "target = [ast for _, ast, _ in output2['cond_asts']]\n",
    "score, dis = get_tsed_score(source, target, build_type='apted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "try:\n",
    "    nlp_spacy = spacy.load('en_core_web_md')\n",
    "except OSError:\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_md')\n",
    "\n",
    "from bert_score import score as bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97697 lineitem.l_receiptdate > lineitem.l_commitdate lineitem.l_receiptdate < '[placeholder-type:string]'\n",
      "0.98193 lineitem.l_receiptdate > lineitem.l_commitdate lineitem.l_receiptdate >= '[placeholder-type:string]'\n",
      "1.00000 lineitem.l_receiptdate > lineitem.l_commitdate lineitem.l_commitdate < lineitem.l_receiptdate\n",
      "0.99397 STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]' lineitem.l_receiptdate < '[placeholder-type:string]'\n",
      "0.99266 STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]' lineitem.l_receiptdate >= '[placeholder-type:string]'\n",
      "0.96241 STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]' lineitem.l_commitdate < lineitem.l_receiptdate\n"
     ]
    }
   ],
   "source": [
    "source_spacy = [nlp_spacy(str(x)) for x in source]\n",
    "target_spacy = [nlp_spacy(str(x)) for x in target]\n",
    "\n",
    "for s in source_spacy:\n",
    "    for t in target_spacy:\n",
    "        print(f'{s.similarity(t):.5f}', s, t, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonjisu/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "source_str = [str(x) for x in source]\n",
    "target_str = [str(x) for x in target]\n",
    "source_str_list, target_str_list = list(zip(*product(source_str, target_str)))\n",
    "P, R, F1 = bscore(source_str_list, target_str_list, lang='en', verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91560, 0.86583, 0.89002 lineitem.l_receiptdate > lineitem.l_commitdate lineitem.l_receiptdate < '[placeholder-type:string]'\n",
      "0.91453, 0.86756, 0.89043 lineitem.l_receiptdate > lineitem.l_commitdate lineitem.l_receiptdate >= '[placeholder-type:string]'\n",
      "0.98415, 0.98415, 0.98415 lineitem.l_receiptdate > lineitem.l_commitdate lineitem.l_commitdate < lineitem.l_receiptdate\n",
      "0.90197, 0.96393, 0.93192 STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]' lineitem.l_receiptdate < '[placeholder-type:string]'\n",
      "0.90342, 0.96516, 0.93327 STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]' lineitem.l_receiptdate >= '[placeholder-type:string]'\n",
      "0.82550, 0.91720, 0.86893 STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]' lineitem.l_commitdate < lineitem.l_receiptdate\n"
     ]
    }
   ],
   "source": [
    "for i, (s, t) in enumerate(zip(source_str_list, target_str_list)):\n",
    "    print(f'{P[i]:.5f}, {R[i]:.5f}, {F1[i]:.5f}', s, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42857143, 0.42857143, 0.28571429],\n",
       "       [0.57142857, 0.57142857, 0.14285714]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4., 4., 5.],\n",
       "       [3., 3., 6.]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(score, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table(\n",
       "  this=Identifier(this=LINEITEM, quoted=False),\n",
       "  alias=TableAlias(\n",
       "    this=Identifier(this=L, quoted=False)))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use ranking of two metrics to determine the best matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier(this=LINEITEM, quoted=False)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expr.args['this']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier(this=lineitem, quoted=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.Identifier(\n",
    "    this=expr.args['this'].name.lower(), \n",
    "    quoted=expr.args['this'].quoted   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
