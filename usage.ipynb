{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "proj_path = Path('.').resolve()\n",
    "sys.path.append(str(proj_path))\n",
    "\n",
    "import sqlglot\n",
    "import numpy as np\n",
    "from sqlglot import expressions as exp\n",
    "from src.parsing_sql import Schema, extract_all\n",
    "from src.eval_utils import (\n",
    "    partial_match, \n",
    "    compute_tsed\n",
    ")\n",
    "\n",
    "from src.parsing_sql import (\n",
    "    extract_aliases,\n",
    "    extract_condition,\n",
    "    get_subqueries,\n",
    "    _extract_conditions,\n",
    "    _extract_columns_from_expression,\n",
    "    _determine_tag,\n",
    "    _format_expression,\n",
    "    _get_full_column_name,\n",
    "    extract_aliases,\n",
    "    extract_selection,\n",
    "    extract_aggregation,\n",
    "    extract_orderby,\n",
    "    extract_others,\n",
    "    \n",
    "    _extract_aliases_from_select,\n",
    "    _handle_table_or_subquery\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_dict = {'lists': {'user_id': 'text',\n",
    "  'list_id': 'text',\n",
    "  'list_title': 'text',\n",
    "  'list_movie_number': 'text',\n",
    "  'list_update_timestamp_utc': 'text',\n",
    "  'list_creation_timestamp_utc': 'text',\n",
    "  'list_followers': 'text',\n",
    "  'list_url': 'text',\n",
    "  'list_comments': 'text',\n",
    "  'list_description': 'text',\n",
    "  'list_cover_image_url': 'text',\n",
    "  'list_first_image_url': 'text',\n",
    "  'list_second_image_url': 'text',\n",
    "  'list_third_image_url': 'text'},\n",
    " 'movies': {'movie_id': 'integer',\n",
    "  'movie_title': 'integer',\n",
    "  'movie_release_year': 'integer',\n",
    "  'movie_url': 'integer',\n",
    "  'movie_title_language': 'integer',\n",
    "  'movie_popularity': 'integer',\n",
    "  'movie_image_url': 'integer',\n",
    "  'director_id': 'integer',\n",
    "  'director_name': 'integer',\n",
    "  'director_url': 'integer'},\n",
    " 'ratings_users': {'user_id': 'integer',\n",
    "  'rating_date_utc': 'integer',\n",
    "  'user_trialist': 'integer',\n",
    "  'user_subscriber': 'integer',\n",
    "  'user_avatar_image_url': 'integer',\n",
    "  'user_cover_image_url': 'integer',\n",
    "  'user_eligible_for_trial': 'integer',\n",
    "  'user_has_payment_method': 'integer'},\n",
    " 'lists_users': {'user_id': 'text',\n",
    "  'list_id': 'text',\n",
    "  'list_update_date_utc': 'text',\n",
    "  'list_creation_date_utc': 'text',\n",
    "  'user_trialist': 'text',\n",
    "  'user_subscriber': 'text',\n",
    "  'user_avatar_image_url': 'text',\n",
    "  'user_cover_image_url': 'text',\n",
    "  'user_eligible_for_trial': 'text',\n",
    "  'user_has_payment_method': 'text'},\n",
    " 'ratings': {'movie_id': 'integer',\n",
    "  'rating_id': 'integer',\n",
    "  'rating_url': 'integer',\n",
    "  'rating_score': 'integer',\n",
    "  'rating_timestamp_utc': 'integer',\n",
    "  'critic': 'integer',\n",
    "  'critic_likes': 'integer',\n",
    "  'critic_comments': 'integer',\n",
    "  'user_id': 'integer',\n",
    "  'user_trialist': 'integer',\n",
    "  'user_subscriber': 'integer',\n",
    "  'user_eligible_for_trial': 'integer',\n",
    "  'user_has_payment_method': 'integer'}}\n",
    "\n",
    "sqls = \"\"\"\n",
    "SELECT movie_release_year FROM movies WHERE movie_title = 'Cops'\n",
    "SELECT T1.user_id FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE rating_score = 4 AND rating_timestamp_utc LIKE '2013-05-04 06:33:32' AND T2.movie_title LIKE 'Freaks'\n",
    "SELECT T1.user_trialist FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'A Way of Life' AND T1.user_id = 39115684\n",
    "SELECT T2.movie_title FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T1.rating_timestamp_utc LIKE '2020%' GROUP BY T2.movie_title ORDER BY COUNT(T2.movie_title) DESC LIMIT 1\n",
    "SELECT AVG(T1.rating_score), T2.director_name FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'When Will I Be Loved'\n",
    "\"\"\"\n",
    "schema = Schema(schema_dict)\n",
    "sqls = [s.strip() for s in sqls.strip().split('\\n')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL: SELECT movie_release_year FROM movies WHERE movie_title = 'Cops'\n",
      "# Selection\n",
      "  unique columns: {'__movies.movie_release_year__'}\n",
      " [0] type: <select>\n",
      " [0] ast:\n",
      "  Column(\n",
      "  this=Identifier(this=movie_release_year, quoted=False),\n",
      "  table=Identifier(this=movies, quoted=False))\n",
      "\n",
      "# condition\n",
      "  operations: {'eq'}\n",
      " [0] __movies.movie_title__ eq [placeholder-type:string]\n",
      " [0] ast:\n",
      "  EQ(\n",
      "  this=Column(\n",
      "    this=Identifier(this=movie_title, quoted=False),\n",
      "    table=Identifier(this=movies, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:string], is_string=True))\n",
      "\n",
      "# nested\n",
      "  number of nested: 1\n",
      "----------------------------------\n",
      "SQL: SELECT T1.user_id FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE rating_score = 4 AND rating_timestamp_utc LIKE '2013-05-04 06:33:32' AND T2.movie_title LIKE 'Freaks'\n",
      "# Selection\n",
      "  unique columns: {'__ratings.user_id__'}\n",
      " [0] type: <select>\n",
      " [0] ast:\n",
      "  Column(\n",
      "  this=Identifier(this=user_id, quoted=False),\n",
      "  table=Identifier(this=ratings, quoted=False))\n",
      "\n",
      "# condition\n",
      "  operations: {'eq', 'like'}\n",
      " [0] __movies.movie_title__ like [placeholder-type:string]\n",
      " [0] ast:\n",
      "  Like(\n",
      "  this=Column(\n",
      "    this=Identifier(this=movie_title, quoted=False),\n",
      "    table=Identifier(this=movies, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:string], is_string=True))\n",
      " [1] __ratings.rating_timestamp_utc__ like [placeholder-type:string]\n",
      " [1] ast:\n",
      "  Like(\n",
      "  this=Column(\n",
      "    this=Identifier(this=rating_timestamp_utc, quoted=False),\n",
      "    table=Identifier(this=ratings, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:string], is_string=True))\n",
      " [2] __ratings.rating_score__ eq [placeholder-type:numeric]\n",
      " [2] ast:\n",
      "  EQ(\n",
      "  this=Column(\n",
      "    this=Identifier(this=rating_score, quoted=False),\n",
      "    table=Identifier(this=ratings, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:numeric], is_string=False))\n",
      "\n",
      "# nested\n",
      "  number of nested: 1\n",
      "----------------------------------\n",
      "SQL: SELECT T1.user_trialist FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'A Way of Life' AND T1.user_id = 39115684\n",
      "# Selection\n",
      "  unique columns: {'__ratings.user_trialist__'}\n",
      " [0] type: <select>\n",
      " [0] ast:\n",
      "  Column(\n",
      "  this=Identifier(this=user_trialist, quoted=False),\n",
      "  table=Identifier(this=ratings, quoted=False))\n",
      "\n",
      "# condition\n",
      "  operations: {'eq'}\n",
      " [0] __movies.movie_title__ eq [placeholder-type:string]\n",
      " [0] ast:\n",
      "  EQ(\n",
      "  this=Column(\n",
      "    this=Identifier(this=movie_title, quoted=False),\n",
      "    table=Identifier(this=movies, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:string], is_string=True))\n",
      " [1] __ratings.user_id__ eq [placeholder-type:numeric]\n",
      " [1] ast:\n",
      "  EQ(\n",
      "  this=Column(\n",
      "    this=Identifier(this=user_id, quoted=False),\n",
      "    table=Identifier(this=ratings, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:numeric], is_string=False))\n",
      "\n",
      "# nested\n",
      "  number of nested: 1\n",
      "----------------------------------\n",
      "SQL: SELECT T2.movie_title FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T1.rating_timestamp_utc LIKE '2020%' GROUP BY T2.movie_title ORDER BY COUNT(T2.movie_title) DESC LIMIT 1\n",
      "# Selection\n",
      "  unique columns: {'__movies.movie_title__'}\n",
      " [0] type: <select>\n",
      " [0] ast:\n",
      "  Column(\n",
      "  this=Identifier(this=movie_title, quoted=False),\n",
      "  table=Identifier(this=movies, quoted=False))\n",
      "\n",
      "# condition\n",
      "  operations: {'like'}\n",
      " [0] __ratings.rating_timestamp_utc__ like [placeholder-type:string]\n",
      " [0] ast:\n",
      "  Like(\n",
      "  this=Column(\n",
      "    this=Identifier(this=rating_timestamp_utc, quoted=False),\n",
      "    table=Identifier(this=ratings, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:string], is_string=True))\n",
      "\n",
      "# aggregation\n",
      "  unique columns: {'__movies.movie_title__'}\n",
      " [0] __movies.movie_title__\n",
      " [0] ast:\n",
      "  Column(\n",
      "  this=Identifier(this=movie_title, quoted=False),\n",
      "  table=Identifier(this=movies, quoted=False))\n",
      "\n",
      "# orderby\n",
      "  unique columns: {'__movies.movie_title__'}\n",
      "\n",
      "# nested\n",
      "  number of nested: 1\n",
      "\n",
      "# limit: True\n",
      "----------------------------------\n",
      "SQL: SELECT AVG(T1.rating_score), T2.director_name FROM ratings AS T1 INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE T2.movie_title = 'When Will I Be Loved'\n",
      "# Selection\n",
      "  unique columns: {'__movies.director_name__', '__ratings.rating_score__'}\n",
      " [0] type: <select>\n",
      " [0] ast:\n",
      "  Column(\n",
      "  this=Identifier(this=director_name, quoted=False),\n",
      "  table=Identifier(this=movies, quoted=False))\n",
      " [1] type: <func>\n",
      " [1] ast:\n",
      "  Avg(\n",
      "  this=Column(\n",
      "    this=Identifier(this=rating_score, quoted=False),\n",
      "    table=Identifier(this=ratings, quoted=False)))\n",
      "\n",
      "# condition\n",
      "  operations: {'eq'}\n",
      " [0] __movies.movie_title__ eq [placeholder-type:string]\n",
      " [0] ast:\n",
      "  EQ(\n",
      "  this=Column(\n",
      "    this=Identifier(this=movie_title, quoted=False),\n",
      "    table=Identifier(this=movies, quoted=False)),\n",
      "  expression=Literal(this=[placeholder-type:string], is_string=True))\n",
      "\n",
      "# nested\n",
      "  number of nested: 1\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "for sql in sqls:\n",
    "    output = extract_all(sql, schema)\n",
    "    # print\n",
    "    print('SQL:', sql)\n",
    "    print('# Selection')\n",
    "    print(f'  unique columns: {output[\"sel\"]}')\n",
    "    for i, ast in enumerate(output['sel_asts']):\n",
    "        print(f' [{i}] type: {ast[2]}')\n",
    "        print(f' [{i}] ast:')\n",
    "        print('  ' + repr(ast[1]))\n",
    "    if output['cond_asts']:\n",
    "        print('\\n# condition')\n",
    "        print(f'  operations: {output[\"op_types\"]}')\n",
    "        for i, ast in enumerate(output['cond_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    if output['agg_asts']:\n",
    "        print('\\n# aggregation')\n",
    "        print(f'  unique columns: {output[\"agg\"]}')\n",
    "        for i, ast in enumerate(output['agg_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    if output['orderby_asts']:\n",
    "        print('\\n# orderby')\n",
    "        print(f'  unique columns: {output[\"orderby\"]}')\n",
    "        for i, ast in enumerate(output['group_asts']):\n",
    "            print(f' [{i}] {ast[0]}')\n",
    "            print(f' [{i}] ast:')\n",
    "            print('  ' + repr(ast[1]))\n",
    "    \n",
    "    if output['nested']:\n",
    "        print('\\n# nested')\n",
    "        print(f'  number of nested: {output[\"nested\"]}')\n",
    "        # check the `output['subqueries']` if you waht to see the nested queries\n",
    "        # first one is the original query\n",
    "    if output['distinct']:\n",
    "        print(f'\\n# distinct: {output[\"distinct\"]}')\n",
    "    if output['limit']:\n",
    "        print(f'\\n# limit: {output[\"limit\"]}')\n",
    "    print('----------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measurement of Complexity\n",
    "\n",
    "1. Tree Similarity Edit Distance\n",
    "2. Set of unique columns, tables, types of functions \n",
    "\n",
    "* `n` = number of source asts\n",
    "* `m` = number of target asts\n",
    "\n",
    "```python\n",
    "if n == m:\n",
    "    # means that the number of source and target asts are the same\n",
    "elif n > m:\n",
    "    # means that the number of source asts are greater than the number of target asts\n",
    "else:\n",
    "    # means that the number of source asts are less than the number of target asts\n",
    "```\n",
    "\n",
    "\n",
    "Hungarian algorithm - https://hongl.tistory.com/159\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SQL1]\n",
      " SELECT\n",
      "  ratings.user_id\n",
      "FROM ratings\n",
      "INNER JOIN movies AS T2\n",
      "  ON T1.movie_id = T2.movie_id\n",
      "WHERE\n",
      "  ratings.rating_score = [placeholder-type:numeric]\n",
      "  AND ratings.rating_timestamp_utc LIKE '[placeholder-type:string]'\n",
      "  AND movies.movie_title LIKE '[placeholder-type:string]'\n",
      "\n",
      "[SQL2]\n",
      " SELECT\n",
      "  ratings.user_id,\n",
      "  COUNT(movies.movie_title)\n",
      "FROM ratings\n",
      "INNER JOIN movies AS T2\n",
      "  ON T1.movie_id = T2.movie_id\n",
      "GROUP BY\n",
      "  ratings.user_id\n",
      "HAVING\n",
      "  COUNT(movies.movie_title) > [placeholder-type:numeric]\n",
      "ORDER BY\n",
      "  COUNT(movies.movie_title)\n",
      "\n",
      "TSED: 0.4359\n",
      "Tree Edit Distance: 22\n",
      "Partial Match Score\n",
      "  Selection: tsed=0.4950000047683716\n",
      "  Condition: tsed=0.1600000113248825\n",
      "  Aggregation: tsed=None\n",
      "  Orderby: tsed=None\n",
      "  Nested: tsed=1.0\n",
      "  Distinct: tsed=1.0\n",
      "  Limit: tsed=1.0\n"
     ]
    }
   ],
   "source": [
    "# import sqlglot\n",
    "\n",
    "sql1 = \"\"\"SELECT T1.USER_ID \n",
    "FROM ratings AS T1 \n",
    "INNER JOIN movies AS T2 \n",
    "ON T1.movie_id = T2.movie_id \n",
    "WHERE \n",
    "    rating_score = 4 \n",
    "    AND rating_timestamp_utc LIKE '2013-05-04 06:33:32' \n",
    "    AND T2.movie_title LIKE 'Freaks'\n",
    "\"\"\"\n",
    "\n",
    "sql2 = \"\"\"SELECT T1.user_id, COUNT(T2.movie_title)\n",
    "FROM ratings AS T1 \n",
    "INNER JOIN movies AS T2 \n",
    "ON T1.movie_id = T2.movie_id \n",
    "GROUP BY T1.user_id\n",
    "HAVING COUNT(T2.movie_title) > 1\n",
    "ORDER BY COUNT(T2.movie_title) DESC\n",
    "\"\"\"\n",
    "schema = Schema(schema_dict)\n",
    "\n",
    "# sql1 = \"\"\"SELECT\n",
    "#   COUNT(*) AS count\n",
    "# FROM lineitem\n",
    "# WHERE\n",
    "#   lineitem.l_commitdate < lineitem.l_receiptdate\n",
    "#   AND lineitem.l_receiptdate >= '1993-01-01'\n",
    "#   AND lineitem.l_receiptdate < '1994-01-01'\n",
    "# \"\"\"\n",
    "\n",
    "# sql2 = \"\"\"SELECT\n",
    "#   COUNT(*) AS late_line_items_count\n",
    "# FROM LINEITEM L\n",
    "# WHERE\n",
    "#   lineitem.L_RECEIPTDATE > lineitem.L_COMMITDATE\n",
    "#   AND STRFTIME('%Y', lineitem.L_RECEIPTDATE) = 'abcd'\"\"\"\n",
    "\n",
    "# schema = Schema({\n",
    "#     'lineitem': {'l_receiptdate': 'date', 'l_commitdate': 'date'}\n",
    "# })\n",
    "\n",
    "output1 = extract_all(sql1, schema)\n",
    "output2 = extract_all(sql2, schema)\n",
    "\n",
    "formatted_sql1 = output1['subqueries'][0]\n",
    "formatted_sql2 = output2['subqueries'][0]\n",
    "tsed, distance = compute_tsed(formatted_sql1, formatted_sql2, build_type='apted')  # apted or zss\n",
    "print('[SQL1]\\n', formatted_sql1.sql(pretty=True))\n",
    "print()\n",
    "print('[SQL2]\\n', formatted_sql2.sql(pretty=True))\n",
    "print()\n",
    "print(f'TSED: {tsed:.4f}')\n",
    "print(f'Tree Edit Distance: {distance}')\n",
    "\n",
    "\n",
    "# partial match\n",
    "print('Partial Match Score')\n",
    "\n",
    "from scipy.optimize import linear_sum_assignment \n",
    "\n",
    "def partial_matching_with_penalty(matrix: np.ndarray, penalty: float=0.0, maximize: bool=True, epsilon: float=1e-9):\n",
    "    n, m = matrix.shape  # (# of source, # of target)\n",
    "    size = max(n, m)\n",
    "    score_matrix = np.full((size, size), -penalty, dtype=np.float32)\n",
    "    score_matrix[:n, :m] = matrix\n",
    "    row_ind, col_ind = linear_sum_assignment(score_matrix, maximize=maximize)\n",
    "    total_score = (score_matrix[row_ind, col_ind] + epsilon).mean()\n",
    "    return row_ind, col_ind, total_score\n",
    "\n",
    "def get_score(\n",
    "        source: list[exp.Expression], \n",
    "        target: list[exp.Expression], \n",
    "        build_type: str='apted',\n",
    "        criteria: str='tsed',\n",
    "        penalty: float=0.01,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    n = len(source), m = len(target)\n",
    "    if n == m: \n",
    "        it means that we can match all source to target \n",
    "        run partial matching with zero penalty\n",
    "    if n != m: \n",
    "        it means that we can't match all source to target: either we over-guess or under-guess\n",
    "        run partial matching with np.infty penalty\n",
    "    criteria: tsed (max) or distance (min)\n",
    "    \"\"\"\n",
    "    n = len(source)\n",
    "    m = len(target)\n",
    "    scores = np.zeros((n, m), dtype=np.float32)\n",
    "    distance = np.zeros((n, m), dtype=np.float32)\n",
    "    for i, ast1 in enumerate(source):\n",
    "        for j, ast2 in enumerate(target):\n",
    "            score, dis = compute_tsed(ast1, ast2, build_type)\n",
    "            scores[i, j] = score\n",
    "            distance[i, j] = dis\n",
    "\n",
    "    maximize = True if criteria == 'tsed' else False\n",
    "    matrix = scores if criteria == 'tsed' else distance\n",
    "    *_, final_score = partial_matching_with_penalty(matrix, penalty, maximize)\n",
    "\n",
    "    return final_score\n",
    "\n",
    "def get_partial_score(\n",
    "        output1, \n",
    "        output2, \n",
    "        arg,\n",
    "        build_type: str='apted',\n",
    "        criteria: str='tsed',\n",
    "        penalty: float=0.01,\n",
    "    ):\n",
    "    \"\"\"\n",
    "    table:\n",
    "\n",
    "    target |  prediction  |  score\n",
    "    True   |  True        |  depends on arg\n",
    "    True   |  False       |  tsed=0.0 or distance=np.infty\n",
    "    False  |  True        |  tsed=0.0 or distance=np.infty\n",
    "    False  |  False       |  None\n",
    "    \n",
    "    arg: \n",
    "     - use all: 'sel_asts', 'cond_asts', 'agg_asts', 'orderby_asts'\n",
    "     - only use items from 2nd item in the list: 'subqueries'\n",
    "     - boolean: 'distinct', 'limit'\n",
    "    \"\"\"\n",
    "    assert build_type in ['apted', 'zss'], f'build_type should be either apted or zss, but got {build_type}'\n",
    "    assert criteria in ['tsed', 'distance'], f'criteria should be either tsed or distance, but got {criteria}'\n",
    "    assert arg in ['sel_asts', 'cond_asts', 'agg_asts', 'orderby_asts', 'subqueries', 'distinct', 'limit'], f'arg should be either sel_asts, cond_asts, agg_asts, orderby_asts, subqueries, distinct, limit, but got {arg}'\n",
    "    \n",
    "    if output2[arg] and output1[arg]:\n",
    "        if arg in ['sel_asts', 'cond_asts', 'agg_asts', 'orderby_asts']:\n",
    "            source = [ast for _, ast, _ in output1[arg]]\n",
    "            target = [ast for _, ast, _ in output2[arg]]\n",
    "            score = get_score(source, target, build_type, criteria, penalty)\n",
    "        elif arg == 'subqueries':\n",
    "            output1 = {'subqueries': output1[arg][1:]}\n",
    "            output2 = {'subqueries': output2[arg][1:]}\n",
    "            return get_partial_score(output1, output2, arg='subqueries', criteria=criteria, penalty=penalty)\n",
    "        elif arg in ['distinct', 'limit']:\n",
    "            score = 1.0 if criteria == 'tsed' else 0.0\n",
    "    elif (not output2[arg]) and (not output1[arg]):\n",
    "        score = 1.0 if criteria == 'tsed' else 0.0    \n",
    "    else:\n",
    "        # they don't exist in both so, we can't measure the score\n",
    "        score = None\n",
    "        # score = 0.0 if criteria == 'tsed' else np.infty\n",
    "    return score\n",
    "\n",
    "build_type = 'apted'  # apted or zss\n",
    "criteria = 'tsed'  # tsed or distance\n",
    "penalty = 0.01\n",
    "\n",
    "sel_score = get_partial_score(output1, output2, arg='sel_asts', criteria=criteria, penalty=penalty)\n",
    "print(f'  Selection: {criteria}={sel_score}')\n",
    "cond_score = get_partial_score(output1, output2, arg='cond_asts', criteria=criteria, penalty=penalty)\n",
    "print(f'  Condition: {criteria}={cond_score}')\n",
    "agg_score = get_partial_score(output1, output2, arg='agg_asts', criteria=criteria, penalty=penalty)\n",
    "print(f'  Aggregation: {criteria}={agg_score}')\n",
    "orderby_score = get_partial_score(output1, output2, arg='orderby_asts', criteria=criteria, penalty=penalty)\n",
    "print(f'  Orderby: {criteria}={orderby_score}')\n",
    "nested_score = get_partial_score(output1, output2, arg='subqueries', criteria=criteria, penalty=penalty)\n",
    "print(f'  Nested: {criteria}={nested_score}')\n",
    "distinct_score = get_partial_score(output1, output2, arg='distinct', criteria=criteria, penalty=penalty)\n",
    "print(f'  Distinct: {criteria}={distinct_score}')\n",
    "limit_score = get_partial_score(output1, output2, arg='limit', criteria=criteria, penalty=penalty)\n",
    "print(f'  Limit: {criteria}={limit_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.495"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "try:\n",
    "    nlp_spacy = spacy.load('en_core_web_md')\n",
    "except OSError:\n",
    "    from spacy.cli import download\n",
    "    download('en_core_web_md')\n",
    "\n",
    "from bert_score import score as bscore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.00000 lineitem.l_commitdate < lineitem.l_receiptdate lineitem.l_receiptdate > lineitem.l_commitdate\n",
      "0.96241 lineitem.l_commitdate < lineitem.l_receiptdate STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
      "0.98193 lineitem.l_receiptdate >= '[placeholder-type:string]' lineitem.l_receiptdate > lineitem.l_commitdate\n",
      "0.99266 lineitem.l_receiptdate >= '[placeholder-type:string]' STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
      "0.97697 lineitem.l_receiptdate < '[placeholder-type:string]' lineitem.l_receiptdate > lineitem.l_commitdate\n",
      "0.99397 lineitem.l_receiptdate < '[placeholder-type:string]' STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n"
     ]
    }
   ],
   "source": [
    "source_spacy = [nlp_spacy(str(x)) for x in source]\n",
    "target_spacy = [nlp_spacy(str(x)) for x in target]\n",
    "\n",
    "for s in source_spacy:\n",
    "    for t in target_spacy:\n",
    "        print(f'{s.similarity(t):.5f}', s, t, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonjisu/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "source_str = [str(x) for x in source]\n",
    "target_str = [str(x) for x in target]\n",
    "source_str_list, target_str_list = list(zip(*product(source_str, target_str)))\n",
    "P, R, F1 = bscore(source_str_list, target_str_list, lang='en', verbose=False)\n",
    "precision = P.numpy().reshape(len(source_str), len(target_str))\n",
    "recall = R.numpy().reshape(len(source_str), len(target_str))\n",
    "f1 = F1.numpy().reshape(len(source_str), len(target_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9841494 , 0.868934  ],\n",
       "       [0.8904283 , 0.93327105],\n",
       "       [0.8900186 , 0.9319242 ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source0: lineitem.l_commitdate < lineitem.l_receiptdate\n",
      "  -> Target0: lineitem.l_receiptdate > lineitem.l_commitdate\n",
      "  BS: 0.9841 (0) | TSED: 0.2857 (0)\n",
      "  -> Target1: STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
      "  BS: 0.8689 (1) | TSED: 0.1429 (1)\n",
      "Source1: lineitem.l_receiptdate >= '[placeholder-type:string]'\n",
      "  -> Target0: lineitem.l_receiptdate > lineitem.l_commitdate\n",
      "  BS: 0.8904 (1) | TSED: 0.4286 (1)\n",
      "  -> Target1: STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
      "  BS: 0.9333 (0) | TSED: 0.5714 (0)\n",
      "Source2: lineitem.l_receiptdate < '[placeholder-type:string]'\n",
      "  -> Target0: lineitem.l_receiptdate > lineitem.l_commitdate\n",
      "  BS: 0.8900 (1) | TSED: 0.4286 (1)\n",
      "  -> Target1: STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
      "  BS: 0.9319 (0) | TSED: 0.5714 (0)\n"
     ]
    }
   ],
   "source": [
    "for i, s in enumerate(source_str):\n",
    "    print(f'Source{i}: {s}')\n",
    "    rank_f1 = f1[i, :].argsort()[::-1].argsort()\n",
    "    rank_score = score[i, :].argsort()[::-1].argsort()\n",
    "    for j, t in enumerate(target_str):\n",
    "        print(f'  -> Target{j}: {t}')\n",
    "        print(f'  BS: {f1[i, j]:.4f} ({rank_f1[j]}) | TSED: {score[i, j]:.4f} ({rank_score[j]})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 6.],\n",
       "       [4., 3.],\n",
       "       [4., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9841494 , 0.868934  ],\n",
       "       [0.8904283 , 0.93327105],\n",
       "       [0.8900186 , 0.9319242 ]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import linear_sum_assignment \n",
    "\n",
    "def partial_matching_with_penalty(matrix: np.ndarray, penalty: float=0.0, is_sim: bool=True):\n",
    "    n, m = matrix.shape  # (# of source, # of target)\n",
    "    size = max(n, m)\n",
    "    score_matrix = np.full((size, size), -penalty, dtype=np.float32)\n",
    "    score_matrix[:n, :m] = matrix\n",
    "    row_ind, col_ind = linear_sum_assignment(score_matrix, maximize=is_sim)\n",
    "    total_score = score_matrix[row_ind, col_ind].mean()\n",
    "    return row_ind, col_ind, total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.3333333"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind, col_ind, total_score = partial_matching_with_penalty(distance, penalty=0.0)\n",
    "total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([2, 1, 0]))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind, col_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6391401"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind, col_ind, total_f1 = partial_matching_with_penalty(f1)\n",
    "total_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.28571429, 0.14285714],\n",
       "       [0.42857143, 0.57142857],\n",
       "       [0.42857143, 0.57142857]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.42857143, 0.57142857])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind, col_ind = linear_sum_assignment(score, maximize=True)\n",
    "score[row_ind, col_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9841494 , 0.868934  ],\n",
       "       [0.8904283 , 0.93327105],\n",
       "       [0.8900186 , 0.9319242 ]], dtype=float32)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9841494 , 0.93327105], dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row_ind, col_ind = linear_sum_assignment(f1, maximize=True)\n",
    "f1[row_ind, col_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4., 3.], dtype=float32), 3.5)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# score = np.array(\n",
    "#     [[0.1, 0.5, 0.3], \n",
    "#      [0.1, 0.7, 0.2]])\n",
    "\n",
    "# score = np.array(\n",
    "#     [[0.1, 0.5], \n",
    "#      [0.1, 0.7]])\n",
    "\n",
    "row_ind, col_ind = linear_sum_assignment(distance, maximize=False)\n",
    "distance[row_ind, col_ind], distance[row_ind, col_ind].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 6.],\n",
       "       [4., 3.],\n",
       "       [4., 3.]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = score\n",
    "n, m = matrix.shape  # (# of source, # of target)\n",
    "size = max(n, m)\n",
    "score_matrix = np.full((size, size), -0.0, dtype=np.float32)\n",
    "score_matrix[:n, :m] = matrix\n",
    "row_ind, col_ind = linear_sum_assignment(score_matrix, maximize=True)\n",
    "total_score = score_matrix[row_ind, col_ind].mean()\n",
    "total_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1, 0.7], dtype=float32)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_matrix[row_ind, col_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([2, 1, 0]), 0.33333334)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "partial_matching_with_penalty(score, penalty=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Source0: lineitem.l_commitdate < lineitem.l_receiptdate\n",
    "  -> Target0: lineitem.l_receiptdate > lineitem.l_commitdate\n",
    "  BS: 0.9841 (0) | TSED: 0.2857 (0)\n",
    "  -> Target1: STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
    "  BS: 0.8689 (1) | TSED: 0.1429 (1)\n",
    "Source1: lineitem.l_receiptdate >= '[placeholder-type:string]'\n",
    "  -> Target0: lineitem.l_receiptdate > lineitem.l_commitdate\n",
    "  BS: 0.8904 (1) | TSED: 0.4286 (1)\n",
    "  -> Target1: STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
    "  BS: 0.9333 (0) | TSED: 0.5714 (0)\n",
    "Source2: lineitem.l_receiptdate < '[placeholder-type:string]'\n",
    "  -> Target0: lineitem.l_receiptdate > lineitem.l_commitdate\n",
    "  BS: 0.8900 (1) | TSED: 0.4286 (1)\n",
    "  -> Target1: STRFTIME('%Y', lineitem.l_receiptdate) = '[placeholder-type:string]'\n",
    "  BS: 0.9319 (0) | TSED: 0.5714 (0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identifier(this=lineitem, quoted=False)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.Identifier(\n",
    "    this=expr.args['this'].name.lower(), \n",
    "    quoted=expr.args['this'].quoted   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
