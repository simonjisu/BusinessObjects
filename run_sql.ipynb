{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "proj_path = Path('.').resolve()\n",
    "sys.path.append(str(proj_path))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.runnables import RunnableSequence\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.vectorstores.utils import DistanceStrategy\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "from src.db_utils import get_schema_str, get_data_dict\n",
    "from src.pymodels import (\n",
    "    DatabaseModel, \n",
    "    SpiderSample, \n",
    "    BirdSample, \n",
    "    BODescription,\n",
    "    SQLResponse\n",
    ")\n",
    "from src.prompts import Prompts\n",
    "from src.database import SqliteDatabase\n",
    "from src.data_preprocess import (\n",
    "    load_raw_data,\n",
    "    process_all_tables,\n",
    "    filter_samples_by_count_spider_bird,\n",
    "    process_samples_bird,\n",
    "    split_train_dev_test,\n",
    "    save_samples_spider_bird,\n",
    "    load_samples_spider_bird,\n",
    ")\n",
    "\n",
    "from src.parsing_sql import Schema, extract_all\n",
    "from src.eval_utils import get_complexity, result_eq, check_if_exists_orderby\n",
    "from run_bo_sql import get_vector_store\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.globals import set_llm_cache\n",
    "# from langchain_community.cache import SQLiteCache\n",
    "# set_llm_cache(SQLiteCache(database_path=f\"./cache/valid_bo_bird_dev.db\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'soccer_2016-0'\n",
    "db = SqliteDatabase(f\"./cache/valid_bo_{file_name}.db\")\n",
    "db.start()\n",
    "c = db.con.cursor()\n",
    "c.execute('BEGIN TRANSACTION')\n",
    "c.execute(\"\"\"\n",
    "DELETE FROM full_llm_cache WHERE response LIKE '%JSONDecodeError%';\n",
    "\"\"\")\n",
    "# c.execute('''\n",
    "# DELETE FROM full_llm_cache\n",
    "# WHERE prompt LIKE '%Which teams have had a player awarded the Purple Cap and another with the Orange Cap%'\n",
    "# ''')\n",
    "db.con.commit()\n",
    "db.close()\n",
    "# JSONDecodeError\n",
    "# ValidationError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>llm</th>\n",
       "      <th>idx</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [prompt, llm, idx, response]\n",
       "Index: []"
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "df = db.execute(\n",
    "'''\n",
    "SELECT * FROM full_llm_cache\n",
    "WHERE prompt LIKE '%Which teams have had a player awarded the Purple Cap and another with the Orange Cap%'\n",
    "''')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.eval_utils import get_structural_score, get_all_structural_score, get_all_semantic_score, partial_matching_with_penalty\n",
    "from run_evaluation import get_target_parsed_sql, get_prediction_parsed_sql\n",
    "from run_bo_sql import _get_categories, _format_interval, get_retriever\n",
    "from bert_score import score as bscore\n",
    "from transformers import logging as tfloggings\n",
    "tfloggings.set_verbosity_error()\n",
    "import warnings\n",
    "\n",
    "ds = 'spider'\n",
    "task = 'zero_shot_hint'\n",
    "typ = 'test'\n",
    "scenario = 0\n",
    "description_file = f'description.json' if ds == 'spider' else f'{ds}_description.json'\n",
    "experiment_folder = proj_path / 'experiments' / ds\n",
    "prediction_path = experiment_folder / 'predictions' / task\n",
    "eval_path = experiment_folder / 'evals' / task\n",
    "\n",
    "tables, *_ = load_raw_data(proj_path / 'data' / ds, load_test=False)\n",
    "with (proj_path / 'data' / description_file).open() as f:\n",
    "    all_descriptions = json.load(f)\n",
    "tables = process_all_tables(tables, descriptions=all_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bird_path = proj_path / 'data' / 'bird'\n",
    "# tables, train_data, dev_data = load_raw_data(bird_path, load_test=False)\n",
    "\n",
    "# with (proj_path / 'data' / 'bird_description.json').open() as f:\n",
    "#     all_descriptions = json.load(f)\n",
    "\n",
    "# bird_tables = process_all_tables(tables, descriptions=all_descriptions)\n",
    "# train_samples = load_samples_spider_bird(proj_path / 'data' / 'bird_train.json')\n",
    "# dev_samples = load_samples_spider_bird(proj_path / 'data' / 'bird_dev.json')\n",
    "# test_samples = load_samples_spider_bird(proj_path / 'data' / 'bird_test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_post_fix = f'{ds}_{typ}' if scenario < 0 else f'{ds}_{typ}_{scenario}'\n",
    "# final_file = f'final_{file_post_fix}.json'\n",
    "# samples = load_samples_spider_bird(proj_path / 'data' / f'{ds}_{typ}.json')\n",
    "\n",
    "# if not (prediction_path / final_file).exists():\n",
    "#     all_results = []\n",
    "#     paths = sorted(list(prediction_path.glob(f'{file_post_fix}_*.json')))\n",
    "#     for p in paths:\n",
    "#         with p.open() as f:\n",
    "#             results = json.load(f)\n",
    "            \n",
    "#         for r in results:\n",
    "#             r.pop('rationale')\n",
    "#             r['db_id'] = p.stem.split('_', 3)[-1]\n",
    "\n",
    "#             found = False\n",
    "#             for s in samples:\n",
    "#                 if r['sample_id'] == s.sample_id:\n",
    "#                     found = True\n",
    "#                     break\n",
    "#             r['gold_sql'] = s.final.sql\n",
    "#             assert found, r['sample_id']\n",
    "\n",
    "#         all_results.extend(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(prediction_path / final_file, 'r') as f:\n",
    "#     preds = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wta_1: 100%|██████████| 1508/1508 [00:02<00:00, 548.94it/s]                         \n"
     ]
    }
   ],
   "source": [
    "# pred_parsed, _ = get_prediction_parsed_sql(preds, tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a retrieval model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'bird'\n",
    "typ = 'dev'\n",
    "task = 'retrieval' # 'zero_shot', 'retrieval', 'valid_bo'\n",
    "description_file = f'description.json' if ds == 'spider' else f'{ds}_description.json'\n",
    "experiment_folder = proj_path / 'experiments' / ds\n",
    "\n",
    "eval_path = experiment_folder / 'evals' / task\n",
    "prediction_path = experiment_folder / 'predictions' / task\n",
    "\n",
    "tables, *_ = load_raw_data(proj_path / 'data' / ds, load_test=False)\n",
    "with (proj_path / 'data' / description_file).open() as f:\n",
    "    all_descriptions = json.load(f)\n",
    "tables = process_all_tables(tables, descriptions=all_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gold_complexity_codes\n",
      "0    1655\n",
      "1    1040\n",
      "2     891\n",
      "3    1146\n",
      "4     976\n",
      "Name: count, dtype: int64\n",
      "gold_complexity_codes\n",
      "0    184\n",
      "1    115\n",
      "2     99\n",
      "3    127\n",
      "4    108\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# with open(experiment_folder / 'predictions' / 'create_bo' / f'final_{ds}_train_bo.json', 'r') as f:\n",
    "#     train_bo = json.load(f)\n",
    "\n",
    "# df = []\n",
    "# for db_id, xs in train_bo.items():\n",
    "#     for x in xs:\n",
    "#         x['db_id'] = db_id\n",
    "#         df.append(x)\n",
    "\n",
    "# df = pd.DataFrame(df)\n",
    "# cates = pd.qcut(df['gold_complexity'], q=5)\n",
    "# df['gold_complexity_cates'] = cates\n",
    "# df['gold_complexity_codes'] = cates.cat.codes\n",
    "# df.to_csv(experiment_folder / 'predictions' / 'create_bo' / f'final_{ds}_train_bo.csv', index=False)\n",
    "# df = pd.read_csv(experiment_folder / 'predictions' / 'create_bo' / f'final_{ds}_train_bo.csv')\n",
    "\n",
    "# df_train = df.groupby('gold_complexity_codes').sample(frac=0.9, random_state=42)\n",
    "# df_dev = df.drop(df_train.index)\n",
    "\n",
    "# print(df_train['gold_complexity_codes'].value_counts().sort_index())\n",
    "# print(df_dev['gold_complexity_codes'].value_counts().sort_index())\n",
    "\n",
    "# df_train.to_csv(experiment_folder / 'predictions' / 'create_bo' / f'{ds}_{task}_trainset.csv', index=False)\n",
    "# df_dev.to_csv(experiment_folder / 'predictions' / 'create_bo' / f'{ds}_{task}_devset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "def run_parallel(func, args, num_cpus: int=1):\n",
    "    pool = mp.Pool(processes=num_cpus)\n",
    "    results = pool.starmap(func, args)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return results\n",
    "\n",
    "\n",
    "def get_hard_negative_samples(df: pd.DataFrame, n_neg_each_db: int=1):\n",
    "    db_ids = df['db_id'].unique()\n",
    "    samples = df.loc[:, ['sample_id', 'question', 'ba']].set_index('sample_id').to_dict('dict')  # question, ba key -- {sample_id: value}\n",
    "    sample_ids = []\n",
    "\n",
    "    for db_id in db_ids:\n",
    "        positive_samples = df.loc[df['db_id'] == db_id, 'sample_id'].tolist()\n",
    "        for pos in positive_samples:\n",
    "            negative_samples = df.loc[df['db_id'] != db_id, ['sample_id', 'db_id']].groupby(['db_id']).sample(n=n_neg_each_db)['sample_id'].tolist()\n",
    "            sample_ids.append({'pos': pos, 'neg': negative_samples})  # anchor: pos-question | positive: pos-ba | negative: neg-ba\n",
    "\n",
    "    return {'samples': samples, 'sample_ids': sample_ids}\n",
    "\n",
    "def split_train_dev_retrieval_data(train_bo_path: Path|str, frac: float=0.9, n_qcut: int =5, n_neg_each_db: int=1, random_state: int=42, num_cpus: int=1):\n",
    "    with open(train_bo_path, 'r') as f:\n",
    "        train_bo = json.load(f)\n",
    "    # create dataframe\n",
    "    df = []\n",
    "    for db_id, xs in train_bo.items():\n",
    "        for x in xs:\n",
    "            x['db_id'] = db_id\n",
    "            df.append(x)\n",
    "\n",
    "    df = pd.DataFrame(df)\n",
    "    cates = pd.qcut(df['gold_complexity'], q=n_qcut)\n",
    "    df['gold_complexity_cates'] = cates\n",
    "    df['gold_complexity_codes'] = cates.cat.codes\n",
    "\n",
    "    # split train and dev by equal complexity distribution\n",
    "    df_train = df.groupby('gold_complexity_codes').sample(frac=frac, random_state=random_state)\n",
    "    df_dev = df.drop(df_train.index)\n",
    "\n",
    "    train_data = get_hard_negative_samples(df_train, n_neg_each_db)\n",
    "    dev_data = get_hard_negative_samples(df_dev, n_neg_each_db)\n",
    "    # train_data, dev_data = run_parallel(get_hard_negative_samples, [(df_train, n_neg_each_db), (df_dev, n_neg_each_db)], num_cpus=num_cpus)\n",
    "\n",
    "    return {'train': train_data, 'dev': dev_data}\n",
    "\n",
    "data = split_train_dev_retrieval_data(experiment_folder / 'predictions' / 'create_bo' / f'final_{ds}_train_bo.json', num_cpus=4)\n",
    "with open(experiment_folder / 'predictions' / 'create_bo' / f'{ds}_{task}_hard_negative.json', 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import (\n",
    "    SentenceTransformer, \n",
    "    SentenceTransformerTrainer, \n",
    "    SentenceTransformerTrainingArguments, \n",
    "    InputExample,\n",
    "    losses\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sentence_transformers.training_args import BatchSamplers\n",
    "from sentence_transformers.evaluation import TripletEvaluator\n",
    "import random\n",
    "\n",
    "class RetrievalDataset():\n",
    "    def __init__(self, data: dict):\n",
    "        self.samples = self._map_samples_key_to_int(data['samples'])\n",
    "        self.sample_ids = self._align_sample_ids(data['sample_ids'])\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.sample_ids)\n",
    "    \n",
    "    def _map_samples_key_to_int(self, samples: dict[str, dict[int|str, str]]):\n",
    "        samples['question'] = {int(k): v for k, v in samples['question'].items()}\n",
    "        samples['ba'] = {int(k): v for k, v in samples['ba'].items()}\n",
    "        return samples\n",
    "\n",
    "    def _align_sample_ids(self, sample_ids: list[dict[str, int|list[int]]]):\n",
    "        # {'pos: pos, 'neg': [neg1, neg2, ...]}\n",
    "        # -> list of [pos, neg] to make (anchor, positive, negative)\n",
    "        flatten_sample_ids = []\n",
    "        for x in sample_ids:\n",
    "            pos_id = int(x['pos'])\n",
    "            neg_ids = [int(i) for i in x['neg']]\n",
    "            for neg_id in neg_ids:\n",
    "                flatten_sample_ids.append({'pos': pos_id, 'neg': neg_id})\n",
    "\n",
    "        return flatten_sample_ids\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.sample_ids[idx]\n",
    "        question = self.samples['question'][x['pos']]\n",
    "        pos_ba = self.samples['ba'][x['pos']]\n",
    "        neg_ba = self.samples['ba'][x['neg']]\n",
    "\n",
    "        return {\n",
    "            'anchor': question,\n",
    "            'positive': pos_ba,\n",
    "            'negative': neg_ba\n",
    "        }\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simonjisu/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2641c1dce31a4f2db3967db4f2089bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d444f427f5473281517df392982948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8214, 'grad_norm': 21.0008487701416, 'learning_rate': 1.197891710589363e-07, 'epoch': 0.0017968483280326308}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 56\u001b[0m\n\u001b[1;32m     40\u001b[0m dev_evaluator \u001b[38;5;241m=\u001b[39m TripletEvaluator(\n\u001b[1;32m     41\u001b[0m     anchors\u001b[38;5;241m=\u001b[39mdev_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manchor\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     42\u001b[0m     positives \u001b[38;5;241m=\u001b[39mdev_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpositive\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     43\u001b[0m     negatives\u001b[38;5;241m=\u001b[39mdev_ds[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnegative\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m     44\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq_ba_dev\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     47\u001b[0m trainer \u001b[38;5;241m=\u001b[39m SentenceTransformerTrainer(\n\u001b[1;32m     48\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     49\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_ds,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     53\u001b[0m     evaluator\u001b[38;5;241m=\u001b[39mdev_evaluator,\n\u001b[1;32m     54\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# use Precision@k to evaluate the model\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# https://github.com/UKPLab/sentence-transformers/issues/100\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/trainer.py:2052\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2050\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2052\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2056\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/trainer.py:2467\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2464\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m=\u001b[39m epoch \u001b[38;5;241m+\u001b[39m (step \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m steps_skipped) \u001b[38;5;241m/\u001b[39m steps_in_epoch\n\u001b[1;32m   2465\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 2467\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_substep_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/trainer.py:2915\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2913\u001b[0m metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_evaluate:\n\u001b[0;32m-> 2915\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2917\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_save:\n\u001b[1;32m   2918\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_checkpoint(model, trial, metrics\u001b[38;5;241m=\u001b[39mmetrics)\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/trainer.py:2872\u001b[0m, in \u001b[0;36mTrainer._evaluate\u001b[0;34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[0m\n\u001b[1;32m   2871\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m-> 2872\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2873\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2875\u001b[0m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/trainer.py:397\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(eval_dataset, DatasetDict) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    396\u001b[0m     eval_dataset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_dataset_name_column(eval_dataset)\n\u001b[0;32m--> 397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/trainer.py:3868\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3865\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3867\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3868\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3869\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3870\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3871\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3872\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3873\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3874\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3875\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3876\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3878\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/trainer.py:407\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluation_loop\u001b[39m(\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    401\u001b[0m     dataloader: DataLoader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    405\u001b[0m     metric_key_prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    406\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m EvalLoopOutput:\n\u001b[0;32m--> 407\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;66;03m# If the evaluator is not defined, we can just return the output\u001b[39;00m\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/trainer.py:4061\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4058\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m observed_batch_size\n\u001b[1;32m   4060\u001b[0m \u001b[38;5;66;03m# Prediction step\u001b[39;00m\n\u001b[0;32m-> 4061\u001b[0m losses, logits, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprediction_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4062\u001b[0m main_input_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_input_name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   4063\u001b[0m inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_input(inputs[main_input_name]) \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39minclude_inputs_for_metrics \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/trainer.py:4279\u001b[0m, in \u001b[0;36mTrainer.prediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_labels \u001b[38;5;129;01mor\u001b[39;00m loss_without_labels:\n\u001b[1;32m   4278\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 4279\u001b[0m         loss, outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   4280\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m   4282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/trainer.py:344\u001b[0m, in \u001b[0;36mSentenceTransformerTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    338\u001b[0m     model \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m model \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel  \u001b[38;5;66;03m# Only if the model is wrapped\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(loss_fn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# Only if the loss stores the model\u001b[39;00m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m loss_fn\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m!=\u001b[39m model  \u001b[38;5;66;03m# Only if the wrapped model is not already stored\u001b[39;00m\n\u001b[1;32m    342\u001b[0m ):\n\u001b[1;32m    343\u001b[0m     loss_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_model_in_loss(loss_fn, model)\n\u001b[0;32m--> 344\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_outputs:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;66;03m# During prediction/evaluation, `compute_loss` will be called with `return_outputs=True`.\u001b[39;00m\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;66;03m# However, Sentence Transformer losses do not return outputs, so we return an empty dictionary.\u001b[39;00m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;66;03m# This does not result in any problems, as the SentenceTransformerTrainingArguments sets\u001b[39;00m\n\u001b[1;32m    349\u001b[0m     \u001b[38;5;66;03m# `prediction_loss_only=True` which means that the output is not used.\u001b[39;00m\n\u001b[1;32m    350\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss, {}\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/losses/CachedMultipleNegativesRankingLoss.py:265\u001b[0m, in \u001b[0;36mCachedMultipleNegativesRankingLoss.forward\u001b[0;34m(self, sentence_features, labels)\u001b[0m\n\u001b[1;32m    263\u001b[0m reps_mbs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    264\u001b[0m random_state_mbs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 265\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mreps_mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_minibatch_iter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentence_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwith_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_random_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreps_mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreps_mb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequires_grad_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state_mbs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/losses/CachedMultipleNegativesRankingLoss.py:194\u001b[0m, in \u001b[0;36mCachedMultipleNegativesRankingLoss.embed_minibatch_iter\u001b[0;34m(self, sentence_feature, with_grad, copy_random_state, random_states)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, b \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\n\u001b[1;32m    185\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mtrange(\n\u001b[1;32m    186\u001b[0m         \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m     )\n\u001b[1;32m    192\u001b[0m ):\n\u001b[1;32m    193\u001b[0m     e \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmini_batch_size\n\u001b[0;32m--> 194\u001b[0m     reps, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_minibatch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentence_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msentence_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbegin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwith_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwith_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy_random_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy_random_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_states\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrandom_states\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m reps, random_state\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/losses/CachedMultipleNegativesRankingLoss.py:171\u001b[0m, in \u001b[0;36mCachedMultipleNegativesRankingLoss.embed_minibatch\u001b[0;34m(self, sentence_feature, begin, end, with_grad, copy_random_state, random_state)\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m grad_context():\n\u001b[1;32m    170\u001b[0m         random_state \u001b[38;5;241m=\u001b[39m RandContext(\u001b[38;5;241m*\u001b[39msentence_feature_minibatch\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m copy_random_state \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m         reps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentence_feature_minibatch\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence_embedding\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# (mbsz, hdim)\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reps, random_state\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:668\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[0;34m(self, input, **kwargs)\u001b[0m\n\u001b[1;32m    666\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[1;32m    667\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[0;32m--> 668\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/sentence_transformers/models/Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, features, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:544\u001b[0m, in \u001b[0;36mMPNetModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    543\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(input_ids\u001b[38;5;241m=\u001b[39minput_ids, position_ids\u001b[38;5;241m=\u001b[39mposition_ids, inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds)\n\u001b[0;32m--> 544\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    552\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    553\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:334\u001b[0m, in \u001b[0;36mMPNetEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, output_attentions, output_hidden_states, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    332\u001b[0m     all_hidden_states \u001b[38;5;241m=\u001b[39m all_hidden_states \u001b[38;5;241m+\u001b[39m (hidden_states,)\n\u001b[0;32m--> 334\u001b[0m layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    344\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:304\u001b[0m, in \u001b[0;36mMPNetLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, position_bias, output_attentions, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m outputs \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add self attentions if we output attention weights\u001b[39;00m\n\u001b[1;32m    303\u001b[0m intermediate_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintermediate(attention_output)\n\u001b[0;32m--> 304\u001b[0m layer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (layer_output,) \u001b[38;5;241m+\u001b[39m outputs\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/transformers/models/mpnet/modeling_mpnet.py:272\u001b[0m, in \u001b[0;36mMPNetOutput.forward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor, input_tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    271\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense(hidden_states)\n\u001b[0;32m--> 272\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(hidden_states \u001b[38;5;241m+\u001b[39m input_tensor)\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/code/BusinessObjects/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1549\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1546\u001b[0m             tracing_state\u001b[38;5;241m.\u001b[39mpop_scope()\n\u001b[1;32m   1547\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m-> 1549\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrapped_call_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1551\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# sample hard negatives from different db_ids?\n",
    "# check https://github.com/UKPLab/sentence-transformers/blob/master/examples/training/ms_marco/train_bi-encoder_mnrl.py\n",
    "\n",
    "# train_ds = Dataset.from_dict({\n",
    "#     'anchor': df_train['question'].tolist(),\n",
    "#     'positive': df_train['ba'].tolist(),\n",
    "# })\n",
    "\n",
    "# dev_ds = Dataset.from_dict({\n",
    "#     'anchor': df_dev['question'].tolist(),\n",
    "#     'positive': df_dev['ba'].tolist(),\n",
    "# })\n",
    "\n",
    "# Semantic similarity model\n",
    "with open(experiment_folder / 'predictions' / 'create_bo' / f'{ds}_{task}_hard_negative.json', 'r') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "train_ds = Dataset.from_generator(RetrievalDataset(data['train']).__iter__)\n",
    "dev_ds = Dataset.from_generator(RetrievalDataset(data['dev']).__iter__)\n",
    "\n",
    "args = SentenceTransformerTrainingArguments(\n",
    "    output_dir='models/all-mpnet-base-v2-q_ba',\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=100,\n",
    "    batch_sampler=BatchSamplers.NO_DUPLICATES,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    torch_empty_cache_steps=200,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "loss = losses.CachedMultipleNegativesRankingLoss(model, mini_batch_size=128)\n",
    "\n",
    "dev_evaluator = TripletEvaluator(\n",
    "    anchors=dev_ds['anchor'],\n",
    "    positives =dev_ds['positive'],\n",
    "    negatives=dev_ds['negative'],\n",
    "    name='q_ba_dev',\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=model,\n",
    "    train_dataset=train_ds,\n",
    "    loss=loss,\n",
    "    args=args,\n",
    "    eval_dataset=dev_ds,\n",
    "    evaluator=dev_evaluator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# use Precision@k to evaluate the model\n",
    "# https://github.com/UKPLab/sentence-transformers/issues/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1739"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds) // 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = 'cross-encoder/ms-marco-MiniLM-L-6-v2'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'spider'\n",
    "typ = 'dev'\n",
    "task = 'valid_bo' # 'zero_shot'\n",
    "eval_path = experiment_folder / 'evals' / task\n",
    "\n",
    "all_results = []\n",
    "for p in eval_path.glob(f'{ds}_{typ}_*.json'):\n",
    "    with p.open() as f:\n",
    "        all_results.extend(json.load(f))\n",
    "\n",
    "df = pd.DataFrame(all_results)\n",
    "df.to_csv(eval_path / f'{ds}_{typ}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'experiment_folder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# rewrite the complexity\u001b[39;00m\n\u001b[1;32m      2\u001b[0m preds \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m (\u001b[43mexperiment_folder\u001b[49m \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictions\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m task)\u001b[38;5;241m.\u001b[39mglob(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtyp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_*.json\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m p\u001b[38;5;241m.\u001b[39mopen() \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m         x \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'experiment_folder' is not defined"
     ]
    }
   ],
   "source": [
    "# rewrite the complexity\n",
    "preds = []\n",
    "for p in (experiment_folder / 'predictions' / task).glob(f'{ds}_{typ}_*.json'):\n",
    "    with p.open() as f:\n",
    "        x = json.load(f)\n",
    "        preds.append({'sample_id': x['sample_id'], 'db_id': x['db_id'], 'pred_sql': x['pred_sql']})\n",
    "\n",
    "pred_parsed, _ = get_prediction_parsed_sql(preds, tables)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = pd.read_csv(experiment_folder / 'evals' / 'zero_shot' / f'{ds}_{typ}.csv')\n",
    "df_bo = pd.read_csv(experiment_folder / 'evals' / 'valid_bo' / f'{ds}_{typ}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cates = df_base.groupby('db_id')['gold_complexity'].apply(_get_categories).rename('category').apply(_format_interval)\n",
    "df_base = pd.merge(df_base, df_cates.reset_index('db_id', drop=True), left_index=True, right_index=True)\n",
    "\n",
    "df = pd.merge(\n",
    "    left=df_bo,\n",
    "    right=df_base,\n",
    "    how='inner',\n",
    "    on=['db_id', 'sample_id', 'gold_complexity'],\n",
    "    suffixes=('_bo', '_base')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_column = ['db_id', 'retrieved']\n",
    "execution_improvement = df.groupby(group_column)[['exec_result_base', 'exec_result_bo']].sum().diff(axis=1)['exec_result_bo'].rename('execution_improvement')\n",
    "merit_structural = df.groupby(group_column)[['structural_score_base', 'structural_score_bo']].mean().diff(axis=1)['structural_score_bo'].rename('merit_structural')\n",
    "merit_semantic = df.groupby(group_column)[['semantic_score_base', 'semantic_score_bo']].mean().diff(axis=1)['semantic_score_bo'].rename('merit_semantic')\n",
    "merit = df.groupby(group_column)[['f1_score_base', 'f1_score_bo']].mean().diff(axis=1)['f1_score_bo'].rename('merit')\n",
    "\n",
    "ranks = merit.reset_index().groupby(['db_id'])['merit'].rank(method='first', ascending=False).rename('rank').astype(np.int64)\n",
    "merit = pd.concat([merit.reset_index(), ranks], axis=1)\n",
    "merit_by_rank = merit.sort_values(by=['db_id', 'rank'], ascending=True)\n",
    "\n",
    "# merit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "merit\n",
       "True     85\n",
       "False    41\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(merit_by_rank.groupby('db_id')['merit'].mean().sort_values(ascending=False) > 0.0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bos = defaultdict(list)\n",
    "for x in merit_by_rank.loc[:, ['db_id', 'retrieved']].to_dict(orient='records'):\n",
    "    test_bos[x['db_id']].append(x['retrieved'])\n",
    "\n",
    "n_bos = range(5, 26, 5)\n",
    "test_scenarios = defaultdict(dict)\n",
    "for n_bo in n_bos:\n",
    "    for db_id in test_bos:\n",
    "        test_scenarios[n_bo][db_id] = test_bos[db_id][:n_bo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (experiment_folder / 'test_scenarios.json').open('w') as f:\n",
    "    json.dump(test_scenarios, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spider_path = proj_path / 'data' / 'spider'\n",
    "# tables, train_data, dev_data = load_raw_data(spider_path, load_test=False)\n",
    "\n",
    "# with (proj_path / 'data' / 'description.json').open() as f:\n",
    "#     all_descriptions = json.load(f)\n",
    "# seed = 42\n",
    "# all_data = filter_samples_by_count_spider_bird(train_data+dev_data, n=10)\n",
    "\n",
    "# with open(proj_path / 'data' / 'bird_skip.txt') as f:\n",
    "#     skip = [int(line.strip()) for line in f]\n",
    "\n",
    "# bird_samples = process_samples_bird(all_data, bird_tables, skip=skip)\n",
    "# train_samples, dev_samples, test_samples = split_train_dev_test(bird_samples, train_ratio=0.6, dev_ratio=0.2, seed=seed)\n",
    "\n",
    "# save_samples_spider_bird(train_samples, proj_path / 'data' / 'bird_train.json')\n",
    "# save_samples_spider_bird(dev_samples, proj_path / 'data' / 'bird_dev.json')\n",
    "# save_samples_spider_bird(test_samples, proj_path / 'data' / 'bird_test.json')\n",
    "# print(len(train_samples), len(dev_samples), len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_folder = proj_path / 'experiments' / 'bird'\n",
    "# prediction_path = experiment_folder / 'predictions' / 'create_bo'\n",
    "# tables = bird_tables\n",
    "# bos = []\n",
    "# for p in prediction_path.glob('bird_train_bo_*.json'):\n",
    "#     with p.open() as f:\n",
    "#         bos = json.load(f)\n",
    "\n",
    "#     db_id = p.stem.split('_', 3)[-1]\n",
    "#     schema = Schema(tables[db_id].db_schema)\n",
    "#     for bo in bos:\n",
    "#         output = extract_all(bo['gold_sql'], schema)\n",
    "#         bo['gold_complexity'] = get_complexity(output)\n",
    "    \n",
    "#     with p.open('w') as f:\n",
    "#         json.dump(bos, f, indent=4)\n",
    "\n",
    "# bos = {}\n",
    "# for p in prediction_path.glob('bird_train_bo_*.json'):\n",
    "#     db_id = p.stem.split('_', 3)[-1]\n",
    "#     with p.open() as f:\n",
    "#         bos[db_id] = json.load(f)\n",
    "\n",
    "# with (experiment_folder / 'predictions' / 'create_bo' / f'final_bird_train_bo.json').open('w') as f:\n",
    "#     json.dump(bos, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from run_bo_sql import Sampler, get_vector_store, get_retriever\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "k_retrieval: int = 5  # for test\n",
    "n_retrieval: int = 1   # for test\n",
    "score_threshold: float = 0.65\n",
    "use_reranker: bool = True\n",
    "# TODO: run spider 4567\n",
    "ds = 'bird'\n",
    "task = 'zero_shot'\n",
    "experiment_folder = proj_path / 'experiments' / ds\n",
    "prediction_path = experiment_folder / 'predictions' / task\n",
    "eval_path = experiment_folder / 'evals' / task\n",
    "\n",
    "bo_path = experiment_folder / 'predictions' / 'create_bo' / f'final_{ds}_train_bo.json'\n",
    "with bo_path.open() as f:\n",
    "    bos = json.load(f)\n",
    "\n",
    "samples = load_samples_spider_bird(proj_path / 'data' / f'{ds}_dev.json')\n",
    "df = pd.read_csv(experiment_folder / 'evals' / 'zero_shot' / f'bird_dev.csv')\n",
    "df_score = df.loc[:, ['sample_id', 'db_id', 'exec_result']]\n",
    "df_error = df_score.loc[df_score['exec_result'] == 0, ['db_id', 'sample_id']]\n",
    "error_ids = df_error['sample_id'].tolist()\n",
    "samples = list(filter(lambda x: x.sample_id in error_ids, samples))\n",
    "\n",
    "\n",
    "samples_by_db_id = defaultdict(list)\n",
    "for sample in samples:\n",
    "    samples_by_db_id[sample.db_id].append(sample)\n",
    "\n",
    "cross_encoder = HuggingFaceCrossEncoder(model_name='cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "\n",
    "vectorstore = get_vector_store(bos)\n",
    "# dev_samples = load_samples_spider_bird(proj_path / 'data' / f'{ds}_dev.json')\n",
    "# pred_res = defaultdict(dict)  # db_id -> train_bo -> list[dict]\n",
    "# for p in prediction_path.glob(f'{ds}_dev_*.json'):\n",
    "#     name = p.stem.split('_', 2)[-1]\n",
    "#     db_id, idx = name.split('-')\n",
    "#     with p.open() as f:\n",
    "# \n",
    "#     for r in res:\n",
    "#         train_bo_id = r['retrieved']\n",
    "#         if not pred_res[db_id].get(train_bo_id):\n",
    "#             pred_res[db_id][train_bo_id] = []\n",
    "#         pred_res[db_id][r['retrieved']].append(r)\n",
    "#     break\n",
    "\n",
    "# save_path = prediction_path / f'final_{ds}_dev.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ids = []\n",
    "\n",
    "for db_id, samples in samples_by_db_id.items():\n",
    "    retriever = vectorstore.as_retriever(\n",
    "        search_type='similarity_score_threshold',\n",
    "        search_kwargs={\n",
    "            'k': k_retrieval, \n",
    "            'score_threshold': score_threshold, \n",
    "            'filter': {'db_id': db_id, 'sample_id': {'$nin' : sample_ids}},\n",
    "        }\n",
    "    )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x7ff2c8db3e90>, search_type='similarity_score_threshold', search_kwargs={'k': 5, 'score_threshold': 0.65, 'filter': {'db_id': 'movie_platform', 'sample_id': {'$nin': []}}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3385365853658537"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(eval_path / f'bird_dev.csv')\n",
    "df_score = df.loc[:, ['sample_id', 'db_id', 'exec_result']]\n",
    "df_score['exec_result'].sum() / len(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "n_sample = 3\n",
    "n_stop = 50\n",
    "typ = 'dev'\n",
    "samples = load_samples_spider_bird(proj_path / 'data' / f'{ds}_{typ}.json')\n",
    "df = pd.read_csv(experiment_folder / 'evals' / 'zero_shot' / f'{ds}_dev.csv')\n",
    "df_score = df.loc[:, ['sample_id', 'db_id', 'exec_result']]\n",
    "df_error = df_score.loc[df_score['exec_result'] == 0, ['db_id', 'sample_id']]\n",
    "error_ids = df_error['sample_id'].tolist()\n",
    "samples = list(filter(lambda x: x.sample_id in error_ids, samples))\n",
    "\n",
    "with open(experiment_folder / f'partial_{ds}_db_ids.json') as f:\n",
    "    partial_db_ids = json.load(f)\n",
    "\n",
    "bo_path = experiment_folder / 'predictions' / 'create_bo' / f'final_{ds}_train_bo.json'\n",
    "assert bo_path.exists(), 'Run with the `task=create_bo, type=train` first'\n",
    "with bo_path.open() as f:\n",
    "    bos = json.load(f)\n",
    "\n",
    "# with open(experiment_folder / f'partial_{ds}_db_ids.json', 'w') as f:\n",
    "#     json.dump(partial_db_ids, f, indent=4)\n",
    "\n",
    "sampler = Sampler(bos)\n",
    "\n",
    "sampled_bos = {}\n",
    "for db_id_group in partial_db_ids:\n",
    "    sampled_bos[str(db_id_group)] = defaultdict()\n",
    "    for db_id in partial_db_ids[str(db_id_group)]:\n",
    "        x_samples = list(filter(lambda x: x.db_id == db_id, samples))\n",
    "        for idx_bos, train_bos in enumerate(sampler.sample(db_id, n_sample, n_stop, rt_idx=False)):\n",
    "            # print(f'{db_id}-{idx_bos} :', f'{len(train_bos)}', f'{len(list(product(train_bos, x_samples)))}')\n",
    "            sampled_bos[str(db_id_group)][f'{db_id}-{idx_bos}'] = {\n",
    "                'train_bos': train_bos,\n",
    "                'n_iter': len(list(product(train_bos, x_samples))), \n",
    "                'total_bos_in_batch': len(train_bos),\n",
    "                'total_samples_in_batch': len(x_samples)\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'bird'\n",
    "task = 'zero_shot'\n",
    "experiment_folder = proj_path / 'experiments' / ds\n",
    "prediction_path = experiment_folder / 'predictions' / task\n",
    "eval_path = experiment_folder / 'evals' / task\n",
    "typ = 'dev'\n",
    "samples = load_samples_spider_bird(proj_path / 'data' / f'{ds}_{typ}.json')\n",
    "df = pd.read_csv(experiment_folder / 'evals' / 'zero_shot' / f'{ds}_dev.csv')\n",
    "df_error = df.loc[df['exec_result'] == 0]\n",
    "error_ids = df_error['sample_id'].tolist()\n",
    "samples = list(filter(lambda x: x.sample_id in error_ids, samples))\n",
    "\n",
    "with (experiment_folder / f'partial_{ds}_batch.json').open('r') as f:\n",
    "    partial_batch = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_files = 0\n",
    "for db_group_id, batch in partial_batch.items():\n",
    "    count_files += len(batch)\n",
    "count_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0] before: file = 82 bos= 644 n_iter= 8394\n",
      "[0] after: file = 59 bos= 511 n_iter= 1957\n",
      "[1] before: file = 50 bos= 411 n_iter= 4583\n",
      "[1] after: file = 45 bos= 367 n_iter= 881\n",
      "[2] before: file = 62 bos= 517 n_iter= 6707\n",
      "[2] after: file = 46 bos= 396 n_iter= 1184\n",
      "[3] before: file = 75 bos= 690 n_iter= 10838\n",
      "[3] after: file = 52 bos= 505 n_iter= 1900\n",
      "[4] before: file = 68 bos= 561 n_iter= 6246\n",
      "[4] after: file = 53 bos= 470 n_iter= 1264\n",
      "[5] before: file = 64 bos= 508 n_iter= 6218\n",
      "[5] after: file = 50 bos= 409 n_iter= 1073\n",
      "[6] before: file = 70 bos= 573 n_iter= 7298\n",
      "[6] after: file = 52 bos= 436 n_iter= 1577\n",
      "[7] before: file = 70 bos= 583 n_iter= 8072\n",
      "[7] after: file = 50 bos= 434 n_iter= 1442\n"
     ]
    }
   ],
   "source": [
    "new_partial_batch = defaultdict()\n",
    "to_be = 30\n",
    "for db_id_group, batches in partial_batch.items():\n",
    "    new_batch = defaultdict(dict)\n",
    "    db_id_count = defaultdict(int)\n",
    "    for file_name, batch in batches.items():\n",
    "        db_id, idx = file_name.split('-')\n",
    "        x_samples = list(filter(lambda x: x.db_id == db_id, samples))\n",
    "        if db_id_count[db_id] >= to_be:\n",
    "            # print('drop ', file_name)\n",
    "            continue\n",
    "\n",
    "        if db_id_count[db_id] + len(batch['train_bos']) < to_be:\n",
    "            train_bos = batch['train_bos']\n",
    "            new_batch[file_name] = {\n",
    "                'train_bos': train_bos,\n",
    "                'n_iter': len(list(product(train_bos, x_samples))),\n",
    "                'total_bos_in_batch': len(train_bos),\n",
    "                'total_samples_in_batch': len(x_samples)\n",
    "            }\n",
    "            db_id_count[db_id] += len(train_bos)\n",
    "        else: # count + len(batch['train_bos']) > to_be:\n",
    "            n = to_be - db_id_count[db_id]\n",
    "            train_bos = batch['train_bos'][:n]\n",
    "            new_batch[file_name] = {\n",
    "                'train_bos': train_bos,\n",
    "                'n_iter': len(list(product(train_bos, x_samples))),\n",
    "                'total_bos_in_batch': len(train_bos),\n",
    "                'total_samples_in_batch': len(x_samples)\n",
    "            }\n",
    "            db_id_count[db_id] += len(train_bos)\n",
    "    \n",
    "    new_partial_batch[db_id_group] = new_batch\n",
    "    \n",
    "    print(f'[{db_id_group}] before: file = {len(batches)} bos=' , sum([len(v['train_bos']) for v in batches.values()]), 'n_iter=', sum([v['n_iter'] for v in batches.values()]))\n",
    "    print(f'[{db_id_group}] after: file = {len(new_batch)} bos=' , sum([len(v['train_bos']) for v in new_batch.values()]), 'n_iter=', sum([v['n_iter'] for v in new_batch.values()]))\n",
    "    print(f'[{db_id_group}] count = {db_id_count}')\n",
    "# with (experiment_folder / f'partial_{ds}_batch.json').open('w') as f:\n",
    "#     json.dump(new_partial_batch, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (experiment_folder / f'partial_{ds}_batch-back.json').open('r') as f:\n",
    "    partial_batch = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "app_store-0 before: n_retrieved = 12 | bos = 12 | 132  --> 60\n",
      "app_store-1 before: n_retrieved = 12 | bos = 12 | 132  --> 60\n",
      "app_store-2 before: n_retrieved = 6 | bos = 6 | 66  --> 30\n",
      "app_store-3 not found: 3, delete\n",
      "app_store-4 not found: 1, delete\n",
      "authors-0 before: n_retrieved = 15 | bos = 15 | 510  --> 255\n",
      "authors-1 before: n_retrieved = 15 | bos = 15 | 510  --> 255\n",
      "authors-2 not found: 15, delete\n",
      "authors-3 not found: 5, delete\n",
      "books-0 before: n_retrieved = 15 | bos = 15 | 585  --> 180\n",
      "books-1 before: n_retrieved = 15 | bos = 15 | 585  --> 180\n",
      "books-2 not found: 15, delete\n",
      "books-3 not found: 5, delete\n",
      "california_schools-0 before: n_retrieved = 15 | bos = 15 | 255  --> 225\n",
      "california_schools-1 before: n_retrieved = 15 | bos = 15 | 255  --> 225\n",
      "california_schools-2 not found: 13, delete\n",
      "california_schools-3 not found: 6, delete\n",
      "california_schools-4 not found: 1, delete\n",
      "college_completion-0 before: n_retrieved = 15 | bos = 15 | 225  --> 225\n",
      "college_completion-1 before: n_retrieved = 15 | bos = 15 | 225  --> 225\n",
      "college_completion-2 not found: 14, delete\n",
      "college_completion-3 not found: 1, delete\n",
      "computer_student-0 before: n_retrieved = 15 | bos = 15 | 210  --> 165\n",
      "computer_student-1 before: n_retrieved = 15 | bos = 15 | 210  --> 165\n",
      "computer_student-2 not found: 11, delete\n",
      "computer_student-3 not found: 2, delete\n",
      "genes-0 before: n_retrieved = 12 | bos = 12 | 48  --> 48\n",
      "genes-1 before: n_retrieved = 1 | bos = 1 | 4  --> 4\n",
      "human_resources-0 before: n_retrieved = 15 | bos = 15 | 165  --> 135\n",
      "human_resources-1 before: n_retrieved = 14 | bos = 14 | 154  --> 126\n",
      "human_resources-2 before: n_retrieved = 6 | bos = 1 | 66  --> 54\n",
      "menu-0 before: n_retrieved = 15 | bos = 15 | 315  --> 210\n",
      "menu-1 before: n_retrieved = 15 | bos = 15 | 315  --> 210\n",
      "menu-2 not found: 14, delete\n",
      "menu-3 not found: 6, delete\n",
      "music_tracker-0 before: n_retrieved = 12 | bos = 12 | 108  --> 48\n",
      "music_tracker-1 before: n_retrieved = 11 | bos = 11 | 99  --> 44\n",
      "music_tracker-2 before: n_retrieved = 4 | bos = 4 | 36  --> 16\n",
      "olympics-0 before: n_retrieved = 15 | bos = 15 | 495  --> 240\n",
      "olympics-1 before: n_retrieved = 15 | bos = 15 | 495  --> 240\n",
      "olympics-2 not found: 15, delete\n",
      "olympics-3 not found: 5, delete\n",
      "regional_sales-0 before: n_retrieved = 15 | bos = 15 | 480  --> 435\n",
      "regional_sales-1 before: n_retrieved = 15 | bos = 15 | 480  --> 435\n",
      "regional_sales-2 not found: 15, delete\n",
      "regional_sales-3 not found: 5, delete\n",
      "retail_world-0 before: n_retrieved = 12 | bos = 12 | 156  --> 48\n",
      "retail_world-1 before: n_retrieved = 11 | bos = 11 | 143  --> 44\n",
      "retail_world-2 before: n_retrieved = 4 | bos = 4 | 52  --> 16\n",
      "retail_world-3 before: n_retrieved = 3 | bos = 3 | 39  --> 12\n",
      "retail_world-4 not found: 3, delete\n",
      "retail_world-5 not found: 3, delete\n",
      "retail_world-6 not found: 3, delete\n",
      "retail_world-7 not found: 1, delete\n",
      "retails-0 before: n_retrieved = 12 | bos = 12 | 588  --> 312\n",
      "retails-1 before: n_retrieved = 12 | bos = 12 | 588  --> 312\n",
      "shakespeare-0 before: n_retrieved = 12 | bos = 12 | 264  --> 192\n",
      "shakespeare-1 before: n_retrieved = 12 | bos = 12 | 264  --> 192\n",
      "shakespeare-2 before: n_retrieved = 12 | bos = 6 | 264  --> 192\n",
      "shakespeare-3 not found: 7, delete\n",
      "shakespeare-4 not found: 6, delete\n",
      "shakespeare-5 not found: 1, delete\n",
      "shipping-0 before: n_retrieved = 15 | bos = 15 | 315  --> 135\n",
      "shipping-1 before: n_retrieved = 15 | bos = 15 | 315  --> 135\n",
      "shipping-2 not found: 14, delete\n",
      "shipping-3 not found: 6, delete\n",
      "student_loan-0 before: n_retrieved = 12 | bos = 12 | 480  --> 168\n",
      "student_loan-1 before: n_retrieved = 12 | bos = 12 | 480  --> 168\n",
      "student_loan-2 before: n_retrieved = 12 | bos = 6 | 480  --> 168\n",
      "student_loan-3 not found: 12, delete\n",
      "student_loan-4 not found: 2, delete\n",
      "talkingdata-0 before: n_retrieved = 15 | bos = 15 | 615  --> 270\n",
      "talkingdata-1 before: n_retrieved = 15 | bos = 15 | 615  --> 270\n",
      "talkingdata-2 not found: 15, delete\n",
      "talkingdata-3 not found: 5, delete\n",
      "trains-0 before: n_retrieved = 15 | bos = 15 | 120  --> 45\n",
      "trains-1 before: n_retrieved = 7 | bos = 7 | 56  --> 21\n",
      "trains-2 before: n_retrieved = 2 | bos = 2 | 16  --> 6\n",
      "world_development_indicators-0 before: n_retrieved = 12 | bos = 12 | 372  --> 324\n",
      "world_development_indicators-1 before: n_retrieved = 12 | bos = 12 | 372  --> 324\n",
      "world_development_indicators-2 before: n_retrieved = 12 | bos = 6 | 372  --> 324\n",
      "world_development_indicators-3 not found: 12, delete\n",
      "world_development_indicators-4 not found: 2, delete\n"
     ]
    }
   ],
   "source": [
    "# 돌려 놓은거 처리\n",
    "ds = 'bird'\n",
    "task = 'valid_bo'\n",
    "experiment_folder = proj_path / 'experiments' / ds\n",
    "prediction_path = experiment_folder / 'predictions' / task\n",
    "eval_path = experiment_folder / 'evals' / task\n",
    "\n",
    "with (experiment_folder / f'partial_{ds}_batch.json').open('r') as f:\n",
    "    new_partial_batch = json.load(f)\n",
    "\n",
    "df = pd.read_csv(experiment_folder / 'evals' / 'zero_shot' / f'{ds}_dev.csv')\n",
    "df_error = df.loc[df['exec_result'] == 0]\n",
    "error_ids = df_error['sample_id'].tolist()\n",
    "count_db_ids = defaultdict(int)\n",
    "for p in sorted(prediction_path.glob(f'{ds}_dev_*.json')):\n",
    "    name = p.stem.split('_', 2)[-1]\n",
    "    db_id, idx = name.split('-')\n",
    "    # if name == 'app_store-2':\n",
    "    #     break\n",
    "    with p.open() as f:\n",
    "        res = json.load(f)\n",
    "    found = False\n",
    "    for db_id_group, batches in new_partial_batch.items():\n",
    "        if name in batches:\n",
    "            found = True\n",
    "            train_bo_ids = [x['sample_id'] for x in batches[name]['train_bos']]\n",
    "            break\n",
    "\n",
    "    if not found:\n",
    "        n_retrieved = set([x['retrieved'] for x in res])\n",
    "        p.unlink()\n",
    "        print(f'{name} not found: {len(n_retrieved)}, delete')\n",
    "    else:\n",
    "        n_retrieved = set([x['retrieved'] for x in res])\n",
    "        count_db_ids[name] += len(n_retrieved)\n",
    "        print(f'{name} before: n_retrieved = {len(n_retrieved)} | bos = {len(train_bo_ids)} | {len(res)}', end=' ')\n",
    "        # error_ids 에 있는것만 남기기\n",
    "        res = list(filter(lambda x: x['sample_id'] in error_ids, res))\n",
    "        print(f' --> {len(res)}')\n",
    "        # train_bo_ids 에 해당하는 bos만 남기기\n",
    "        if len(res) < len(list(filter(lambda x: x['retrieved'] in train_bo_ids, res))):\n",
    "            print(f'{name} before reduce bo: {len(res)}')\n",
    "            res = list(filter(lambda x: x['retrieved'] in train_bo_ids, res))\n",
    "            print(f'{name} after reduce bo: {len(res)}')\n",
    "\n",
    "        with p.open('w') as f:\n",
    "            json.dump(res, f, indent=4)\n",
    "\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "db_ids = list(bos.keys())\n",
    "partial_db_ids = {}\n",
    "n = 20\n",
    "for i in range(30):\n",
    "    if db_ids[i*n:(i+1)*n]:\n",
    "        partial_db_ids[i] = db_ids[i*n:(i+1)*n]\n",
    "print(partial_db_ids.keys())\n",
    "\n",
    "with open(experiment_folder / f'partial_{ds}_db_ids.json', 'w') as f:\n",
    "    json.dump(partial_db_ids, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(experiment_folder / f'partial_{ds}_db_ids.json') as f:\n",
    "    partial_db_ids = json.load(f)\n",
    "\n",
    "sampler = Sampler(bos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, islice\n",
    "\n",
    "def batched(iterable, n, *, strict=False):\n",
    "    # batched('ABCDEFG', 3) → ABC DEF G\n",
    "    if n < 1:\n",
    "        raise ValueError('n must be at least one')\n",
    "    iterator = iter(iterable)\n",
    "    while batch := tuple(islice(iterator, n)):\n",
    "        if strict and len(batch) != n:\n",
    "            raise ValueError('batched(): incomplete batch')\n",
    "        yield batch\n",
    "\n",
    "sampled_ids = {}\n",
    "for db_id_group in partial_db_ids:\n",
    "    sampled_ids[str(db_id_group)] = defaultdict()\n",
    "    for db_id in partial_db_ids[str(db_id_group)]:\n",
    "        x_samples = list(filter(lambda x: x.db_id == db_id, dev_samples))\n",
    "        for idx_bos, train_bos in enumerate(sampler.sample(db_id, 3, 50, rt_idx=False)):\n",
    "            # print(f'{db_id}-{idx_bos} :', f'{len(train_bos)}', f'{len(list(product(train_bos, x_samples)))}')\n",
    "            sampled_ids[str(db_id_group)][f'{db_id}-{idx_bos}'] = {\n",
    "                'train_bos': train_bos,\n",
    "                'n_iter': len(list(product(train_bos, x_samples))), \n",
    "                'total_bos_in_batch': len(train_bos)\n",
    "            }\n",
    "\n",
    "with (experiment_folder / f'partial_{ds}_batch.json').open('w') as f:\n",
    "    json.dump(sampled_ids, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "n_iter: 8394, iter per file: 102.37\n",
      "50\n",
      "n_iter: 4583, iter per file: 91.66\n",
      "62\n",
      "n_iter: 6707, iter per file: 108.18\n",
      "75\n",
      "n_iter: 10838, iter per file: 144.51\n",
      "68\n",
      "n_iter: 6246, iter per file: 91.85\n",
      "64\n",
      "n_iter: 6218, iter per file: 97.16\n",
      "70\n",
      "n_iter: 7298, iter per file: 104.26\n",
      "70\n",
      "n_iter: 8072, iter per file: 115.31\n"
     ]
    }
   ],
   "source": [
    "for db_id_group in partial_db_ids:\n",
    "    print(len(sampled_ids[str(db_id_group)]))\n",
    "    niters = [x['n_iter'] for x in sampled_ids[str(db_id_group)].values()]\n",
    "    print(f'n_iter: {sum(niters)}, iter per file: {np.mean(niters):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "for db_id, bs in bos.items():\n",
    "    for b in bs:\n",
    "        res = {'db_id': db_id, 'gold_complexity': b['gold_complexity']}\n",
    "        df.append(res)\n",
    "\n",
    "df = pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import pairwise\n",
    "\n",
    "def _format_interval(x: pd.Interval):\n",
    "    return pd.Interval(\n",
    "        left=int(np.floor(x.left)), \n",
    "        right=int(np.floor(x.right)),\n",
    "        closed=x.closed\n",
    "    )\n",
    "\n",
    "def _get_categories(s: pd.Series):\n",
    "    tiles = [0, 0.2, 0.4, 0.6, 0.8, 1]\n",
    "    df = pd.qcut(s, q=tiles, duplicates='drop')\n",
    "    return df\n",
    "\n",
    "def _get_df_from_bos(bos):\n",
    "    df = []\n",
    "    for db_id, bs in bos.items():\n",
    "        for b in bs:\n",
    "            res = {'db_id': db_id}\n",
    "            res.update(b)\n",
    "            df.append(res)\n",
    "    df = pd.DataFrame(df)\n",
    "    df_cates = df.groupby('db_id')['gold_complexity'].apply(_get_categories)\n",
    "    df_cates = df_cates.rename('category').apply(_format_interval)\n",
    "    df = df.merge(df_cates.reset_index('db_id', drop=True), left_index=True, right_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 'bird'\n",
    "task = 'zero_shot_hint'\n",
    "typ = 'dev'\n",
    "experiment_folder = proj_path / 'experiments' / ds\n",
    "prediction_path = experiment_folder / 'predictions' / task\n",
    "eval_path = experiment_folder / 'evals' / task\n",
    "\n",
    "# file_name = f'{ds}_{typ}_parsed.pkl'\n",
    "# with (eval_path / file_name).open('rb') as f:\n",
    "#     target_parsed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/simonjisu/code/BusinessObjects/experiments/bird')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_path.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'sample_id': 5156,\n",
       "  'vt': \"SELECT area_code.area_code, country.county FROM area_code INNER JOIN country AS T2 ON T1.zip_code = T2.zip_code INNER JOIN zip_data AS T3 ON T1.zip_code = T3.zip_code WHERE zip_data.city = '[placeholder-type:string]'\",\n",
       "  'ba': \"The virtual table provides the area code and county information for a specific city based on its zip code. It combines data from the 'area_code', 'country', and 'zip_data' tables, filtering results to match the specified city name.\",\n",
       "  'gold_complexity': 10,\n",
       "  'gold_sql': \"SELECT T1.area_code, T2.county FROM area_code AS T1 INNER JOIN country AS T2 ON T1.zip_code = T2.zip_code INNER JOIN zip_data AS T3 ON T1.zip_code = T3.zip_code WHERE T3.city = 'Savoy'\"},\n",
       " {'sample_id': 5211,\n",
       "  'vt': 'SELECT alias.alias FROM alias INNER JOIN zip_data AS T2 ON T1.zip_code = T2.zip_code WHERE zip_data.population_2020 = (SELECT MAX(zip_data.population_2020) FROM zip_data)',\n",
       "  'ba': \"The virtual table retrieves the aliases of cities from the 'alias' table that correspond to the zip codes with the highest population recorded in 2020 from the 'zip_data' table. The query uses an inner join to connect the 'alias' and 'zip_data' tables based on the zip code, ensuring that only the aliases for the most populated areas are selected.\",\n",
       "  'gold_complexity': 11,\n",
       "  'gold_sql': 'SELECT T1.alias FROM alias AS T1 INNER JOIN zip_data AS T2 ON T1.zip_code = T2.zip_code WHERE T2.population_2020 = ( SELECT MAX(population_2020) FROM zip_data )'},\n",
       " {'sample_id': 5227,\n",
       "  'vt': \"SELECT zip_congress.district FROM zip_data INNER JOIN zip_congress AS T2 ON T1.zip_code = T2.zip_code WHERE zip_data.city = '[placeholder-type:string]'\",\n",
       "  'ba': \"The virtual table retrieves the district information associated with a specific city from the 'zip_data' table by joining it with the 'zip_congress' table. The placeholder in the WHERE clause represents the name of the city for which the district is being queried.\",\n",
       "  'gold_complexity': 7,\n",
       "  'gold_sql': \"SELECT T2.district FROM zip_data AS T1 INNER JOIN zip_congress AS T2 ON T1.zip_code = T2.zip_code WHERE T1.city = 'East Springfield'\"},\n",
       " {'sample_id': 5091,\n",
       "  'vt': \"SELECT COUNT(zip_data.zip_code) FROM zip_data INNER JOIN avoid AS T2 ON T1.zip_code = T2.zip_code WHERE avoid.bad_alias = '[placeholder-type:string]' AND zip_data.time_zone = '[placeholder-type:string]'\",\n",
       "  'ba': \"The virtual table counts the number of zip codes from the 'zip_data' table that are associated with bad aliases from the 'avoid' table. It filters the results based on a specific bad alias and a specified time zone.\",\n",
       "  'gold_complexity': 8,\n",
       "  'gold_sql': \"SELECT COUNT(T1.zip_code) FROM zip_data AS T1 INNER JOIN avoid AS T2 ON T1.zip_code = T2.zip_code WHERE T2.bad_alias = 'Internal Revenue Service' AND T1.time_zone = 'Eastern'\"}]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos['address'][:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 85\n",
      "\tPrompt Tokens: 51\n",
      "\tCompletion Tokens: 34\n",
      "Successful Requests: 1\n",
      "Total Cost (USD): $2.805e-05\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain_community.callbacks.manager import get_openai_callback\n",
    "\n",
    "class Out(BaseModel):\n",
    "    response: str\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0,\n",
    "    stream_usage=True,\n",
    ")\n",
    "model = llm.with_structured_output(Out)\n",
    "\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    result = model.invoke(\"Tell me a joke with JSON format\")\n",
    "    print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.26582278481013 46.229123611557306 11 280\n"
     ]
    }
   ],
   "source": [
    "samples_by_db_id = defaultdict(list)\n",
    "for sample in train_samples:\n",
    "    samples_by_db_id[sample.db_id].append(sample)\n",
    "\n",
    "x = []\n",
    "for db_id, samples in samples_by_db_id.items():\n",
    "    x.append(len(samples))\n",
    "\n",
    "print(np.mean(x), np.std(x), np.min(x), np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.468354430379748 15.462355628942769 3 93\n"
     ]
    }
   ],
   "source": [
    "samples_by_db_id = defaultdict(list)\n",
    "for sample in dev_samples:\n",
    "    samples_by_db_id[sample.db_id].append(sample)\n",
    "\n",
    "x = []\n",
    "for db_id, samples in samples_by_db_id.items():\n",
    "    x.append(len(samples))\n",
    "\n",
    "print(np.mean(x), np.std(x), np.min(x), np.max(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(proj_path / 'data' / 'pkl_files' / 'bird_train_parsed.pkl', 'rb') as f:\n",
    "#     train_parsed = pickle.load(f)\n",
    "\n",
    "# # prediction parsed\n",
    "# with open(proj_path / 'data' / 'pkl_files' / 'bird_dev_parsed.pkl', 'rb') as f:\n",
    "#     dev_parsed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_path = proj_path / 'experiments' / 'bird' / 'evals' / 'zero_shot'\n",
    "\n",
    "df = []\n",
    "for p in eval_path.glob('bird_dev_*.json'):\n",
    "    with p.open() as f:\n",
    "        for line in f:\n",
    "            eval_data = json.loads(line)\n",
    "            df.append(eval_data)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "df.to_csv(eval_path / 'bird_dev.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean      0.450361\n",
       "std       0.055482\n",
       "min       0.318118\n",
       "max       0.726155\n",
       "median    0.446118\n",
       "Name: gold_complexity, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gold_complexity'].agg(['mean', 'std', 'min', 'max', 'median'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_path = proj_path / 'experiments' / 'bird' / 'predictions' / 'create_bo'\n",
    "bos = defaultdict(list)\n",
    "for p in prediction_path.glob('bird_train_bo_*.json'):\n",
    "    with p.open() as f:\n",
    "        temp = json.load(f)\n",
    "    \n",
    "    bos[p.stem.split('_', 3)[-1]] = temp\n",
    "\n",
    "# with (prediction_path / 'final_bird_train_bo.json').open('w') as f:\n",
    "#     json.dump(bos, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = get_vector_store({'address': bos['address'][:10]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5156, 5211, 5227, 5091, 5152, 5128, 5200, 5119, 5194, 5141]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[b['sample_id'] for b in bos['address'][:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sample_id': 5156,\n",
       " 'vt': \"SELECT area_code.area_code, country.county FROM area_code INNER JOIN country AS T2 ON T1.zip_code = T2.zip_code INNER JOIN zip_data AS T3 ON T1.zip_code = T3.zip_code WHERE zip_data.city = '[placeholder-type:string]'\",\n",
       " 'ba': \"The virtual table provides the area code and county information for a specific city based on its zip code. It combines data from the 'area_code', 'country', and 'zip_data' tables, filtering results to match the specified city name.\"}"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bos['address'][:10][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
    "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
    "base_retriever = vector_store.as_retriever(\n",
    "    search_type='similarity_score_threshold', \n",
    "    search_kwargs={\n",
    "        'k': 3,\n",
    "        'score_threshold': 0.3, 'filter': {'sample_id': {'$nin': []}}\n",
    "    }\n",
    ")\n",
    "\n",
    "# 'lambda_mult': 0.5  'score_threshold': 0.0\n",
    "# 'filter': {'sample_id': {'$in': [5156]}}}\n",
    "model = HuggingFaceCrossEncoder(model_name='cross-encoder/ms-marco-MiniLM-L-6-v2')\n",
    "compressor = CrossEncoderReranker(model=model, top_n=1)\n",
    "retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor, base_retriever=base_retriever\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = 'what is the aliases of cities along with their elevation?'\n",
    "x = base_retriever.invoke(q)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = vector_store.similarity_search_with_relevance_scores(\n",
    "    q, k=2, filter={'sample_id': {'$nin': [5152, 5211, 5194]}})\n",
    "x\n",
    "# similarity_search_with_relevance_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'sample_id': 5152, 'db_id': 'address', 'vt': 'SELECT alias.alias, zip_data.elevation FROM alias INNER JOIN zip_data AS T2 ON T1.zip_code = T2.zip_code WHERE alias.zip_code = [placeholder-type:numeric]'}, page_content=\"The virtual table describes the aliases of cities along with their elevation from the 'zip_data' table. The query joins the 'alias' table with the 'zip_data' table based on the zip code, filtering for a specific zip code using a placeholder for numeric values.\"),\n",
       "  0.7825041385389271),\n",
       " (Document(metadata={'sample_id': 5211, 'db_id': 'address', 'vt': 'SELECT alias.alias FROM alias INNER JOIN zip_data AS T2 ON T1.zip_code = T2.zip_code WHERE zip_data.population_2020 = (SELECT MAX(zip_data.population_2020) FROM zip_data)'}, page_content=\"The virtual table retrieves the aliases of cities from the 'alias' table that correspond to the zip codes with the highest population recorded in 2020 from the 'zip_data' table. The query uses an inner join to connect the 'alias' and 'zip_data' tables based on the zip code, ensuring that only the aliases for the most populated areas are selected.\"),\n",
       "  0.7281931194919099),\n",
       " (Document(metadata={'sample_id': 5194, 'db_id': 'address', 'vt': \"SELECT avoid.bad_alias FROM avoid INNER JOIN zip_data AS T2 ON T1.zip_code = T2.zip_code WHERE zip_data.city = '[placeholder-type:string]'\"}, page_content=\"The virtual table retrieves the bad aliases associated with a specific city from the 'avoid' table by joining it with the 'zip_data' table based on the zip code. The placeholder in the WHERE clause represents the name of the city for which we want to find bad aliases.\"),\n",
       "  0.691056772625688),\n",
       " (Document(metadata={'sample_id': 5227, 'db_id': 'address', 'vt': \"SELECT zip_congress.district FROM zip_data INNER JOIN zip_congress AS T2 ON T1.zip_code = T2.zip_code WHERE zip_data.city = '[placeholder-type:string]'\"}, page_content=\"The virtual table retrieves the district information associated with a specific city from the 'zip_data' table by joining it with the 'zip_congress' table. The placeholder in the WHERE clause represents the name of the city for which the district is being queried.\"),\n",
       "  0.6538844955711105)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_and_similarities = [\n",
    "    (doc, similarity)\n",
    "    for doc, similarity in x\n",
    "    if similarity >= 0.5\n",
    "]\n",
    "docs_and_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(bos: dict[str, list[dict[str, str]]]):\n",
    "    documents = []\n",
    "    for db_id, samples in bos.items():\n",
    "        for x in samples:\n",
    "            doc = Document(\n",
    "                doc_id=x['sample_id'],\n",
    "                page_content=x['ba'],\n",
    "                metadata={\n",
    "                    'sample_id': x['sample_id'],\n",
    "                    'db_id': db_id,\n",
    "                    'vt': x['vt']\n",
    "                }\n",
    "            )\n",
    "            documents.append(doc)\n",
    "\n",
    "    embeddings_model = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents, \n",
    "        embedding = embeddings_model,\n",
    "    )\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = get_vector_store(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sql_bo(\n",
    "    to_pred_samples: list[SpiderSample|BirdSample],\n",
    "    tables: dict[DatabaseModel],\n",
    "    vectorstore: FAISS,\n",
    "    chain: RunnableSequence,\n",
    "    prediction_path: Path,\n",
    "    file_name: str = '[args.ds]_[args.type]',\n",
    "    n_retrieval: int = 3,\n",
    "    score_threshold: float = 0.65,\n",
    "):\n",
    "    processed_db_ids = [p.stem.split('_')[-1] for p in prediction_path.glob(f'{file_name}_*')]\n",
    "    # restart from checkpoint\n",
    "    if processed_db_ids:\n",
    "        to_pred_samples = [sample for sample in to_pred_samples if sample.db_id not in processed_db_ids]\n",
    "    \n",
    "    samples_by_db_id = defaultdict(list)\n",
    "    for sample in to_pred_samples:\n",
    "        samples_by_db_id[sample.db_id].append(sample)\n",
    "\n",
    "    for db_id, samples in samples_by_db_id.items():\n",
    "        retriever = vectorstore.as_retriever(\n",
    "            search_kwargs={'k': n_retrieval, 'score_threshold': score_threshold, 'filter': {'db_id': db_id}}\n",
    "        )\n",
    "        schema_str = get_schema_str(\n",
    "            schema=tables[db_id].db_schema, \n",
    "            foreign_keys=tables[db_id].foreign_keys,\n",
    "            col_explanation=tables[db_id].col_explanation\n",
    "        )\n",
    "        results = []\n",
    "        for sample in tqdm(samples, total=len(samples), desc=f\"{db_id}\"):\n",
    "            question = sample.final.question\n",
    "            docs = retriever.invoke(question)\n",
    "            hint = '\\nDescriptions and Virtual Tables:\\n'\n",
    "            hint += json.dumps({j: {'description': doc.page_content, 'virtual_table': doc.metadata['vt']} for j, doc in enumerate(docs)}, indent=4)\n",
    "            hint += '\\n'\n",
    "            input_data = {'schema': schema_str, 'input_query': question, 'hint': hint}\n",
    "            output = chain.invoke(input=input_data)\n",
    "            \n",
    "            full_sql_output = {}\n",
    "            full_sql_output['sample_id'] = sample.sample_id\n",
    "            full_sql_output['rationale'] = output.rationale\n",
    "            full_sql_output['pred_sql'] = output.full_sql_query\n",
    "            # full_sql_output = 1\n",
    "            results.append(full_sql_output)\n",
    "\n",
    "        with open(prediction_path / f'{file_name}_{db_id}.json', 'w') as f:\n",
    "            json.dump(results, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "movie_platform: 100%|██████████| 10/10 [00:04<00:00,  2.34it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# with open(proj_path / 'data' / 'pkl_files' / 'bird_train_bo.json', 'r') as f:\n",
    "#     bos = json.load(res, f, indent=4)\n",
    "# vectorstore = get_vector_store(bos)\n",
    "\n",
    "\n",
    "data_path = proj_path / 'data' / 'bird'\n",
    "experiment_folder = proj_path / 'experiments' / 'bird'\n",
    "prediction_path = experiment_folder / 'predictions' / 'zero_shot_hint'\n",
    "eval_path = experiment_folder / 'evals'\n",
    "for p in [prediction_path, eval_path]:\n",
    "    if not p.exists():\n",
    "        p.mkdir(parents=True)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=Prompts.zero_shot_hints_inference,\n",
    "    input_variables=['schema', 'input_query', 'hint'],\n",
    ")\n",
    "\n",
    "model_openai = ChatOpenAI(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0.0,\n",
    "    frequency_penalty=0.1,\n",
    ")\n",
    "\n",
    "model = model_openai.with_structured_output(SQLResponse)\n",
    "chain = (prompt | model)\n",
    "\n",
    "n_retrieval = 3\n",
    "score_threshold = 0.65\n",
    "\n",
    "predict_sql_bo(\n",
    "    to_pred_samples=dev_samples[:10],\n",
    "    tables=bird_tables,\n",
    "    vectorstore=vectorstore,\n",
    "    chain=chain,\n",
    "    prediction_path=prediction_path,\n",
    "    n_retrieval=n_retrieval,\n",
    "    score_threshold=score_threshold,\n",
    "    file_name='bird_dev',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Descriptions and Virtual Tables:\n",
      "{\n",
      "    \"0\": {\n",
      "        \"description\": \"The virtual table retrieves the titles of movies that have been rated, filtering by a specific rating timestamp and grouping the results by movie title. The results are ordered by the count of ratings for each movie title, and a limit is applied to restrict the number of returned titles.\",\n",
      "        \"virtual_table\": \"SELECT movies.movie_title FROM ratings INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE ratings.rating_timestamp_utc LIKE '[placeholder-type:string]' GROUP BY movies.movie_title ORDER BY COUNT(movies.movie_title) LIMIT [placeholder-type:numeric]\"\n",
      "    },\n",
      "    \"1\": {\n",
      "        \"description\": \"The virtual table provides a count of users who have rated a specific movie, identified by its title, while also filtering for users who were trialists at the time of rating. It combines data from the 'ratings' and 'movies' tables to achieve this.\",\n",
      "        \"virtual_table\": \"SELECT COUNT(ratings.user_id) FROM ratings INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE movies.movie_title = '[placeholder-type:string]' AND ratings.user_trialist = [placeholder-type:numeric]\"\n",
      "    },\n",
      "    \"2\": {\n",
      "        \"description\": \"The virtual table retrieves the titles of movies that have been rated, ordered by the number of likes received on the critics' comments. The query joins the 'ratings' table with the 'movies' table to access the movie titles associated with each rating. The result is limited to a specified number of entries, allowing users to see the most liked critics' comments for rated movies.\",\n",
      "        \"virtual_table\": \"SELECT movies.movie_title FROM ratings INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id ORDER BY ratings.critic_likes LIMIT [placeholder-type:numeric]\"\n",
      "    },\n",
      "    \"3\": {\n",
      "        \"description\": \"The virtual table displays the titles of movies from the 'movies' table that have received a certain number of likes on user-written critiques. The query joins the 'ratings' table with the 'movies' table to filter movies based on the number of likes their critiques have received, using a placeholder for the minimum number of likes.\",\n",
      "        \"virtual_table\": \"SELECT movies.movie_title FROM ratings INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE ratings.critic_likes > [placeholder-type:numeric]\"\n",
      "    },\n",
      "    \"4\": {\n",
      "        \"description\": \"The virtual table counts the number of ratings for a specific movie title from the 'movies' table, filtering by the movie's title and a specified rating timestamp. The placeholders represent the movie title and the date from which to count ratings.\",\n",
      "        \"virtual_table\": \"SELECT COUNT(ratings.rating_id) FROM ratings INNER JOIN movies AS T2 ON T1.movie_id = T2.movie_id WHERE movies.movie_title = '[placeholder-type:string]' AND ratings.rating_timestamp_utc >= '[placeholder-type:string]'\"\n",
      "    }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "docs = retriever.invoke(sample.final.question)\n",
    "hint = '\\nDescriptions and Virtual Tables:\\n'\n",
    "hint += json.dumps({j: {'description': doc.page_content, 'virtual_table': doc.metadata['vt']} for j, doc in enumerate(docs)}, indent=4)\n",
    "hint += '\\n'\n",
    "input_data = {'schema': db_schema, 'input_query': row['question'], 'hint': hint}\n",
    "output = chain.invoke(input=input_data)\n",
    "\n",
    "print(hint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity between dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "movie_platform:   0%|          | 0/6341 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "debit_card_specializing: 100%|██████████| 6341/6341 [00:21<00:00, 299.00it/s]    \n",
      "debit_card_specializing: 100%|██████████| 2091/2091 [00:05<00:00, 408.98it/s]    \n",
      "debit_card_specializing: 100%|██████████| 2193/2193 [00:09<00:00, 225.64it/s]    \n"
     ]
    }
   ],
   "source": [
    "def get_parsed_sql(samples: dict, tables: dict):\n",
    "    error_ids = []\n",
    "    parsed = defaultdict(dict)\n",
    "    iterator = tqdm(samples, total=len(samples))\n",
    "    for sample in iterator:\n",
    "        db_id = sample.db_id\n",
    "        sample_id = sample.sample_id\n",
    "        iterator.set_description(f\"{db_id}\")\n",
    "        schema = Schema(tables[db_id].db_schema)\n",
    "        sql_i = sample.final.sql\n",
    "        try:\n",
    "            ei = extract_all(sql_i, schema)\n",
    "            assert len(ei['sel']) > 0, f'No selection found-{db_id}-{sample_id}'\n",
    "        except Exception as e:\n",
    "            error_ids.append((db_id, sample_id, str(e)))\n",
    "            parsed[db_id].append(None)\n",
    "            continue\n",
    "        parsed[db_id][sample_id] = ei\n",
    "    return parsed, error_ids\n",
    "\n",
    "train_parsed, error_ids = get_parsed_sql(train_samples, bird_tables)\n",
    "dev_parsed, error_ids = get_parsed_sql(dev_samples, bird_tables)\n",
    "test_parsed, error_ids = get_parsed_sql(test_samples, bird_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(proj_path / 'data' / 'pkl_files' / 'bird_train_parsed.pkl', 'wb') as f:\n",
    "#     pickle.dump(train_parsed, f)\n",
    "\n",
    "# with open(proj_path / 'data' / 'pkl_files' / 'bird_dev_parsed.pkl', 'wb') as f:\n",
    "#     pickle.dump(dev_parsed, f)\n",
    "\n",
    "# with open(proj_path / 'data' / 'pkl_files' / 'bird_test_parsed.pkl', 'wb') as f:\n",
    "#     pickle.dump(test_parsed, f)\n",
    "\n",
    "with open(proj_path / 'data' / 'pkl_files' / 'bird_dev_parsed.pkl', 'rb') as f:\n",
    "    dev_parsed = pickle.load(f)\n",
    "\n",
    "with open(proj_path / 'data' / 'pkl_files' / 'bird_test_parsed.pkl', 'rb') as f:\n",
    "    test_parsed = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations, product\n",
    "from collections import defaultdict\n",
    "from src.eval_utils import get_all_partial_score\n",
    "\n",
    "def measure_inter_score(parsed1: dict[str, tuple], parsed2: dict[str, tuple]):\n",
    "    results = defaultdict()\n",
    "    assert len(parsed1) == len(parsed2), f\"Length mismatch-1: {len(parsed1)} 2:{len(parsed2)}\"\n",
    "    db_ids = list(parsed1.keys())\n",
    "    for db_id in db_ids:\n",
    "        o1 = parsed1[db_id]\n",
    "        o2 = parsed2[db_id]\n",
    "        n1 = len(o1)\n",
    "        n2 = len(o2)\n",
    "        semantic_sim = np.zeros((n1, n2), dtype=np.float32)\n",
    "        structural_sim = np.zeros((n1, n2), dtype=np.float32)\n",
    "        overall_sim = np.zeros((n1, n2), dtype=np.float32)\n",
    "\n",
    "        idxs = list(product(range(n1), range(n2)))\n",
    "        iterator = tqdm(idxs, total=len(idxs), desc=f\"{db_id}\")\n",
    "        for i, j in iterator:\n",
    "            ei = o1[i]\n",
    "            ej = o2[j]\n",
    "\n",
    "            _, final_score = get_all_partial_score(ei, ej, use_bert=True)\n",
    "\n",
    "            structural_sim[i, j] = final_score['structural']\n",
    "            semantic_sim[i, j] = final_score['semantic']\n",
    "            overall_sim[i, j] = final_score['overall']\n",
    "\n",
    "        results[db_id] = {\n",
    "            'semantic': semantic_sim,\n",
    "            'struct': structural_sim,\n",
    "            'overall': overall_sim\n",
    "        }\n",
    "    return results\n",
    "\n",
    "results = measure_inter_score(dev_parsed, test_parsed)\n",
    "with (proj_path / 'data' / 'pkl_files' / 'bird_dev_test_similarity.pkl').open('wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complexity between datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6341/6341 [00:10<00:00, 631.17it/s]\n",
      "100%|██████████| 2091/2091 [00:03<00:00, 589.55it/s]\n",
      "100%|██████████| 2193/2193 [00:03<00:00, 591.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def measure_complexity(samples, tables):\n",
    "    cs = []\n",
    "    for s in tqdm(samples, total=len(samples)):\n",
    "        schema = Schema(tables[s.db_id].db_schema)\n",
    "        output = extract_all(s.final.sql, schema)\n",
    "        complexity = get_complexity(output)\n",
    "        cs.append(complexity)\n",
    "    return cs\n",
    "\n",
    "train_complexities = measure_complexity(train_samples, bird_tables)\n",
    "dev_complexities = measure_complexity(dev_samples, bird_tables)\n",
    "test_complexities = measure_complexity(test_samples, bird_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train] Mean=0.2753 +/-0.0476, Median=0.2710\n",
      "[dev  ] Mean=0.2758 +/-0.0471, Median=0.2710\n",
      "[test ] Mean=0.2760 +/-0.0477, Median=0.2709\n"
     ]
    }
   ],
   "source": [
    "for c, n in zip([train_complexities, dev_complexities, test_complexities], ['train', 'dev  ', 'test ']):\n",
    "    print(f'[{n}] Mean={np.mean(c):.4f} +/-{np.std(c):.4f}, Median={np.median(c):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = defaultdict(list)\n",
    "for s in dev_samples:\n",
    "    stats[s.db_id].append(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
