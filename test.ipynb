{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gpt-4o-mini\n",
    "* gemini-1.5-pro\n",
    "* gemini-1.5-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train: 3034 | Number of dev: 422\n"
     ]
    }
   ],
   "source": [
    "# create database\n",
    "import duckdb\n",
    "from src.database import Database\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.db_utils import get_schema_str, get_data_dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "data_type = 'train'\n",
    "def load_sparc_data(data_path: Path):\n",
    "    with (data_path / f'tables.json').open() as f:\n",
    "        data_tables = json.load(f)\n",
    "    with (data_path / f'train.json').open() as f:\n",
    "        train_data = json.load(f)\n",
    "    with (data_path / f'dev.json').open() as f:\n",
    "        dev_data = json.load(f)\n",
    "    return data_tables, train_data, dev_data\n",
    "\n",
    "duckdb.sql('INSTALL sqlite')\n",
    "\n",
    "proj_path = Path('.').resolve()\n",
    "sparc_path = proj_path / 'data' / 'sparc'\n",
    "\n",
    "db_id = 'hospital_1'\n",
    "db = Database(db_file=str(sparc_path / 'database' / db_id / f'{db_id}.sqlite'))\n",
    "\n",
    "tables, train_data, dev_data = load_sparc_data(sparc_path)\n",
    "print(f'Number of train: {len(train_data)} | Number of dev: {len(dev_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class DatabaseModel(BaseModel):\n",
    "    db_id: str\n",
    "    db_schema: dict[str, dict[str, str]]\n",
    "    col_explanation: dict[str, str]\n",
    "    foreign_keys: list[str]\n",
    "    primary_keys: list[str]\n",
    "\n",
    "class QuestionSQL(BaseModel):\n",
    "    question: str\n",
    "    sql: str\n",
    "\n",
    "class SparcSample(BaseModel):\n",
    "    sample_id: int = -1\n",
    "    db_id: str\n",
    "    interactions: list[QuestionSQL]\n",
    "    final: QuestionSQL\n",
    "\n",
    "def preprocess_sql(sql: str) -> str:\n",
    "    return sql.replace('\"', \"'\").strip()\n",
    "\n",
    "def process_all_tables(tables: list) -> dict[str, DatabaseModel]:\n",
    "    database = defaultdict(DatabaseModel)\n",
    "    for table in tables:\n",
    "        db_id = table['db_id']\n",
    "        data_dict = get_data_dict(table)\n",
    "        database[db_id] = DatabaseModel(\n",
    "            db_id=db_id,\n",
    "            db_schema=data_dict['schema'],\n",
    "            col_explanation=data_dict['col_explanation'],\n",
    "            foreign_keys=data_dict['foreign_keys'],\n",
    "            primary_keys=data_dict['primary_keys']\n",
    "        )\n",
    "    return database\n",
    "\n",
    "def filter_samples_by_count(all_data: dict, n: int=5) -> list:\n",
    "    counter = defaultdict(int)\n",
    "    for data in all_data:\n",
    "        db_id = data['database_id']\n",
    "        counter[db_id] += 1\n",
    "    all_data = list(filter(lambda x: counter[x['database_id']] >= n, all_data))\n",
    "    return all_data\n",
    "\n",
    "def process_samples(all_data: list) -> dict[str, list[SparcSample]]:\n",
    "    data_by_db_id = defaultdict(list)\n",
    "    for i, data in enumerate(all_data):\n",
    "        db_id = data['database_id']\n",
    "        sample = SparcSample(\n",
    "            sample_id=i,\n",
    "            db_id=db_id,\n",
    "            interactions=[\n",
    "                QuestionSQL(question=x['utterance'], sql=preprocess_sql(x['query'])) for x in data['interaction']\n",
    "            ],\n",
    "            final=QuestionSQL(\n",
    "                question=data['final']['utterance'], \n",
    "                sql=preprocess_sql(data['final']['query']), \n",
    "            )\n",
    "        )\n",
    "        data_by_db_id[db_id].append(sample)\n",
    "    return data_by_db_id\n",
    "\n",
    "def split_train_dev(sparc_samples: dict, ratio: float=0.8):\n",
    "    train_samples = []\n",
    "    dev_samples = []\n",
    "    for db_id, samples in sparc_samples.items():\n",
    "        n_train = int(len(samples) * ratio)\n",
    "        assert len(samples[n_train:]) > 0, f'Not enough samples for dev set: {db_id}'\n",
    "        train_samples.extend(samples[:n_train])\n",
    "        dev_samples.extend(samples[n_train:])\n",
    "    return train_samples, dev_samples\n",
    "\n",
    "sparc_tables = process_all_tables(tables)\n",
    "# filter samples by count, must have at least 5 samples\n",
    "all_data = filter_samples_by_count(train_data+dev_data, n=5)\n",
    "# process samples -> {db_id: list of samples}\n",
    "sparc_samples = process_samples(all_data)\n",
    "# change train/dev by sample\n",
    "train_samples, dev_samples = split_train_dev(sparc_samples, ratio=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel as LCBaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sparc_schema_description(proj_path: Path, sparc_tables: dict) -> dict:\n",
    "\n",
    "    class Description(LCBaseModel):\n",
    "        output: dict[str, dict[str, str]] = Field(description='Description of each column for all tables in the database')\n",
    "\n",
    "    template = '''### Task\n",
    "    You are tasked with writing one line short description for each column name in a database to help users understand the data better.\n",
    "    You will be proveded a schema with table names and column names.\n",
    "\n",
    "    ### Formatting\n",
    "    Your output should be of the following JSON format with `output` key and value as a dictionary of table names and column names with their descriptions.:\n",
    "    {{\n",
    "        \"<table_name1>\" : {{\n",
    "            \"<column_name>\": <str: the one line short description of column>,\n",
    "            ...\n",
    "        }},\n",
    "        ...\n",
    "    }} \n",
    "\n",
    "    ### Output\n",
    "    <SCHEMA>:\\n{schema}\n",
    "    <OUTPUT>: \n",
    "    '''\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=['schema']\n",
    "    )\n",
    "\n",
    "    model_openai = ChatOpenAI(\n",
    "        model='gpt-4o-mini',\n",
    "        temperature=0.2,\n",
    "    )\n",
    "\n",
    "    chain = (prompt | model_openai | JsonOutputParser(pydantic_object=Description))\n",
    "\n",
    "    all_descriptions = {}\n",
    "    for db_id, database_model in tqdm(sparc_tables.items(), total=len(sparc_tables)):\n",
    "        schema_desc = chain.invoke(input={'schema': get_schema_str(database_model.db_schema)})\n",
    "        all_descriptions[db_id] = schema_desc\n",
    "\n",
    "    with (proj_path / 'db_data' / 'sparc_description.json').open('w') as f:\n",
    "        json.dump(all_descriptions, f, indent=4)\n",
    "\n",
    "# get_sparc_schema_description(proj_path, sparc_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Name: Physician\n",
      "  - 'EmployeeID'(text): Unique identifier for each physician.\n",
      "  - 'Name'(text): Full name of the physician.\n",
      "  - 'Position'(text): Job title or role of the physician.\n",
      "  - 'SSN'(text): Social Security Number of the physician.\n",
      "Table Name: Department\n",
      "  - 'DepartmentID'(number): Unique identifier for each department.\n",
      "  - 'Name'(number): Name of the department.\n",
      "  - 'Head'(number): Identifier for the head of the department.\n",
      "Table Name: Affiliated_With\n",
      "  - 'Physician'(text): Identifier for the physician.\n",
      "  - 'Department'(text): Identifier for the department.\n",
      "  - 'PrimaryAffiliation'(text): Indicates if this is the primary affiliation.\n",
      "Table Name: Procedures\n",
      "  - 'Code'(text): Unique code for each medical procedure.\n",
      "  - 'Name'(text): Name of the medical procedure.\n",
      "  - 'Cost'(text): Cost associated with the procedure.\n",
      "Table Name: Trained_In\n",
      "  - 'Physician'(number): Identifier for the physician.\n",
      "  - 'Treatment'(number): Identifier for the treatment.\n",
      "  - 'CertificationDate'(number): Date when the physician was certified.\n",
      "  - 'CertificationExpires'(number): Date when the certification expires.\n",
      "Table Name: Patient\n",
      "  - 'SSN'(number): Social Security Number of the patient.\n",
      "  - 'Name'(number): Full name of the patient.\n",
      "  - 'Address'(number): Residential address of the patient.\n",
      "  - 'Phone'(number): Contact phone number of the patient.\n",
      "  - 'InsuranceID'(number): Identifier for the patient's insurance.\n",
      "  - 'PCP'(number): Identifier for the patient's primary care physician.\n",
      "Table Name: Nurse\n",
      "  - 'EmployeeID'(text): Unique identifier for each nurse.\n",
      "  - 'Name'(text): Full name of the nurse.\n",
      "  - 'Position'(text): Job title or role of the nurse.\n",
      "  - 'Registered'(text): Indicates if the nurse is registered.\n",
      "  - 'SSN'(text): Social Security Number of the nurse.\n",
      "Table Name: Appointment\n",
      "  - 'AppointmentID'(number): Unique identifier for each appointment.\n",
      "  - 'Patient'(number): Identifier for the patient.\n",
      "  - 'PrepNurse'(number): Identifier for the nurse preparing the patient.\n",
      "  - 'Physician'(number): Identifier for the physician conducting the appointment.\n",
      "  - 'Start'(number): Start time of the appointment.\n",
      "  - 'End'(number): End time of the appointment.\n",
      "  - 'ExaminationRoom'(number): Identifier for the examination room.\n",
      "Table Name: Medication\n",
      "  - 'Code'(number): Unique code for each medication.\n",
      "  - 'Name'(number): Name of the medication.\n",
      "  - 'Brand'(number): Brand name of the medication.\n",
      "  - 'Description'(number): Description of the medication.\n",
      "Table Name: Prescribes\n",
      "  - 'Physician'(number): Identifier for the physician prescribing the medication.\n",
      "  - 'Patient'(number): Identifier for the patient receiving the prescription.\n",
      "  - 'Medication'(number): Identifier for the prescribed medication.\n",
      "  - 'Date'(number): Date when the medication was prescribed.\n",
      "  - 'Appointment'(number): Identifier for the appointment related to the prescription.\n",
      "  - 'Dose'(number): Dosage of the medication prescribed.\n",
      "Table Name: Block\n",
      "  - 'BlockFloor'(boolean): Indicates if the floor is blocked.\n",
      "  - 'BlockCode'(boolean): Indicates if the block code is active.\n",
      "Table Name: Room\n",
      "  - 'RoomNumber'(number): Unique identifier for each room.\n",
      "  - 'RoomType'(number): Type of the room (e.g., patient room, examination room).\n",
      "  - 'BlockFloor'(number): Identifier for the blocked floor status.\n",
      "  - 'BlockCode'(number): Identifier for the blocked code status.\n",
      "  - 'Unavailable'(number): Indicates if the room is unavailable.\n",
      "Table Name: On_Call\n",
      "  - 'Nurse'(text): Identifier for the nurse on call.\n",
      "  - 'BlockFloor'(text): Identifier for the blocked floor status.\n",
      "  - 'BlockCode'(text): Identifier for the blocked code status.\n",
      "  - 'OnCallStart'(text): Start time of the on-call period.\n",
      "  - 'OnCallEnd'(text): End time of the on-call period.\n",
      "Table Name: Stay\n",
      "  - 'StayID'(number): Unique identifier for each hospital stay.\n",
      "  - 'Patient'(number): Identifier for the patient staying in the hospital.\n",
      "  - 'Room'(number): Identifier for the room where the patient is staying.\n",
      "  - 'StayStart'(number): Start date and time of the hospital stay.\n",
      "  - 'StayEnd'(number): End date and time of the hospital stay.\n",
      "Table Name: Undergoes\n",
      "  - 'Patient'(number): Identifier for the patient undergoing procedures.\n",
      "  - 'Procedures'(number): Identifier for the procedures being undergone.\n",
      "  - 'Stay'(number): Identifier for the stay associated with the procedures.\n",
      "  - 'DateUndergoes'(number): Date when the procedures are performed.\n",
      "  - 'Physician'(number): Identifier for the physician performing the procedures.\n",
      "  - 'AssistingNurse'(number): Identifier for the nurse assisting during the procedures.\n"
     ]
    }
   ],
   "source": [
    "with (proj_path / 'db_data' / 'sparc_description.json').open() as f:\n",
    "    all_descriptions = json.load(f)\n",
    "\n",
    "print(get_schema_str(schema=sparc_tables['hospital_1'].db_schema, col_explanation=all_descriptions['hospital_1']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
