{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* gpt-4o-mini\n",
    "* gemini-1.5-pro\n",
    "* gemini-1.5-flash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train: 3034 | Number of dev: 422\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "from src.db_utils import get_schema_str, get_data_dict\n",
    "from src.database import SqliteDatabase, DuckDBDatabase\n",
    "from src.sparc_preprocess import (\n",
    "    load_sparc_data,\n",
    "    process_all_tables, \n",
    "    filter_samples_by_count, \n",
    "    process_samples, \n",
    "    split_train_dev\n",
    ")\n",
    "\n",
    "# duckdb.sql('INSTALL sqlite')\n",
    "# duckdb.sql('SET GLOBAL sqlite_all_varchar = true;')\n",
    "\n",
    "proj_path = Path('.').resolve()\n",
    "sparc_path = proj_path / 'data' / 'sparc'\n",
    "\n",
    "tables, train_data, dev_data = load_sparc_data(sparc_path)\n",
    "print(f'Number of train: {len(train_data)} | Number of dev: {len(dev_data)}')\n",
    "\n",
    "sparc_tables = process_all_tables(tables)\n",
    "# filter samples by count, must have at least 5 samples\n",
    "all_data = filter_samples_by_count(train_data+dev_data, n=5)\n",
    "# process samples -> {db_id: list of samples}\n",
    "sparc_samples = process_samples(all_data)\n",
    "# change train/dev by sample\n",
    "train_samples, dev_samples = split_train_dev(sparc_samples, ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Physician', 'Department', 'Affiliated_With', 'Procedures', 'Trained_In', 'Patient', 'Nurse', 'Appointment', 'Medication', 'Prescribes', 'Block', 'Room', 'On_Call', 'Stay', 'Undergoes'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_id = 'hospital_1'\n",
    "db_file = str(sparc_path / 'database' / db_id / f'{db_id}.sqlite')\n",
    "database = SqliteDatabase(db_file, foreign_keys=sparc_tables[db_id].foreign_keys)\n",
    "database.table_cols.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DepartmentID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Head</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>General Medicine</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Surgery</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Psychiatry</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DepartmentID              Name  Head\n",
       "0             1  General Medicine     4\n",
       "1             2           Surgery     7\n",
       "2             3        Psychiatry     9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database.execute('SELECT * FROM Department LIMIT 5;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AppointmentID: numeric ordinal\n",
      "Patient: numeric ordinal\n",
      "PrepNurse: numeric ordinal\n",
      "Physician: numeric ordinal\n",
      "Start: datetime ordinal\n"
     ]
    }
   ],
   "source": [
    "dtype_functions = {\n",
    "    'numeric': pd.to_numeric,\n",
    "    'datetime': pd.to_datetime\n",
    "}\n",
    "\n",
    "def null_percentage(s: pd.Series) -> float:\n",
    "    return s.isnull().sum() / len(s)\n",
    "\n",
    "column_info = {}\n",
    "for col in df.columns:\n",
    "    # dtype\n",
    "    null_index = df[col].isnull()\n",
    "    for logical_type in ['numeric', 'datetime', 'text']:\n",
    "        if logical_type in ['numeric', 'datetime']:\n",
    "            try:\n",
    "                df.loc[~null_index, col] = dtype_functions[logical_type](df.loc[~null_index, col], errors='raise')\n",
    "                attribute_type = 'ordinal'\n",
    "                break\n",
    "            except ValueError as e:\n",
    "                # print(f'-- {col}: {logical_type} {e}')\n",
    "                continue\n",
    "            except TypeError as e:\n",
    "                # print(f'-- {col}: {logical_type} {e}')\n",
    "                continue\n",
    "        else:\n",
    "            attribute_type = 'nominal'\n",
    "            break\n",
    "    print(f'{col}: {logical_type} {attribute_type}')\n",
    "    # unique values\n",
    "    unique_values = df[col].unique()\n",
    "    # min, max\n",
    "    min_val = df[col].min()\n",
    "    max_val = df[col].max()\n",
    "    # null percentage\n",
    "    null_percent = null_percentage(df[col])\n",
    "\n",
    "    column_info[col] = {\n",
    "        'logical_type': logical_type,\n",
    "        'attribute_type': attribute_type,\n",
    "        'unique_values': unique_values,\n",
    "        'min': min_val,\n",
    "        'max': max_val,\n",
    "        'null_percentage': null_percent\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "from langchain_core.pydantic_v1 import BaseModel as LCBaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Table and Columns]\n",
      "Table Name: Physician\n",
      "  - 'EmployeeID'(text): Unique identifier for each physician.\n",
      "  - 'Name'(text): Full name of the physician.\n",
      "  - 'Position'(text): Job title or role of the physician.\n",
      "  - 'SSN'(text): Social Security Number of the physician.\n",
      "Table Name: Department\n",
      "  - 'Depart\n"
     ]
    }
   ],
   "source": [
    "with (proj_path / 'db_data' / 'sparc_description.json').open() as f:\n",
    "    all_descriptions = json.load(f)\n",
    "\n",
    "print(get_schema_str(\n",
    "    schema=sparc_tables['hospital_1'].db_schema, \n",
    "    col_explanation=all_descriptions['hospital_1'])[:300]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Department.Head = Physician.EmployeeID',\n",
       " 'Affiliated_With.Department = Department.DepartmentID',\n",
       " 'Affiliated_With.Physician = Physician.EmployeeID',\n",
       " 'Trained_In.Treatment = Procedures.Code',\n",
       " 'Trained_In.Physician = Physician.EmployeeID',\n",
       " 'Patient.PCP = Physician.EmployeeID',\n",
       " 'Appointment.Physician = Physician.EmployeeID',\n",
       " 'Appointment.PrepNurse = Nurse.EmployeeID',\n",
       " 'Appointment.Patient = Patient.SSN',\n",
       " 'Prescribes.Appointment = Appointment.AppointmentID',\n",
       " 'Prescribes.Medication = Medication.Code',\n",
       " 'Prescribes.Patient = Patient.SSN',\n",
       " 'Prescribes.Physician = Physician.EmployeeID',\n",
       " 'Room.BlockFloor = Block.BlockFloor',\n",
       " 'Room.BlockCode = Block.BlockCode',\n",
       " 'On_Call.BlockFloor = Block.BlockFloor',\n",
       " 'On_Call.BlockCode = Block.BlockCode',\n",
       " 'On_Call.Nurse = Nurse.EmployeeID',\n",
       " 'Stay.Room = Room.RoomNumber',\n",
       " 'Stay.Patient = Patient.SSN',\n",
       " 'Undergoes.AssistingNurse = Nurse.EmployeeID',\n",
       " 'Undergoes.Physician = Physician.EmployeeID',\n",
       " 'Undergoes.Stay = Stay.StayID',\n",
       " 'Undergoes.Procedures = Procedures.Code',\n",
       " 'Undergoes.Patient = Patient.SSN']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparc_tables['hospital_1'].foreign_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Access Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0-Question] How many employees does each department have?\n",
      "[0-SQL]: SELECT count(departmentID) FROM department GROUP BY departmentID\n",
      "[1-Question] Which department has the least employees?\n",
      "[1-SQL]: SELECT * FROM department GROUP BY departmentID ORDER BY count(departmentID) LIMIT 1;\n",
      "[2-Question] Who is the head of this department? Find the employee id.\n",
      "[2-SQL]: SELECT head FROM department GROUP BY departmentID ORDER BY count(departmentID) LIMIT 1; \n",
      "\n",
      "[Final]\n",
      "Question: Tell me the employee id of the head of the department with the least employees.\n",
      "SQL: SELECT head FROM department GROUP BY departmentID ORDER BY count(departmentID) LIMIT 1;\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.sparc_preprocess import SparcSample, QuestionSQL\n",
    "\n",
    "def format_interactions(interactions: list[QuestionSQL]) -> str:\n",
    "    workload = ''\n",
    "    for i, interaction in enumerate(interactions):\n",
    "        workload += f'[{i}-Question] {interaction.question}\\n[{i}-SQL]: {interaction.sql}\\n'\n",
    "    return workload.strip()\n",
    "\n",
    "with (proj_path / 'db_data' / 'sparc_description.json').open() as f:\n",
    "    all_descriptions = json.load(f)\n",
    "\n",
    "idx = 1\n",
    "data = train_samples[idx]\n",
    "table = sparc_tables[data.db_id]\n",
    "col_explanation = all_descriptions[data.db_id]\n",
    "schema_str = get_schema_str(\n",
    "    schema=table.db_schema, \n",
    "    foreign_keys=table.foreign_keys,\n",
    "    primary_keys=table.primary_keys,\n",
    "    col_explanation=col_explanation\n",
    ")\n",
    "workload = format_interactions(data.interactions)\n",
    "print(workload, '\\n')\n",
    "print(f'[Final]\\nQuestion: {data.final.question}\\nSQL: {data.final.sql}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlglot\n",
    "import sqlglot.expressions as exp\n",
    "from sqlglot.diff import Keep\n",
    "from sqlglot.optimizer import optimize\n",
    "\n",
    "def get_sources(data: SparcSample, schema: dict) -> list[tuple[str, list[str]]]:\n",
    "    sources = []\n",
    "    for x in data.interactions:\n",
    "        sql = optimize(sqlglot.parse_one(x.sql, read='sqlite'), schema=schema)\n",
    "        tbls = [x.this.this for x in list(sql.find_all(exp.Table))]\n",
    "        sources.append((x.question, tbls))\n",
    "    return sources\n",
    "\n",
    "db_id = 'hospital_1'\n",
    "train_subsamples = list(filter(lambda x: x.db_id == db_id, train_samples))\n",
    "dev_subsamples = list(filter(lambda x: x.db_id == db_id, dev_samples))\n",
    "table = sparc_tables[db_id]\n",
    "database = Database(db_file=str(sparc_path / 'database' / db_id / f'{db_id}.sqlite'))\n",
    "\n",
    "# train_sources = []\n",
    "# for data in train_subsamples:\n",
    "#     train_sources.append(get_sources(data, schema=table.db_schema))\n",
    "# dev_sources = []\n",
    "# for data in dev_subsamples:\n",
    "#     dev_sources.append(get_sources(data, schema=table.db_schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(*) FROM appointment GROUP BY patient\n",
      "SELECT * FROM appointment GROUP BY patient HAVING COUNT(*) > 1\n"
     ]
    }
   ],
   "source": [
    "x = train_subsamples[4].interactions\n",
    "schema = table.db_schema\n",
    "sql1 = sqlglot.parse_one(x[0].sql, read='sqlite')\n",
    "sql2 = sqlglot.parse_one(x[1].sql, read='sqlite')\n",
    "print(sql1.sql())\n",
    "print(sql2.sql())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect(str(sparc_path / 'database' / db_id / f'{db_id}.sqlite'))\n",
    "cursor = conn.cursor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grace Ritchie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>John Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dennis Doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dennis Doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random J. Patient</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>John Smith</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dennis Doe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Grace Ritchie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Name\n",
       "0         John Smith\n",
       "1      Grace Ritchie\n",
       "2         John Smith\n",
       "3         Dennis Doe\n",
       "4         Dennis Doe\n",
       "5  Random J. Patient\n",
       "6         John Smith\n",
       "7         Dennis Doe\n",
       "8      Grace Ritchie"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_sql_query('SELECT name FROM appointment AS T1 JOIN patient AS T2 ON T1.patient = T2.ssn', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John Smith',),\n",
       " ('Grace Ritchie',),\n",
       " ('John Smith',),\n",
       " ('Dennis Doe',),\n",
       " ('Dennis Doe',),\n",
       " ('Random J. Patient',),\n",
       " ('John Smith',),\n",
       " ('Dennis Doe',),\n",
       " ('Grace Ritchie',)]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT name FROM appointment AS T1 JOIN patient AS T2 ON T1.patient = T2.ssn').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13216584, 100000001, 101, 1, '2008-04-24 10:00', '2008-04-24 11:00', 'A'),\n",
       " (26548913, 100000002, 101, 2, '2008-04-24 10:00', '2008-04-24 11:00', 'B'),\n",
       " (46846589, 100000004, 103, 4, '2008-04-25 10:00', '2008-04-25 11:00', 'B')]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cursor.execute('SELECT * FROM appointment GROUP BY patient HAVING COUNT(*) > 1').fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Keep(source=Column(\n",
       "   this=Identifier(this=departmentID, quoted=False)), target=Column(\n",
       "   this=Identifier(this=departmentID, quoted=False))),\n",
       " Keep(source=Count(\n",
       "   this=Column(\n",
       "     this=Identifier(this=departmentID, quoted=False)),\n",
       "   big_int=True), target=Count(\n",
       "   this=Column(\n",
       "     this=Identifier(this=departmentID, quoted=False)),\n",
       "   big_int=True)),\n",
       " Keep(source=From(\n",
       "   this=Table(\n",
       "     this=Identifier(this=department, quoted=False))), target=From(\n",
       "   this=Table(\n",
       "     this=Identifier(this=department, quoted=False)))),\n",
       " Keep(source=Group(\n",
       "   expressions=[\n",
       "     Column(\n",
       "       this=Identifier(this=departmentID, quoted=False))]), target=Group(\n",
       "   expressions=[\n",
       "     Column(\n",
       "       this=Identifier(this=departmentID, quoted=False))])),\n",
       " Keep(source=Table(\n",
       "   this=Identifier(this=department, quoted=False)), target=Table(\n",
       "   this=Identifier(this=department, quoted=False)))}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff1 = sqlglot.diff(sql1, sql2)\n",
    "diff2 = sqlglot.diff(sql2, sql1)\n",
    "diff1 = set(filter(lambda x: isinstance(x, Keep), diff1))\n",
    "diff2 = set(filter(lambda x: isinstance(x, Keep), diff2))\n",
    "filter(lambda x: type(x.source) in [exp.Table, exp.Group, exp.Join, exp] , diff1.intersection(diff2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT COUNT(departmentID) FROM department GROUP BY departmentID\n",
      "SELECT * FROM department GROUP BY departmentID ORDER BY COUNT(departmentID) LIMIT 1\n"
     ]
    }
   ],
   "source": [
    "x = train_subsamples[1].interactions\n",
    "schema = table.db_schema\n",
    "sql1 = sqlglot.parse_one(x[0].sql, read='sqlite')\n",
    "sql2 = sqlglot.parse_one(x[1].sql, read='sqlite')\n",
    "print(sql1.sql())\n",
    "print(sql2.sql())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Keep(source=Column(\n",
       "   this=Identifier(this=departmentID, quoted=False)), target=Column(\n",
       "   this=Identifier(this=departmentID, quoted=False))),\n",
       " Keep(source=Count(\n",
       "   this=Column(\n",
       "     this=Identifier(this=departmentID, quoted=False)),\n",
       "   big_int=True), target=Count(\n",
       "   this=Column(\n",
       "     this=Identifier(this=departmentID, quoted=False)),\n",
       "   big_int=True)),\n",
       " Keep(source=From(\n",
       "   this=Table(\n",
       "     this=Identifier(this=department, quoted=False))), target=From(\n",
       "   this=Table(\n",
       "     this=Identifier(this=department, quoted=False)))),\n",
       " Keep(source=Group(\n",
       "   expressions=[\n",
       "     Column(\n",
       "       this=Identifier(this=departmentID, quoted=False))]), target=Group(\n",
       "   expressions=[\n",
       "     Column(\n",
       "       this=Identifier(this=departmentID, quoted=False))])),\n",
       " Keep(source=Table(\n",
       "   this=Identifier(this=department, quoted=False)), target=Table(\n",
       "   this=Identifier(this=department, quoted=False)))}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff1 = sqlglot.diff(sql1, sql2)\n",
    "diff2 = sqlglot.diff(sql2, sql1)\n",
    "diff1 = set(filter(lambda x: isinstance(x, Keep), diff1))\n",
    "diff2 = set(filter(lambda x: isinstance(x, Keep), diff2))\n",
    "diff1.intersection(diff2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/166 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 28/166 [00:04<00:24,  5.73it/s]\n"
     ]
    },
    {
     "ename": "TypeMismatchException",
     "evalue": "Mismatch Type Error: Invalid type in column \"If_Affirmative_Win\": column was declared as integer, found \"F\" of type \"text\" instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeMismatchException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m database \u001b[38;5;241m=\u001b[39m Database(db_file\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(sparc_path \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatabase\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m/\u001b[39m db_id \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdb_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.sqlite\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mdatabase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_table_summaries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConversionException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     11\u001b[0m     errors\u001b[38;5;241m.\u001b[39mappend((e, db_id))\n",
      "File \u001b[0;32m~/code/BusinessLake/src/database.py:56\u001b[0m, in \u001b[0;36mDatabase.get_table_summaries\u001b[0;34m(self, categorical_threshold, skip_keys)\u001b[0m\n\u001b[1;32m     54\u001b[0m table_summary \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m table_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtable_cols\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m---> 56\u001b[0m     table_summary[table_name] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_summarize_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtable_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_threshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m table_summary\n",
      "File \u001b[0;32m~/code/BusinessLake/src/database.py:66\u001b[0m, in \u001b[0;36mDatabase._summarize_table\u001b[0;34m(self, table_name, categorical_threshold, skip_keys)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_summarize_table\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     61\u001b[0m                      table_name: \u001b[38;5;28mstr\u001b[39m, \n\u001b[1;32m     62\u001b[0m                      categorical_threshold: Optional[\u001b[38;5;28mfloat\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m, \n\u001b[1;32m     63\u001b[0m                      skip_keys: Optional[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]]\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     64\u001b[0m     ):\n\u001b[1;32m     65\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSUMMARIZE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtable_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 66\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogical_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_logical_type, \n\u001b[1;32m     69\u001b[0m         column_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumn_types, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m         axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     73\u001b[0m     )\n\u001b[1;32m     74\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mloc[:, [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolumn_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogical_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapprox_unique\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m     75\u001b[0m                     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnull_percentage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq25\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq50\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq75\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/code/BusinessLake/src/database.py:116\u001b[0m, in \u001b[0;36mDatabase.execute\u001b[0;34m(self, query, rt_pandas)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rt_pandas:\n\u001b[0;32m--> 116\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mdf()\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcon\u001b[38;5;241m.\u001b[39mexecute(query)\n",
      "\u001b[0;31mTypeMismatchException\u001b[0m: Mismatch Type Error: Invalid type in column \"If_Affirmative_Win\": column was declared as integer, found \"F\" of type \"text\" instead."
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from duckdb import ConversionException\n",
    "\n",
    "errors = []\n",
    "for db_id in tqdm(sparc_tables.keys(), total=len(sparc_tables)):\n",
    "    table = sparc_tables[db_id]\n",
    "    database = Database(db_file=str(sparc_path / 'database' / db_id / f'{db_id}.sqlite'))\n",
    "    try:\n",
    "        database.get_table_summaries()\n",
    "    except ConversionException as e:\n",
    "        errors.append((e, db_id))\n",
    "    except ValueError as e:\n",
    "        errors.append((e, db_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(13216584, 100000001, 101, 1, '2008-04-24 10:00', '2008-04-24 11:00', 'A')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = sqlite3.connect(str(sparc_path / 'database' / db_id / f'{db_id}.sqlite'))\n",
    "\n",
    "c = db.cursor()\n",
    "c.execute('SELECT * FROM appointment LIMIT 1').fetchall()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
